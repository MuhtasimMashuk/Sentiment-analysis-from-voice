{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from librosa import display\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('C:/voice/Actor_01/03-01-01-01-01-01-01.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x1ed60a0ee08>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data loaded. Loading time: 91.2150604724884 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "path = 'C:/voice/'\n",
    "lst = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "  for file in files:\n",
    "      try:\n",
    "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
    "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
    "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
    "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
    "        file = int(file[7:8]) - 1 \n",
    "        arr = mfccs, file\n",
    "        lst.append(arr)\n",
    "      # If the file is not valid, skip it\n",
    "      except ValueError:\n",
    "        continue\n",
    "\n",
    "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = zip(*lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1440, 40), (1440,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "X_name = 'X.joblib'\n",
    "y_name = 'y.joblib'\n",
    "save_dir = 'C:/another_model/'\n",
    "\n",
    "savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
    "savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = joblib.load('C:/another_model/X.joblib')\n",
    "y = joblib.load('C:/another_model/y.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',\n",
    "                 input_shape=(40,1)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_11 (Conv1D)           (None, 40, 128)           768       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5, 128)            82048     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 5128      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 87,944\n",
      "Trainable params: 87,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1152 samples, validate on 288 samples\n",
      "Epoch 1/1000\n",
      "1152/1152 [==============================] - 2s 2ms/step - loss: 2.1163 - acc: 0.1311 - val_loss: 2.0716 - val_acc: 0.1181\n",
      "Epoch 2/1000\n",
      "1152/1152 [==============================] - 1s 577us/step - loss: 2.0942 - acc: 0.1328 - val_loss: 2.0659 - val_acc: 0.1632\n",
      "Epoch 3/1000\n",
      "1152/1152 [==============================] - 1s 576us/step - loss: 2.0815 - acc: 0.1345 - val_loss: 2.0561 - val_acc: 0.1389\n",
      "Epoch 4/1000\n",
      "1152/1152 [==============================] - 1s 542us/step - loss: 2.0833 - acc: 0.1545 - val_loss: 2.0700 - val_acc: 0.1319\n",
      "Epoch 5/1000\n",
      "1152/1152 [==============================] - 1s 554us/step - loss: 2.0795 - acc: 0.1424 - val_loss: 2.0566 - val_acc: 0.1667\n",
      "Epoch 6/1000\n",
      "1152/1152 [==============================] - 1s 576us/step - loss: 2.0749 - acc: 0.1545 - val_loss: 2.0648 - val_acc: 0.1944\n",
      "Epoch 7/1000\n",
      "1152/1152 [==============================] - 1s 571us/step - loss: 2.0730 - acc: 0.1345 - val_loss: 2.0393 - val_acc: 0.2222\n",
      "Epoch 8/1000\n",
      "1152/1152 [==============================] - 1s 648us/step - loss: 2.0791 - acc: 0.1337 - val_loss: 2.0431 - val_acc: 0.1944\n",
      "Epoch 9/1000\n",
      "1152/1152 [==============================] - 1s 819us/step - loss: 2.0619 - acc: 0.1589 - val_loss: 2.0520 - val_acc: 0.1632\n",
      "Epoch 10/1000\n",
      "1152/1152 [==============================] - 1s 566us/step - loss: 2.0638 - acc: 0.1493 - val_loss: 2.0405 - val_acc: 0.1979\n",
      "Epoch 11/1000\n",
      "1152/1152 [==============================] - 1s 511us/step - loss: 2.0563 - acc: 0.1597 - val_loss: 2.0295 - val_acc: 0.2292\n",
      "Epoch 12/1000\n",
      "1152/1152 [==============================] - 1s 578us/step - loss: 2.0475 - acc: 0.1814 - val_loss: 2.0450 - val_acc: 0.1667\n",
      "Epoch 13/1000\n",
      "1152/1152 [==============================] - 1s 662us/step - loss: 2.0629 - acc: 0.1562 - val_loss: 2.0318 - val_acc: 0.1910\n",
      "Epoch 14/1000\n",
      "1152/1152 [==============================] - 1s 561us/step - loss: 2.0489 - acc: 0.1684 - val_loss: 2.0218 - val_acc: 0.2396\n",
      "Epoch 15/1000\n",
      "1152/1152 [==============================] - 1s 592us/step - loss: 2.0544 - acc: 0.1684 - val_loss: 2.0226 - val_acc: 0.1840\n",
      "Epoch 16/1000\n",
      "1152/1152 [==============================] - 1s 709us/step - loss: 2.0401 - acc: 0.1701 - val_loss: 2.0191 - val_acc: 0.1806\n",
      "Epoch 17/1000\n",
      "1152/1152 [==============================] - 1s 648us/step - loss: 2.0348 - acc: 0.1849 - val_loss: 2.0234 - val_acc: 0.1910\n",
      "Epoch 18/1000\n",
      "1152/1152 [==============================] - 1s 594us/step - loss: 2.0284 - acc: 0.1875 - val_loss: 2.0070 - val_acc: 0.1979\n",
      "Epoch 19/1000\n",
      "1152/1152 [==============================] - 1s 558us/step - loss: 2.0204 - acc: 0.2101 - val_loss: 2.0180 - val_acc: 0.1875\n",
      "Epoch 20/1000\n",
      "1152/1152 [==============================] - 1s 706us/step - loss: 2.0262 - acc: 0.1693 - val_loss: 2.0074 - val_acc: 0.2153\n",
      "Epoch 21/1000\n",
      "1152/1152 [==============================] - 1s 608us/step - loss: 2.0248 - acc: 0.2005 - val_loss: 1.9957 - val_acc: 0.2743\n",
      "Epoch 22/1000\n",
      "1152/1152 [==============================] - 1s 521us/step - loss: 2.0175 - acc: 0.1892 - val_loss: 2.0015 - val_acc: 0.2014\n",
      "Epoch 23/1000\n",
      "1152/1152 [==============================] - 1s 523us/step - loss: 2.0105 - acc: 0.1988 - val_loss: 2.0020 - val_acc: 0.2188\n",
      "Epoch 24/1000\n",
      "1152/1152 [==============================] - 1s 520us/step - loss: 2.0008 - acc: 0.2205 - val_loss: 1.9946 - val_acc: 0.2118\n",
      "Epoch 25/1000\n",
      "1152/1152 [==============================] - 1s 528us/step - loss: 2.0072 - acc: 0.1953 - val_loss: 1.9876 - val_acc: 0.2118\n",
      "Epoch 26/1000\n",
      "1152/1152 [==============================] - 1s 509us/step - loss: 1.9981 - acc: 0.2049 - val_loss: 1.9930 - val_acc: 0.2188\n",
      "Epoch 27/1000\n",
      "1152/1152 [==============================] - 1s 519us/step - loss: 1.9966 - acc: 0.2214 - val_loss: 1.9817 - val_acc: 0.2118\n",
      "Epoch 28/1000\n",
      "1152/1152 [==============================] - 1s 539us/step - loss: 1.9906 - acc: 0.2309 - val_loss: 1.9782 - val_acc: 0.2257\n",
      "Epoch 29/1000\n",
      "1152/1152 [==============================] - 1s 506us/step - loss: 1.9932 - acc: 0.2005 - val_loss: 1.9683 - val_acc: 0.2188\n",
      "Epoch 30/1000\n",
      "1152/1152 [==============================] - 1s 532us/step - loss: 1.9892 - acc: 0.2101 - val_loss: 1.9710 - val_acc: 0.2188\n",
      "Epoch 31/1000\n",
      "1152/1152 [==============================] - 1s 489us/step - loss: 1.9850 - acc: 0.2109 - val_loss: 1.9626 - val_acc: 0.2569\n",
      "Epoch 32/1000\n",
      "1152/1152 [==============================] - 1s 674us/step - loss: 1.9861 - acc: 0.2092 - val_loss: 1.9589 - val_acc: 0.2326\n",
      "Epoch 33/1000\n",
      "1152/1152 [==============================] - 1s 507us/step - loss: 1.9727 - acc: 0.2240 - val_loss: 1.9619 - val_acc: 0.2188\n",
      "Epoch 34/1000\n",
      "1152/1152 [==============================] - 1s 739us/step - loss: 1.9681 - acc: 0.2326 - val_loss: 1.9626 - val_acc: 0.2292\n",
      "Epoch 35/1000\n",
      "1152/1152 [==============================] - 1s 639us/step - loss: 1.9655 - acc: 0.2500 - val_loss: 1.9566 - val_acc: 0.2222\n",
      "Epoch 36/1000\n",
      "1152/1152 [==============================] - 1s 816us/step - loss: 1.9657 - acc: 0.2257 - val_loss: 1.9548 - val_acc: 0.2292\n",
      "Epoch 37/1000\n",
      "1152/1152 [==============================] - 1s 634us/step - loss: 1.9625 - acc: 0.2266 - val_loss: 1.9435 - val_acc: 0.2535\n",
      "Epoch 38/1000\n",
      "1152/1152 [==============================] - 1s 733us/step - loss: 1.9598 - acc: 0.2222 - val_loss: 1.9428 - val_acc: 0.2222\n",
      "Epoch 39/1000\n",
      "1152/1152 [==============================] - 1s 718us/step - loss: 1.9606 - acc: 0.2387 - val_loss: 1.9446 - val_acc: 0.2396\n",
      "Epoch 40/1000\n",
      "1152/1152 [==============================] - 1s 572us/step - loss: 1.9621 - acc: 0.2248 - val_loss: 1.9438 - val_acc: 0.2153\n",
      "Epoch 41/1000\n",
      "1152/1152 [==============================] - 1s 491us/step - loss: 1.9500 - acc: 0.2569 - val_loss: 1.9385 - val_acc: 0.2535\n",
      "Epoch 42/1000\n",
      "1152/1152 [==============================] - 1s 540us/step - loss: 1.9535 - acc: 0.2127 - val_loss: 1.9353 - val_acc: 0.2431\n",
      "Epoch 43/1000\n",
      "1152/1152 [==============================] - 1s 521us/step - loss: 1.9492 - acc: 0.2457 - val_loss: 1.9318 - val_acc: 0.2257\n",
      "Epoch 44/1000\n",
      "1152/1152 [==============================] - 1s 501us/step - loss: 1.9514 - acc: 0.2422 - val_loss: 1.9348 - val_acc: 0.2257\n",
      "Epoch 45/1000\n",
      "1152/1152 [==============================] - 1s 473us/step - loss: 1.9431 - acc: 0.2474 - val_loss: 1.9316 - val_acc: 0.2292\n",
      "Epoch 46/1000\n",
      "1152/1152 [==============================] - 1s 604us/step - loss: 1.9456 - acc: 0.2457 - val_loss: 1.9213 - val_acc: 0.2361\n",
      "Epoch 47/1000\n",
      "1152/1152 [==============================] - 1s 561us/step - loss: 1.9445 - acc: 0.2370 - val_loss: 1.9274 - val_acc: 0.2326\n",
      "Epoch 48/1000\n",
      "1152/1152 [==============================] - 1s 491us/step - loss: 1.9461 - acc: 0.2309 - val_loss: 1.9259 - val_acc: 0.2326\n",
      "Epoch 49/1000\n",
      "1152/1152 [==============================] - 1s 549us/step - loss: 1.9366 - acc: 0.2361 - val_loss: 1.9310 - val_acc: 0.2083\n",
      "Epoch 50/1000\n",
      "1152/1152 [==============================] - 1s 554us/step - loss: 1.9342 - acc: 0.2309 - val_loss: 1.9234 - val_acc: 0.2326\n",
      "Epoch 51/1000\n",
      "1152/1152 [==============================] - 1s 612us/step - loss: 1.9313 - acc: 0.2630 - val_loss: 1.9217 - val_acc: 0.2500\n",
      "Epoch 52/1000\n",
      "1152/1152 [==============================] - 1s 480us/step - loss: 1.9386 - acc: 0.2370 - val_loss: 1.9195 - val_acc: 0.2396\n",
      "Epoch 53/1000\n",
      "1152/1152 [==============================] - 1s 539us/step - loss: 1.9314 - acc: 0.2500 - val_loss: 1.9153 - val_acc: 0.2326\n",
      "Epoch 54/1000\n",
      "1152/1152 [==============================] - 1s 583us/step - loss: 1.9329 - acc: 0.2274 - val_loss: 1.9135 - val_acc: 0.2292\n",
      "Epoch 55/1000\n",
      "1152/1152 [==============================] - 1s 599us/step - loss: 1.9350 - acc: 0.2257 - val_loss: 1.9153 - val_acc: 0.2326\n",
      "Epoch 56/1000\n",
      "1152/1152 [==============================] - 1s 533us/step - loss: 1.9334 - acc: 0.2517 - val_loss: 1.9065 - val_acc: 0.2326\n",
      "Epoch 57/1000\n",
      "1152/1152 [==============================] - 1s 593us/step - loss: 1.9274 - acc: 0.2266 - val_loss: 1.9137 - val_acc: 0.2361\n",
      "Epoch 58/1000\n",
      "1152/1152 [==============================] - 1s 560us/step - loss: 1.9392 - acc: 0.2309 - val_loss: 1.9136 - val_acc: 0.2257\n",
      "Epoch 59/1000\n",
      "1152/1152 [==============================] - 1s 606us/step - loss: 1.9233 - acc: 0.2491 - val_loss: 1.9064 - val_acc: 0.2257\n",
      "Epoch 60/1000\n",
      "1152/1152 [==============================] - 1s 672us/step - loss: 1.9330 - acc: 0.2318 - val_loss: 1.9062 - val_acc: 0.2153\n",
      "Epoch 61/1000\n",
      "1152/1152 [==============================] - 1s 539us/step - loss: 1.9173 - acc: 0.2535 - val_loss: 1.9061 - val_acc: 0.2257\n",
      "Epoch 62/1000\n",
      "1152/1152 [==============================] - 1s 550us/step - loss: 1.9210 - acc: 0.2318 - val_loss: 1.8979 - val_acc: 0.2361\n",
      "Epoch 63/1000\n",
      "1152/1152 [==============================] - 1s 549us/step - loss: 1.9153 - acc: 0.2578 - val_loss: 1.9021 - val_acc: 0.2396\n",
      "Epoch 64/1000\n",
      "1152/1152 [==============================] - 1s 555us/step - loss: 1.9155 - acc: 0.2509 - val_loss: 1.9105 - val_acc: 0.2188\n",
      "Epoch 65/1000\n",
      "1152/1152 [==============================] - 1s 550us/step - loss: 1.9265 - acc: 0.2309 - val_loss: 1.8965 - val_acc: 0.2500\n",
      "Epoch 66/1000\n",
      "1152/1152 [==============================] - 1s 576us/step - loss: 1.9084 - acc: 0.2795 - val_loss: 1.9034 - val_acc: 0.2326\n",
      "Epoch 67/1000\n",
      "1152/1152 [==============================] - 1s 546us/step - loss: 1.9138 - acc: 0.2431 - val_loss: 1.8959 - val_acc: 0.2708\n",
      "Epoch 68/1000\n",
      "1152/1152 [==============================] - 1s 565us/step - loss: 1.9149 - acc: 0.2569 - val_loss: 1.8910 - val_acc: 0.2604\n",
      "Epoch 69/1000\n",
      "1152/1152 [==============================] - 1s 591us/step - loss: 1.9197 - acc: 0.2552 - val_loss: 1.8967 - val_acc: 0.2500\n",
      "Epoch 70/1000\n",
      "1152/1152 [==============================] - 1s 553us/step - loss: 1.9141 - acc: 0.2431 - val_loss: 1.8920 - val_acc: 0.2431\n",
      "Epoch 71/1000\n",
      "1152/1152 [==============================] - 1s 557us/step - loss: 1.9132 - acc: 0.2500 - val_loss: 1.8931 - val_acc: 0.2396\n",
      "Epoch 72/1000\n",
      "1152/1152 [==============================] - 1s 643us/step - loss: 1.9215 - acc: 0.2526 - val_loss: 1.8886 - val_acc: 0.2743\n",
      "Epoch 73/1000\n",
      "1152/1152 [==============================] - 1s 975us/step - loss: 1.9121 - acc: 0.2587 - val_loss: 1.8988 - val_acc: 0.2222\n",
      "Epoch 74/1000\n",
      "1152/1152 [==============================] - 1s 525us/step - loss: 1.9057 - acc: 0.2622 - val_loss: 1.8950 - val_acc: 0.2396\n",
      "Epoch 75/1000\n",
      "1152/1152 [==============================] - 1s 675us/step - loss: 1.9042 - acc: 0.2656 - val_loss: 1.8861 - val_acc: 0.2465\n",
      "Epoch 76/1000\n",
      "1152/1152 [==============================] - 1s 775us/step - loss: 1.9045 - acc: 0.2665 - val_loss: 1.8896 - val_acc: 0.2326\n",
      "Epoch 77/1000\n",
      "1152/1152 [==============================] - 1s 960us/step - loss: 1.9044 - acc: 0.2457 - val_loss: 1.8935 - val_acc: 0.2326\n",
      "Epoch 78/1000\n",
      "1152/1152 [==============================] - 1s 656us/step - loss: 1.9019 - acc: 0.2595 - val_loss: 1.8879 - val_acc: 0.2604\n",
      "Epoch 79/1000\n",
      "1152/1152 [==============================] - 1s 772us/step - loss: 1.9087 - acc: 0.2509 - val_loss: 1.8798 - val_acc: 0.2674\n",
      "Epoch 80/1000\n",
      "1152/1152 [==============================] - 1s 695us/step - loss: 1.9117 - acc: 0.2509 - val_loss: 1.8787 - val_acc: 0.2500\n",
      "Epoch 81/1000\n",
      "1152/1152 [==============================] - 1s 712us/step - loss: 1.9114 - acc: 0.2457 - val_loss: 1.8850 - val_acc: 0.2431\n",
      "Epoch 82/1000\n",
      "1152/1152 [==============================] - 1s 660us/step - loss: 1.9019 - acc: 0.2474 - val_loss: 1.8833 - val_acc: 0.2778\n",
      "Epoch 83/1000\n",
      "1152/1152 [==============================] - 1s 691us/step - loss: 1.8962 - acc: 0.2517 - val_loss: 1.8746 - val_acc: 0.2708\n",
      "Epoch 84/1000\n",
      "1152/1152 [==============================] - 1s 715us/step - loss: 1.8979 - acc: 0.2630 - val_loss: 1.8730 - val_acc: 0.2778\n",
      "Epoch 85/1000\n",
      "1152/1152 [==============================] - 1s 685us/step - loss: 1.8935 - acc: 0.2578 - val_loss: 1.8858 - val_acc: 0.2396\n",
      "Epoch 86/1000\n",
      "1152/1152 [==============================] - 1s 693us/step - loss: 1.8955 - acc: 0.2517 - val_loss: 1.8800 - val_acc: 0.2500\n",
      "Epoch 87/1000\n",
      "1152/1152 [==============================] - 1s 687us/step - loss: 1.8976 - acc: 0.2639 - val_loss: 1.8711 - val_acc: 0.2639\n",
      "Epoch 88/1000\n",
      "1152/1152 [==============================] - 1s 734us/step - loss: 1.8896 - acc: 0.2656 - val_loss: 1.8792 - val_acc: 0.2604\n",
      "Epoch 89/1000\n",
      "1152/1152 [==============================] - 1s 695us/step - loss: 1.8967 - acc: 0.2535 - val_loss: 1.8771 - val_acc: 0.2535\n",
      "Epoch 90/1000\n",
      "1152/1152 [==============================] - 1s 654us/step - loss: 1.8929 - acc: 0.2656 - val_loss: 1.8792 - val_acc: 0.2569\n",
      "Epoch 91/1000\n",
      "1152/1152 [==============================] - 1s 715us/step - loss: 1.8932 - acc: 0.2569 - val_loss: 1.8680 - val_acc: 0.2882\n",
      "Epoch 92/1000\n",
      "1152/1152 [==============================] - 1s 672us/step - loss: 1.8897 - acc: 0.2509 - val_loss: 1.8783 - val_acc: 0.2500\n",
      "Epoch 93/1000\n",
      "1152/1152 [==============================] - 1s 725us/step - loss: 1.8905 - acc: 0.2639 - val_loss: 1.8666 - val_acc: 0.2674\n",
      "Epoch 94/1000\n",
      "1152/1152 [==============================] - 1s 706us/step - loss: 1.8855 - acc: 0.2465 - val_loss: 1.8807 - val_acc: 0.2431\n",
      "Epoch 95/1000\n",
      "1152/1152 [==============================] - 1s 738us/step - loss: 1.8886 - acc: 0.2795 - val_loss: 1.8733 - val_acc: 0.2639\n",
      "Epoch 96/1000\n",
      "1152/1152 [==============================] - 1s 759us/step - loss: 1.8850 - acc: 0.2908 - val_loss: 1.8773 - val_acc: 0.2326\n",
      "Epoch 97/1000\n",
      "1152/1152 [==============================] - 1s 727us/step - loss: 1.8767 - acc: 0.2734 - val_loss: 1.8698 - val_acc: 0.2708\n",
      "Epoch 98/1000\n",
      "1152/1152 [==============================] - 1s 755us/step - loss: 1.8837 - acc: 0.2778 - val_loss: 1.8822 - val_acc: 0.2396\n",
      "Epoch 99/1000\n",
      "1152/1152 [==============================] - 1s 773us/step - loss: 1.8815 - acc: 0.2700 - val_loss: 1.8855 - val_acc: 0.2326\n",
      "Epoch 100/1000\n",
      "1152/1152 [==============================] - 1s 596us/step - loss: 1.8864 - acc: 0.2630 - val_loss: 1.8703 - val_acc: 0.2708\n",
      "Epoch 101/1000\n",
      "1152/1152 [==============================] - 1s 686us/step - loss: 1.8865 - acc: 0.2613 - val_loss: 1.8577 - val_acc: 0.2847\n",
      "Epoch 102/1000\n",
      "1152/1152 [==============================] - 1s 677us/step - loss: 1.8807 - acc: 0.2856 - val_loss: 1.8707 - val_acc: 0.2778\n",
      "Epoch 103/1000\n",
      "1152/1152 [==============================] - 1s 755us/step - loss: 1.8888 - acc: 0.2517 - val_loss: 1.8594 - val_acc: 0.2778\n",
      "Epoch 104/1000\n",
      "1152/1152 [==============================] - 1s 699us/step - loss: 1.8750 - acc: 0.2691 - val_loss: 1.8664 - val_acc: 0.2847\n",
      "Epoch 105/1000\n",
      "1152/1152 [==============================] - 1s 698us/step - loss: 1.8765 - acc: 0.2804 - val_loss: 1.8756 - val_acc: 0.2361\n",
      "Epoch 106/1000\n",
      "1152/1152 [==============================] - 1s 624us/step - loss: 1.8865 - acc: 0.2700 - val_loss: 1.8695 - val_acc: 0.2569\n",
      "Epoch 107/1000\n",
      "1152/1152 [==============================] - 1s 566us/step - loss: 1.8871 - acc: 0.2587 - val_loss: 1.8667 - val_acc: 0.2639\n",
      "Epoch 108/1000\n",
      "1152/1152 [==============================] - 1s 528us/step - loss: 1.8864 - acc: 0.2734 - val_loss: 1.8591 - val_acc: 0.2708\n",
      "Epoch 109/1000\n",
      "1152/1152 [==============================] - 1s 566us/step - loss: 1.8854 - acc: 0.2717 - val_loss: 1.8574 - val_acc: 0.2917\n",
      "Epoch 110/1000\n",
      "1152/1152 [==============================] - 1s 551us/step - loss: 1.8740 - acc: 0.2743 - val_loss: 1.8624 - val_acc: 0.2604\n",
      "Epoch 111/1000\n",
      "1152/1152 [==============================] - 1s 545us/step - loss: 1.8715 - acc: 0.2821 - val_loss: 1.8577 - val_acc: 0.2639\n",
      "Epoch 112/1000\n",
      "1152/1152 [==============================] - 1s 530us/step - loss: 1.8686 - acc: 0.2674 - val_loss: 1.8708 - val_acc: 0.2882\n",
      "Epoch 113/1000\n",
      "1152/1152 [==============================] - 1s 528us/step - loss: 1.8712 - acc: 0.2630 - val_loss: 1.8572 - val_acc: 0.2604\n",
      "Epoch 114/1000\n",
      "1152/1152 [==============================] - 1s 632us/step - loss: 1.8700 - acc: 0.2613 - val_loss: 1.8564 - val_acc: 0.2847\n",
      "Epoch 115/1000\n",
      "1152/1152 [==============================] - 1s 572us/step - loss: 1.8806 - acc: 0.2656 - val_loss: 1.8547 - val_acc: 0.2882\n",
      "Epoch 116/1000\n",
      "1152/1152 [==============================] - 1s 624us/step - loss: 1.8745 - acc: 0.2734 - val_loss: 1.8681 - val_acc: 0.2569\n",
      "Epoch 117/1000\n",
      "1152/1152 [==============================] - 1s 653us/step - loss: 1.8725 - acc: 0.2595 - val_loss: 1.8540 - val_acc: 0.2847\n",
      "Epoch 118/1000\n",
      "1152/1152 [==============================] - 1s 739us/step - loss: 1.8720 - acc: 0.2674 - val_loss: 1.8490 - val_acc: 0.2986\n",
      "Epoch 119/1000\n",
      "1152/1152 [==============================] - 1s 796us/step - loss: 1.8645 - acc: 0.2786 - val_loss: 1.8477 - val_acc: 0.2812\n",
      "Epoch 120/1000\n",
      "1152/1152 [==============================] - 1s 606us/step - loss: 1.8753 - acc: 0.2604 - val_loss: 1.8608 - val_acc: 0.2465\n",
      "Epoch 121/1000\n",
      "1152/1152 [==============================] - 1s 792us/step - loss: 1.8677 - acc: 0.2786 - val_loss: 1.8568 - val_acc: 0.2812\n",
      "Epoch 122/1000\n",
      "1152/1152 [==============================] - 1s 806us/step - loss: 1.8637 - acc: 0.2873 - val_loss: 1.8486 - val_acc: 0.2708\n",
      "Epoch 123/1000\n",
      "1152/1152 [==============================] - 1s 791us/step - loss: 1.8652 - acc: 0.2786 - val_loss: 1.8582 - val_acc: 0.2639\n",
      "Epoch 124/1000\n",
      "1152/1152 [==============================] - 1s 1ms/step - loss: 1.8687 - acc: 0.2769 - val_loss: 1.8499 - val_acc: 0.2847\n",
      "Epoch 125/1000\n",
      "1152/1152 [==============================] - 1s 577us/step - loss: 1.8597 - acc: 0.2769 - val_loss: 1.8497 - val_acc: 0.2882\n",
      "Epoch 126/1000\n",
      "1152/1152 [==============================] - 1s 704us/step - loss: 1.8573 - acc: 0.2839 - val_loss: 1.8460 - val_acc: 0.2535\n",
      "Epoch 127/1000\n",
      "1152/1152 [==============================] - 1s 862us/step - loss: 1.8542 - acc: 0.2786 - val_loss: 1.8432 - val_acc: 0.2951\n",
      "Epoch 128/1000\n",
      "1152/1152 [==============================] - 1s 942us/step - loss: 1.8667 - acc: 0.2743 - val_loss: 1.8480 - val_acc: 0.2708\n",
      "Epoch 129/1000\n",
      "1152/1152 [==============================] - 1s 674us/step - loss: 1.8568 - acc: 0.2839 - val_loss: 1.8506 - val_acc: 0.2882\n",
      "Epoch 130/1000\n",
      "1152/1152 [==============================] - 1s 665us/step - loss: 1.8498 - acc: 0.2830 - val_loss: 1.8441 - val_acc: 0.2812\n",
      "Epoch 131/1000\n",
      "1152/1152 [==============================] - 1s 816us/step - loss: 1.8465 - acc: 0.2830 - val_loss: 1.8427 - val_acc: 0.2882\n",
      "Epoch 132/1000\n",
      "1152/1152 [==============================] - 1s 998us/step - loss: 1.8602 - acc: 0.2769 - val_loss: 1.8513 - val_acc: 0.2986\n",
      "Epoch 133/1000\n",
      "1152/1152 [==============================] - 1s 606us/step - loss: 1.8592 - acc: 0.2786 - val_loss: 1.8454 - val_acc: 0.2812\n",
      "Epoch 134/1000\n",
      "1152/1152 [==============================] - 1s 600us/step - loss: 1.8529 - acc: 0.2812 - val_loss: 1.8507 - val_acc: 0.2674\n",
      "Epoch 135/1000\n",
      "1152/1152 [==============================] - 1s 694us/step - loss: 1.8587 - acc: 0.2726 - val_loss: 1.8568 - val_acc: 0.2569\n",
      "Epoch 136/1000\n",
      "1152/1152 [==============================] - 1s 687us/step - loss: 1.8549 - acc: 0.2839 - val_loss: 1.8415 - val_acc: 0.2639\n",
      "Epoch 137/1000\n",
      "1152/1152 [==============================] - 1s 502us/step - loss: 1.8603 - acc: 0.2726 - val_loss: 1.8396 - val_acc: 0.2778\n",
      "Epoch 138/1000\n",
      "1152/1152 [==============================] - 1s 523us/step - loss: 1.8489 - acc: 0.2804 - val_loss: 1.8451 - val_acc: 0.2951\n",
      "Epoch 139/1000\n",
      "1152/1152 [==============================] - 1s 557us/step - loss: 1.8451 - acc: 0.2786 - val_loss: 1.8400 - val_acc: 0.2847\n",
      "Epoch 140/1000\n",
      "1152/1152 [==============================] - 1s 565us/step - loss: 1.8506 - acc: 0.2873 - val_loss: 1.8394 - val_acc: 0.2812\n",
      "Epoch 141/1000\n",
      "1152/1152 [==============================] - 1s 446us/step - loss: 1.8552 - acc: 0.2804 - val_loss: 1.8467 - val_acc: 0.2708\n",
      "Epoch 142/1000\n",
      "1152/1152 [==============================] - 1s 566us/step - loss: 1.8531 - acc: 0.2908 - val_loss: 1.8389 - val_acc: 0.2917\n",
      "Epoch 143/1000\n",
      "1152/1152 [==============================] - 1s 545us/step - loss: 1.8494 - acc: 0.2839 - val_loss: 1.8433 - val_acc: 0.2882\n",
      "Epoch 144/1000\n",
      "1152/1152 [==============================] - 1s 800us/step - loss: 1.8395 - acc: 0.2812 - val_loss: 1.8316 - val_acc: 0.2743\n",
      "Epoch 145/1000\n",
      "1152/1152 [==============================] - 1s 671us/step - loss: 1.8486 - acc: 0.2760 - val_loss: 1.8372 - val_acc: 0.3056\n",
      "Epoch 146/1000\n",
      "1152/1152 [==============================] - 1s 550us/step - loss: 1.8500 - acc: 0.2804 - val_loss: 1.8461 - val_acc: 0.2535\n",
      "Epoch 147/1000\n",
      "1152/1152 [==============================] - 1s 559us/step - loss: 1.8514 - acc: 0.2882 - val_loss: 1.8328 - val_acc: 0.3056\n",
      "Epoch 148/1000\n",
      "1152/1152 [==============================] - 1s 929us/step - loss: 1.8568 - acc: 0.2830 - val_loss: 1.8381 - val_acc: 0.2639\n",
      "Epoch 149/1000\n",
      "1152/1152 [==============================] - 1s 552us/step - loss: 1.8512 - acc: 0.2865 - val_loss: 1.8371 - val_acc: 0.2812\n",
      "Epoch 150/1000\n",
      "1152/1152 [==============================] - 1s 539us/step - loss: 1.8358 - acc: 0.2873 - val_loss: 1.8429 - val_acc: 0.2882\n",
      "Epoch 151/1000\n",
      "1152/1152 [==============================] - 1s 543us/step - loss: 1.8456 - acc: 0.2899 - val_loss: 1.8372 - val_acc: 0.2778\n",
      "Epoch 152/1000\n",
      "1152/1152 [==============================] - 1s 530us/step - loss: 1.8448 - acc: 0.3021 - val_loss: 1.8288 - val_acc: 0.2986\n",
      "Epoch 153/1000\n",
      "1152/1152 [==============================] - 1s 488us/step - loss: 1.8364 - acc: 0.3056 - val_loss: 1.8346 - val_acc: 0.3090\n",
      "Epoch 154/1000\n",
      "1152/1152 [==============================] - 1s 541us/step - loss: 1.8377 - acc: 0.3030 - val_loss: 1.8412 - val_acc: 0.2743\n",
      "Epoch 155/1000\n",
      "1152/1152 [==============================] - 1s 538us/step - loss: 1.8453 - acc: 0.2995 - val_loss: 1.8291 - val_acc: 0.3125\n",
      "Epoch 156/1000\n",
      "1152/1152 [==============================] - 1s 541us/step - loss: 1.8408 - acc: 0.2899 - val_loss: 1.8317 - val_acc: 0.2882\n",
      "Epoch 157/1000\n",
      "1152/1152 [==============================] - 1s 533us/step - loss: 1.8432 - acc: 0.2873 - val_loss: 1.8332 - val_acc: 0.3056\n",
      "Epoch 158/1000\n",
      "1152/1152 [==============================] - 1s 529us/step - loss: 1.8371 - acc: 0.2821 - val_loss: 1.8284 - val_acc: 0.3299\n",
      "Epoch 159/1000\n",
      "1152/1152 [==============================] - 1s 529us/step - loss: 1.8345 - acc: 0.2786 - val_loss: 1.8338 - val_acc: 0.2708\n",
      "Epoch 160/1000\n",
      "1152/1152 [==============================] - 1s 503us/step - loss: 1.8300 - acc: 0.2917 - val_loss: 1.8274 - val_acc: 0.2951\n",
      "Epoch 161/1000\n",
      "1152/1152 [==============================] - 1s 571us/step - loss: 1.8366 - acc: 0.2934 - val_loss: 1.8285 - val_acc: 0.2917\n",
      "Epoch 162/1000\n",
      "1152/1152 [==============================] - 1s 558us/step - loss: 1.8360 - acc: 0.2995 - val_loss: 1.8352 - val_acc: 0.2743\n",
      "Epoch 163/1000\n",
      "1152/1152 [==============================] - 1s 701us/step - loss: 1.8322 - acc: 0.2847 - val_loss: 1.8245 - val_acc: 0.2917\n",
      "Epoch 164/1000\n",
      "1152/1152 [==============================] - 1s 588us/step - loss: 1.8357 - acc: 0.2943 - val_loss: 1.8247 - val_acc: 0.3090\n",
      "Epoch 165/1000\n",
      "1152/1152 [==============================] - 1s 485us/step - loss: 1.8388 - acc: 0.2812 - val_loss: 1.8272 - val_acc: 0.2917\n",
      "Epoch 166/1000\n",
      "1152/1152 [==============================] - 1s 627us/step - loss: 1.8326 - acc: 0.2977 - val_loss: 1.8348 - val_acc: 0.2639\n",
      "Epoch 167/1000\n",
      "1152/1152 [==============================] - 1s 666us/step - loss: 1.8315 - acc: 0.2812 - val_loss: 1.8323 - val_acc: 0.2986\n",
      "Epoch 168/1000\n",
      "1152/1152 [==============================] - 1s 535us/step - loss: 1.8331 - acc: 0.2891 - val_loss: 1.8300 - val_acc: 0.3056\n",
      "Epoch 169/1000\n",
      "1152/1152 [==============================] - 1s 550us/step - loss: 1.8176 - acc: 0.3038 - val_loss: 1.8261 - val_acc: 0.2917\n",
      "Epoch 170/1000\n",
      "1152/1152 [==============================] - 1s 562us/step - loss: 1.8316 - acc: 0.2804 - val_loss: 1.8330 - val_acc: 0.2812\n",
      "Epoch 171/1000\n",
      "1152/1152 [==============================] - 1s 540us/step - loss: 1.8364 - acc: 0.2899 - val_loss: 1.8224 - val_acc: 0.3056\n",
      "Epoch 172/1000\n",
      "1152/1152 [==============================] - 1s 628us/step - loss: 1.8281 - acc: 0.2986 - val_loss: 1.8286 - val_acc: 0.2986\n",
      "Epoch 173/1000\n",
      "1152/1152 [==============================] - 1s 538us/step - loss: 1.8290 - acc: 0.2882 - val_loss: 1.8212 - val_acc: 0.3021\n",
      "Epoch 174/1000\n",
      "1152/1152 [==============================] - 1s 554us/step - loss: 1.8243 - acc: 0.2847 - val_loss: 1.8249 - val_acc: 0.2882\n",
      "Epoch 175/1000\n",
      "1152/1152 [==============================] - 1s 567us/step - loss: 1.8237 - acc: 0.2943 - val_loss: 1.8223 - val_acc: 0.3021\n",
      "Epoch 176/1000\n",
      "1152/1152 [==============================] - 1s 544us/step - loss: 1.8261 - acc: 0.2760 - val_loss: 1.8249 - val_acc: 0.2951\n",
      "Epoch 177/1000\n",
      "1152/1152 [==============================] - 1s 549us/step - loss: 1.8274 - acc: 0.2847 - val_loss: 1.8214 - val_acc: 0.2951\n",
      "Epoch 178/1000\n",
      "1152/1152 [==============================] - 1s 564us/step - loss: 1.8228 - acc: 0.3021 - val_loss: 1.8214 - val_acc: 0.2951\n",
      "Epoch 179/1000\n",
      "1152/1152 [==============================] - 1s 561us/step - loss: 1.8243 - acc: 0.2821 - val_loss: 1.8232 - val_acc: 0.2882\n",
      "Epoch 180/1000\n",
      "1152/1152 [==============================] - 1s 572us/step - loss: 1.8208 - acc: 0.2951 - val_loss: 1.8287 - val_acc: 0.3160\n",
      "Epoch 181/1000\n",
      "1152/1152 [==============================] - 1s 569us/step - loss: 1.8130 - acc: 0.3073 - val_loss: 1.8186 - val_acc: 0.3021\n",
      "Epoch 182/1000\n",
      "1152/1152 [==============================] - 1s 565us/step - loss: 1.8117 - acc: 0.2865 - val_loss: 1.8171 - val_acc: 0.2778\n",
      "Epoch 183/1000\n",
      "1152/1152 [==============================] - 1s 645us/step - loss: 1.8222 - acc: 0.3073 - val_loss: 1.8159 - val_acc: 0.3160\n",
      "Epoch 184/1000\n",
      "1152/1152 [==============================] - 1s 796us/step - loss: 1.8240 - acc: 0.2960 - val_loss: 1.8151 - val_acc: 0.3229\n",
      "Epoch 185/1000\n",
      "1152/1152 [==============================] - 1s 630us/step - loss: 1.8140 - acc: 0.3134 - val_loss: 1.8186 - val_acc: 0.2986\n",
      "Epoch 186/1000\n",
      "1152/1152 [==============================] - 1s 542us/step - loss: 1.8164 - acc: 0.2865 - val_loss: 1.8169 - val_acc: 0.3125\n",
      "Epoch 187/1000\n",
      "1152/1152 [==============================] - 1s 586us/step - loss: 1.8221 - acc: 0.2951 - val_loss: 1.8265 - val_acc: 0.2917\n",
      "Epoch 188/1000\n",
      "1152/1152 [==============================] - 1s 580us/step - loss: 1.8145 - acc: 0.2856 - val_loss: 1.8116 - val_acc: 0.3160\n",
      "Epoch 189/1000\n",
      "1152/1152 [==============================] - 1s 500us/step - loss: 1.8109 - acc: 0.3134 - val_loss: 1.8138 - val_acc: 0.3021\n",
      "Epoch 190/1000\n",
      "1152/1152 [==============================] - 1s 567us/step - loss: 1.8114 - acc: 0.3003 - val_loss: 1.8187 - val_acc: 0.2986\n",
      "Epoch 191/1000\n",
      "1152/1152 [==============================] - 1s 519us/step - loss: 1.8051 - acc: 0.3186 - val_loss: 1.8191 - val_acc: 0.2882\n",
      "Epoch 192/1000\n",
      "1152/1152 [==============================] - 1s 528us/step - loss: 1.8130 - acc: 0.2995 - val_loss: 1.8111 - val_acc: 0.3056\n",
      "Epoch 193/1000\n",
      "1152/1152 [==============================] - 1s 527us/step - loss: 1.8138 - acc: 0.3064 - val_loss: 1.8097 - val_acc: 0.3056\n",
      "Epoch 194/1000\n",
      "1152/1152 [==============================] - 1s 545us/step - loss: 1.8100 - acc: 0.3012 - val_loss: 1.8231 - val_acc: 0.2812\n",
      "Epoch 195/1000\n",
      "1152/1152 [==============================] - 1s 679us/step - loss: 1.8133 - acc: 0.3082 - val_loss: 1.8259 - val_acc: 0.2708\n",
      "Epoch 196/1000\n",
      "1152/1152 [==============================] - 1s 544us/step - loss: 1.8081 - acc: 0.3003 - val_loss: 1.8134 - val_acc: 0.3160\n",
      "Epoch 197/1000\n",
      "1152/1152 [==============================] - 1s 584us/step - loss: 1.8092 - acc: 0.3116 - val_loss: 1.8084 - val_acc: 0.2917\n",
      "Epoch 198/1000\n",
      "1152/1152 [==============================] - 1s 547us/step - loss: 1.8037 - acc: 0.3142 - val_loss: 1.8124 - val_acc: 0.2882\n",
      "Epoch 199/1000\n",
      "1152/1152 [==============================] - 1s 585us/step - loss: 1.8113 - acc: 0.3047 - val_loss: 1.8070 - val_acc: 0.2986\n",
      "Epoch 200/1000\n",
      "1152/1152 [==============================] - 1s 584us/step - loss: 1.8129 - acc: 0.2891 - val_loss: 1.8082 - val_acc: 0.3299\n",
      "Epoch 201/1000\n",
      "1152/1152 [==============================] - 1s 619us/step - loss: 1.7960 - acc: 0.3264 - val_loss: 1.8146 - val_acc: 0.2917\n",
      "Epoch 202/1000\n",
      "1152/1152 [==============================] - 1s 562us/step - loss: 1.7978 - acc: 0.3064 - val_loss: 1.8199 - val_acc: 0.3125\n",
      "Epoch 203/1000\n",
      "1152/1152 [==============================] - 1s 603us/step - loss: 1.8032 - acc: 0.3108 - val_loss: 1.8127 - val_acc: 0.3056\n",
      "Epoch 204/1000\n",
      "1152/1152 [==============================] - 1s 655us/step - loss: 1.7965 - acc: 0.3047 - val_loss: 1.8104 - val_acc: 0.3229\n",
      "Epoch 205/1000\n",
      "1152/1152 [==============================] - 1s 622us/step - loss: 1.8023 - acc: 0.3160 - val_loss: 1.8102 - val_acc: 0.2951\n",
      "Epoch 206/1000\n",
      "1152/1152 [==============================] - 1s 688us/step - loss: 1.7906 - acc: 0.3030 - val_loss: 1.8126 - val_acc: 0.2917\n",
      "Epoch 207/1000\n",
      "1152/1152 [==============================] - 1s 567us/step - loss: 1.7937 - acc: 0.3073 - val_loss: 1.8033 - val_acc: 0.3368\n",
      "Epoch 208/1000\n",
      "1152/1152 [==============================] - 1s 593us/step - loss: 1.8027 - acc: 0.3194 - val_loss: 1.7976 - val_acc: 0.3229\n",
      "Epoch 209/1000\n",
      "1152/1152 [==============================] - 1s 729us/step - loss: 1.8022 - acc: 0.3099 - val_loss: 1.8060 - val_acc: 0.3021\n",
      "Epoch 210/1000\n",
      "1152/1152 [==============================] - 1s 787us/step - loss: 1.7989 - acc: 0.2891 - val_loss: 1.8041 - val_acc: 0.3299\n",
      "Epoch 211/1000\n",
      "1152/1152 [==============================] - 1s 870us/step - loss: 1.7993 - acc: 0.3264 - val_loss: 1.8100 - val_acc: 0.2986\n",
      "Epoch 212/1000\n",
      "1152/1152 [==============================] - 1s 927us/step - loss: 1.8014 - acc: 0.3099 - val_loss: 1.7982 - val_acc: 0.3194\n",
      "Epoch 213/1000\n",
      "1152/1152 [==============================] - 1s 748us/step - loss: 1.7863 - acc: 0.3255 - val_loss: 1.8035 - val_acc: 0.2951\n",
      "Epoch 214/1000\n",
      "1152/1152 [==============================] - 1s 572us/step - loss: 1.7998 - acc: 0.3194 - val_loss: 1.8079 - val_acc: 0.3056\n",
      "Epoch 215/1000\n",
      "1152/1152 [==============================] - 1s 802us/step - loss: 1.7939 - acc: 0.3003 - val_loss: 1.8038 - val_acc: 0.3125\n",
      "Epoch 216/1000\n",
      "1152/1152 [==============================] - 1s 882us/step - loss: 1.8051 - acc: 0.3142 - val_loss: 1.7983 - val_acc: 0.3194\n",
      "Epoch 217/1000\n",
      "1152/1152 [==============================] - 1s 609us/step - loss: 1.7867 - acc: 0.3177 - val_loss: 1.7930 - val_acc: 0.3264\n",
      "Epoch 218/1000\n",
      "1152/1152 [==============================] - 1s 760us/step - loss: 1.7950 - acc: 0.3255 - val_loss: 1.8034 - val_acc: 0.3160\n",
      "Epoch 219/1000\n",
      "1152/1152 [==============================] - 1s 721us/step - loss: 1.7854 - acc: 0.3255 - val_loss: 1.8062 - val_acc: 0.3194\n",
      "Epoch 220/1000\n",
      "1152/1152 [==============================] - 1s 669us/step - loss: 1.7969 - acc: 0.3160 - val_loss: 1.8124 - val_acc: 0.3125\n",
      "Epoch 221/1000\n",
      "1152/1152 [==============================] - 1s 845us/step - loss: 1.8020 - acc: 0.2995 - val_loss: 1.7988 - val_acc: 0.3160\n",
      "Epoch 222/1000\n",
      "1152/1152 [==============================] - 1s 670us/step - loss: 1.7889 - acc: 0.3316 - val_loss: 1.8009 - val_acc: 0.3472\n",
      "Epoch 223/1000\n",
      "1152/1152 [==============================] - 1s 763us/step - loss: 1.7949 - acc: 0.3056 - val_loss: 1.7932 - val_acc: 0.3299\n",
      "Epoch 224/1000\n",
      "1152/1152 [==============================] - 1s 541us/step - loss: 1.7867 - acc: 0.3030 - val_loss: 1.7930 - val_acc: 0.3160\n",
      "Epoch 225/1000\n",
      "1152/1152 [==============================] - 1s 711us/step - loss: 1.7828 - acc: 0.3299 - val_loss: 1.8064 - val_acc: 0.2951\n",
      "Epoch 226/1000\n",
      "1152/1152 [==============================] - 1s 741us/step - loss: 1.7889 - acc: 0.3238 - val_loss: 1.7984 - val_acc: 0.3194\n",
      "Epoch 227/1000\n",
      "1152/1152 [==============================] - 1s 695us/step - loss: 1.7918 - acc: 0.3194 - val_loss: 1.7902 - val_acc: 0.3403\n",
      "Epoch 228/1000\n",
      "1152/1152 [==============================] - 1s 533us/step - loss: 1.7860 - acc: 0.3056 - val_loss: 1.7942 - val_acc: 0.3333\n",
      "Epoch 229/1000\n",
      "1152/1152 [==============================] - 1s 912us/step - loss: 1.7818 - acc: 0.3281 - val_loss: 1.7919 - val_acc: 0.3403\n",
      "Epoch 230/1000\n",
      "1152/1152 [==============================] - 1s 922us/step - loss: 1.7914 - acc: 0.3030 - val_loss: 1.7931 - val_acc: 0.3194\n",
      "Epoch 231/1000\n",
      "1152/1152 [==============================] - 1s 508us/step - loss: 1.7829 - acc: 0.3238 - val_loss: 1.7914 - val_acc: 0.3507\n",
      "Epoch 232/1000\n",
      "1152/1152 [==============================] - 1s 780us/step - loss: 1.7943 - acc: 0.3125 - val_loss: 1.7972 - val_acc: 0.2986\n",
      "Epoch 233/1000\n",
      "1152/1152 [==============================] - 1s 884us/step - loss: 1.7766 - acc: 0.3281 - val_loss: 1.7931 - val_acc: 0.3125\n",
      "Epoch 234/1000\n",
      "1152/1152 [==============================] - 1s 820us/step - loss: 1.7766 - acc: 0.3099 - val_loss: 1.7967 - val_acc: 0.2986\n",
      "Epoch 235/1000\n",
      "1152/1152 [==============================] - 1s 822us/step - loss: 1.7862 - acc: 0.3082 - val_loss: 1.7978 - val_acc: 0.3160\n",
      "Epoch 236/1000\n",
      "1152/1152 [==============================] - 1s 690us/step - loss: 1.7804 - acc: 0.3333 - val_loss: 1.7886 - val_acc: 0.3507\n",
      "Epoch 237/1000\n",
      "1152/1152 [==============================] - 1s 612us/step - loss: 1.7703 - acc: 0.3359 - val_loss: 1.7974 - val_acc: 0.3090\n",
      "Epoch 238/1000\n",
      "1152/1152 [==============================] - 1s 770us/step - loss: 1.7743 - acc: 0.3342 - val_loss: 1.7931 - val_acc: 0.3194\n",
      "Epoch 239/1000\n",
      "1152/1152 [==============================] - 1s 706us/step - loss: 1.7757 - acc: 0.3212 - val_loss: 1.7879 - val_acc: 0.3368\n",
      "Epoch 240/1000\n",
      "1152/1152 [==============================] - 1s 573us/step - loss: 1.7732 - acc: 0.3438 - val_loss: 1.7833 - val_acc: 0.3090\n",
      "Epoch 241/1000\n",
      "1152/1152 [==============================] - 1s 867us/step - loss: 1.7634 - acc: 0.3255 - val_loss: 1.7871 - val_acc: 0.3194\n",
      "Epoch 242/1000\n",
      "1152/1152 [==============================] - 1s 749us/step - loss: 1.7711 - acc: 0.3385 - val_loss: 1.7912 - val_acc: 0.3299\n",
      "Epoch 243/1000\n",
      "1152/1152 [==============================] - 1s 839us/step - loss: 1.7741 - acc: 0.3290 - val_loss: 1.7989 - val_acc: 0.2882\n",
      "Epoch 244/1000\n",
      "1152/1152 [==============================] - 1s 752us/step - loss: 1.7820 - acc: 0.3290 - val_loss: 1.7902 - val_acc: 0.3160\n",
      "Epoch 245/1000\n",
      "1152/1152 [==============================] - 1s 650us/step - loss: 1.7695 - acc: 0.3281 - val_loss: 1.7843 - val_acc: 0.3507\n",
      "Epoch 246/1000\n",
      "1152/1152 [==============================] - 1s 620us/step - loss: 1.7699 - acc: 0.3194 - val_loss: 1.7875 - val_acc: 0.3125\n",
      "Epoch 247/1000\n",
      "1152/1152 [==============================] - 1s 566us/step - loss: 1.7714 - acc: 0.3299 - val_loss: 1.7876 - val_acc: 0.3333\n",
      "Epoch 248/1000\n",
      "1152/1152 [==============================] - 1s 589us/step - loss: 1.7683 - acc: 0.3264 - val_loss: 1.7929 - val_acc: 0.3056\n",
      "Epoch 249/1000\n",
      "1152/1152 [==============================] - 1s 618us/step - loss: 1.7762 - acc: 0.3255 - val_loss: 1.8031 - val_acc: 0.2708\n",
      "Epoch 250/1000\n",
      "1152/1152 [==============================] - 1s 493us/step - loss: 1.7744 - acc: 0.3290 - val_loss: 1.7973 - val_acc: 0.3194\n",
      "Epoch 251/1000\n",
      "1152/1152 [==============================] - 1s 597us/step - loss: 1.7723 - acc: 0.3238 - val_loss: 1.7840 - val_acc: 0.3194\n",
      "Epoch 252/1000\n",
      "1152/1152 [==============================] - 1s 617us/step - loss: 1.7598 - acc: 0.3472 - val_loss: 1.7907 - val_acc: 0.3021\n",
      "Epoch 253/1000\n",
      "1152/1152 [==============================] - 1s 912us/step - loss: 1.7638 - acc: 0.3299 - val_loss: 1.7922 - val_acc: 0.3056\n",
      "Epoch 254/1000\n",
      "1152/1152 [==============================] - 1s 790us/step - loss: 1.7645 - acc: 0.3247 - val_loss: 1.7818 - val_acc: 0.3125\n",
      "Epoch 255/1000\n",
      "1152/1152 [==============================] - 1s 760us/step - loss: 1.7631 - acc: 0.3108 - val_loss: 1.7921 - val_acc: 0.3368\n",
      "Epoch 256/1000\n",
      "1152/1152 [==============================] - 1s 563us/step - loss: 1.7688 - acc: 0.3351 - val_loss: 1.7826 - val_acc: 0.3021\n",
      "Epoch 257/1000\n",
      "1152/1152 [==============================] - 1s 709us/step - loss: 1.7616 - acc: 0.3464 - val_loss: 1.7942 - val_acc: 0.2986\n",
      "Epoch 258/1000\n",
      "1152/1152 [==============================] - 1s 593us/step - loss: 1.7736 - acc: 0.3281 - val_loss: 1.7848 - val_acc: 0.3160\n",
      "Epoch 259/1000\n",
      "1152/1152 [==============================] - 1s 596us/step - loss: 1.7527 - acc: 0.3255 - val_loss: 1.7835 - val_acc: 0.3299\n",
      "Epoch 260/1000\n",
      "1152/1152 [==============================] - 1s 627us/step - loss: 1.7492 - acc: 0.3472 - val_loss: 1.7918 - val_acc: 0.3194\n",
      "Epoch 261/1000\n",
      "1152/1152 [==============================] - 1s 629us/step - loss: 1.7662 - acc: 0.3342 - val_loss: 1.7822 - val_acc: 0.3021\n",
      "Epoch 262/1000\n",
      "1152/1152 [==============================] - 1s 609us/step - loss: 1.7648 - acc: 0.3290 - val_loss: 1.7752 - val_acc: 0.3472\n",
      "Epoch 263/1000\n",
      "1152/1152 [==============================] - 1s 622us/step - loss: 1.7582 - acc: 0.3368 - val_loss: 1.7766 - val_acc: 0.3472\n",
      "Epoch 264/1000\n",
      "1152/1152 [==============================] - 1s 622us/step - loss: 1.7615 - acc: 0.3394 - val_loss: 1.7721 - val_acc: 0.3438\n",
      "Epoch 265/1000\n",
      "1152/1152 [==============================] - 1s 606us/step - loss: 1.7635 - acc: 0.3316 - val_loss: 1.7865 - val_acc: 0.3194\n",
      "Epoch 266/1000\n",
      "1152/1152 [==============================] - 1s 644us/step - loss: 1.7614 - acc: 0.3247 - val_loss: 1.7772 - val_acc: 0.3368\n",
      "Epoch 267/1000\n",
      "1152/1152 [==============================] - 1s 629us/step - loss: 1.7575 - acc: 0.3359 - val_loss: 1.7725 - val_acc: 0.3438\n",
      "Epoch 268/1000\n",
      "1152/1152 [==============================] - 1s 619us/step - loss: 1.7561 - acc: 0.3299 - val_loss: 1.7692 - val_acc: 0.3472\n",
      "Epoch 269/1000\n",
      "1152/1152 [==============================] - 1s 606us/step - loss: 1.7646 - acc: 0.3281 - val_loss: 1.7867 - val_acc: 0.3090\n",
      "Epoch 270/1000\n",
      "1152/1152 [==============================] - 1s 696us/step - loss: 1.7493 - acc: 0.3438 - val_loss: 1.7793 - val_acc: 0.3090\n",
      "Epoch 271/1000\n",
      "1152/1152 [==============================] - 1s 637us/step - loss: 1.7504 - acc: 0.3429 - val_loss: 1.7733 - val_acc: 0.3125\n",
      "Epoch 272/1000\n",
      "1152/1152 [==============================] - 1s 648us/step - loss: 1.7596 - acc: 0.3403 - val_loss: 1.7736 - val_acc: 0.3472\n",
      "Epoch 273/1000\n",
      "1152/1152 [==============================] - 1s 624us/step - loss: 1.7561 - acc: 0.3273 - val_loss: 1.7681 - val_acc: 0.3403\n",
      "Epoch 274/1000\n",
      "1152/1152 [==============================] - 1s 733us/step - loss: 1.7507 - acc: 0.3307 - val_loss: 1.7774 - val_acc: 0.3264\n",
      "Epoch 275/1000\n",
      "1152/1152 [==============================] - 1s 751us/step - loss: 1.7454 - acc: 0.3403 - val_loss: 1.7695 - val_acc: 0.3299\n",
      "Epoch 276/1000\n",
      "1152/1152 [==============================] - 1s 754us/step - loss: 1.7578 - acc: 0.3385 - val_loss: 1.7772 - val_acc: 0.3403\n",
      "Epoch 277/1000\n",
      "1152/1152 [==============================] - 1s 607us/step - loss: 1.7434 - acc: 0.3394 - val_loss: 1.7678 - val_acc: 0.3333\n",
      "Epoch 278/1000\n",
      "1152/1152 [==============================] - 1s 629us/step - loss: 1.7558 - acc: 0.3429 - val_loss: 1.7765 - val_acc: 0.3368\n",
      "Epoch 279/1000\n",
      "1152/1152 [==============================] - 1s 845us/step - loss: 1.7470 - acc: 0.3385 - val_loss: 1.7712 - val_acc: 0.3125\n",
      "Epoch 280/1000\n",
      "1152/1152 [==============================] - 1s 667us/step - loss: 1.7470 - acc: 0.3411 - val_loss: 1.7808 - val_acc: 0.3090\n",
      "Epoch 281/1000\n",
      "1152/1152 [==============================] - 1s 737us/step - loss: 1.7414 - acc: 0.3420 - val_loss: 1.7767 - val_acc: 0.3056\n",
      "Epoch 282/1000\n",
      "1152/1152 [==============================] - 1s 864us/step - loss: 1.7503 - acc: 0.3342 - val_loss: 1.7578 - val_acc: 0.3264\n",
      "Epoch 283/1000\n",
      "1152/1152 [==============================] - 1s 665us/step - loss: 1.7469 - acc: 0.3255 - val_loss: 1.7710 - val_acc: 0.3403\n",
      "Epoch 284/1000\n",
      "1152/1152 [==============================] - 1s 745us/step - loss: 1.7468 - acc: 0.3377 - val_loss: 1.7904 - val_acc: 0.3090\n",
      "Epoch 285/1000\n",
      "1152/1152 [==============================] - 1s 520us/step - loss: 1.7438 - acc: 0.3194 - val_loss: 1.7646 - val_acc: 0.3403\n",
      "Epoch 286/1000\n",
      "1152/1152 [==============================] - 1s 830us/step - loss: 1.7371 - acc: 0.3438 - val_loss: 1.7723 - val_acc: 0.3403\n",
      "Epoch 287/1000\n",
      "1152/1152 [==============================] - 1s 647us/step - loss: 1.7381 - acc: 0.3516 - val_loss: 1.7672 - val_acc: 0.3368\n",
      "Epoch 288/1000\n",
      "1152/1152 [==============================] - 1s 708us/step - loss: 1.7335 - acc: 0.3602 - val_loss: 1.7691 - val_acc: 0.3160\n",
      "Epoch 289/1000\n",
      "1152/1152 [==============================] - 1s 668us/step - loss: 1.7362 - acc: 0.3481 - val_loss: 1.7613 - val_acc: 0.3299\n",
      "Epoch 290/1000\n",
      "1152/1152 [==============================] - 1s 608us/step - loss: 1.7422 - acc: 0.3411 - val_loss: 1.7653 - val_acc: 0.3194\n",
      "Epoch 291/1000\n",
      "1152/1152 [==============================] - 1s 579us/step - loss: 1.7407 - acc: 0.3420 - val_loss: 1.7669 - val_acc: 0.3333\n",
      "Epoch 292/1000\n",
      "1152/1152 [==============================] - 1s 500us/step - loss: 1.7222 - acc: 0.3542 - val_loss: 1.7680 - val_acc: 0.3021\n",
      "Epoch 293/1000\n",
      "1152/1152 [==============================] - 1s 784us/step - loss: 1.7432 - acc: 0.3472 - val_loss: 1.7667 - val_acc: 0.3507\n",
      "Epoch 294/1000\n",
      "1152/1152 [==============================] - 1s 802us/step - loss: 1.7389 - acc: 0.3333 - val_loss: 1.7699 - val_acc: 0.3090\n",
      "Epoch 295/1000\n",
      "1152/1152 [==============================] - 1s 722us/step - loss: 1.7339 - acc: 0.3351 - val_loss: 1.7598 - val_acc: 0.3507\n",
      "Epoch 296/1000\n",
      "1152/1152 [==============================] - 1s 545us/step - loss: 1.7353 - acc: 0.3281 - val_loss: 1.7571 - val_acc: 0.3264\n",
      "Epoch 297/1000\n",
      "1152/1152 [==============================] - 1s 553us/step - loss: 1.7354 - acc: 0.3559 - val_loss: 1.7733 - val_acc: 0.3229\n",
      "Epoch 298/1000\n",
      "1152/1152 [==============================] - 1s 525us/step - loss: 1.7315 - acc: 0.3385 - val_loss: 1.7687 - val_acc: 0.3125\n",
      "Epoch 299/1000\n",
      "1152/1152 [==============================] - 1s 498us/step - loss: 1.7367 - acc: 0.3316 - val_loss: 1.7621 - val_acc: 0.3507\n",
      "Epoch 300/1000\n",
      "1152/1152 [==============================] - 1s 534us/step - loss: 1.7409 - acc: 0.3420 - val_loss: 1.7679 - val_acc: 0.3299\n",
      "Epoch 301/1000\n",
      "1152/1152 [==============================] - 1s 534us/step - loss: 1.7340 - acc: 0.3542 - val_loss: 1.7560 - val_acc: 0.3438\n",
      "Epoch 302/1000\n",
      "1152/1152 [==============================] - 1s 525us/step - loss: 1.7302 - acc: 0.3550 - val_loss: 1.7683 - val_acc: 0.3125\n",
      "Epoch 303/1000\n",
      "1152/1152 [==============================] - 1s 529us/step - loss: 1.7282 - acc: 0.3411 - val_loss: 1.7563 - val_acc: 0.3403\n",
      "Epoch 304/1000\n",
      "1152/1152 [==============================] - 1s 519us/step - loss: 1.7213 - acc: 0.3498 - val_loss: 1.7689 - val_acc: 0.3264\n",
      "Epoch 305/1000\n",
      "1152/1152 [==============================] - 1s 790us/step - loss: 1.7271 - acc: 0.3533 - val_loss: 1.7581 - val_acc: 0.3611\n",
      "Epoch 306/1000\n",
      "1152/1152 [==============================] - 1s 724us/step - loss: 1.7230 - acc: 0.3516 - val_loss: 1.7642 - val_acc: 0.3368\n",
      "Epoch 307/1000\n",
      "1152/1152 [==============================] - 1s 522us/step - loss: 1.7288 - acc: 0.3559 - val_loss: 1.7589 - val_acc: 0.3368\n",
      "Epoch 308/1000\n",
      "1152/1152 [==============================] - 1s 609us/step - loss: 1.7318 - acc: 0.3576 - val_loss: 1.7499 - val_acc: 0.3611\n",
      "Epoch 309/1000\n",
      "1152/1152 [==============================] - 1s 589us/step - loss: 1.7236 - acc: 0.3602 - val_loss: 1.7592 - val_acc: 0.3299\n",
      "Epoch 310/1000\n",
      "1152/1152 [==============================] - 1s 911us/step - loss: 1.7284 - acc: 0.3576 - val_loss: 1.7598 - val_acc: 0.3403\n",
      "Epoch 311/1000\n",
      "1152/1152 [==============================] - 1s 833us/step - loss: 1.7228 - acc: 0.3594 - val_loss: 1.7623 - val_acc: 0.3611\n",
      "Epoch 312/1000\n",
      "1152/1152 [==============================] - 1s 725us/step - loss: 1.7269 - acc: 0.3637 - val_loss: 1.7568 - val_acc: 0.3333\n",
      "Epoch 313/1000\n",
      "1152/1152 [==============================] - 1s 660us/step - loss: 1.7187 - acc: 0.3507 - val_loss: 1.7549 - val_acc: 0.3403\n",
      "Epoch 314/1000\n",
      "1152/1152 [==============================] - 1s 650us/step - loss: 1.7223 - acc: 0.3542 - val_loss: 1.7553 - val_acc: 0.3056\n",
      "Epoch 315/1000\n",
      "1152/1152 [==============================] - 1s 716us/step - loss: 1.7098 - acc: 0.3681 - val_loss: 1.7532 - val_acc: 0.3507\n",
      "Epoch 316/1000\n",
      "1152/1152 [==============================] - 1s 645us/step - loss: 1.7231 - acc: 0.3403 - val_loss: 1.7550 - val_acc: 0.3368\n",
      "Epoch 317/1000\n",
      "1152/1152 [==============================] - 1s 659us/step - loss: 1.7148 - acc: 0.3481 - val_loss: 1.7563 - val_acc: 0.3299\n",
      "Epoch 318/1000\n",
      "1152/1152 [==============================] - 1s 683us/step - loss: 1.7144 - acc: 0.3628 - val_loss: 1.7423 - val_acc: 0.3576\n",
      "Epoch 319/1000\n",
      "1152/1152 [==============================] - 1s 658us/step - loss: 1.7243 - acc: 0.3420 - val_loss: 1.7532 - val_acc: 0.3403\n",
      "Epoch 320/1000\n",
      "1152/1152 [==============================] - 1s 680us/step - loss: 1.7226 - acc: 0.3637 - val_loss: 1.7560 - val_acc: 0.3507\n",
      "Epoch 321/1000\n",
      "1152/1152 [==============================] - 1s 706us/step - loss: 1.7084 - acc: 0.3689 - val_loss: 1.7496 - val_acc: 0.3507\n",
      "Epoch 322/1000\n",
      "1152/1152 [==============================] - 1s 707us/step - loss: 1.7217 - acc: 0.3524 - val_loss: 1.7519 - val_acc: 0.3299\n",
      "Epoch 323/1000\n",
      "1152/1152 [==============================] - 1s 765us/step - loss: 1.7098 - acc: 0.3481 - val_loss: 1.7369 - val_acc: 0.3507\n",
      "Epoch 324/1000\n",
      "1152/1152 [==============================] - 1s 742us/step - loss: 1.7076 - acc: 0.3785 - val_loss: 1.7663 - val_acc: 0.3090\n",
      "Epoch 325/1000\n",
      "1152/1152 [==============================] - 1s 780us/step - loss: 1.7109 - acc: 0.3533 - val_loss: 1.7431 - val_acc: 0.3299\n",
      "Epoch 326/1000\n",
      "1152/1152 [==============================] - 1s 747us/step - loss: 1.7148 - acc: 0.3602 - val_loss: 1.7517 - val_acc: 0.3507\n",
      "Epoch 327/1000\n",
      "1152/1152 [==============================] - 1s 744us/step - loss: 1.7121 - acc: 0.3663 - val_loss: 1.7553 - val_acc: 0.3438\n",
      "Epoch 328/1000\n",
      "1152/1152 [==============================] - 1s 647us/step - loss: 1.7102 - acc: 0.3568 - val_loss: 1.7554 - val_acc: 0.3299\n",
      "Epoch 329/1000\n",
      "1152/1152 [==============================] - 1s 707us/step - loss: 1.7034 - acc: 0.3655 - val_loss: 1.7462 - val_acc: 0.3264\n",
      "Epoch 330/1000\n",
      "1152/1152 [==============================] - 1s 720us/step - loss: 1.7121 - acc: 0.3516 - val_loss: 1.7430 - val_acc: 0.3472\n",
      "Epoch 331/1000\n",
      "1152/1152 [==============================] - 1s 751us/step - loss: 1.7093 - acc: 0.3568 - val_loss: 1.7453 - val_acc: 0.3646\n",
      "Epoch 332/1000\n",
      "1152/1152 [==============================] - 1s 847us/step - loss: 1.7086 - acc: 0.3550 - val_loss: 1.7474 - val_acc: 0.3403\n",
      "Epoch 333/1000\n",
      "1152/1152 [==============================] - 1s 652us/step - loss: 1.7147 - acc: 0.3602 - val_loss: 1.7487 - val_acc: 0.3264\n",
      "Epoch 334/1000\n",
      "1152/1152 [==============================] - 1s 764us/step - loss: 1.7044 - acc: 0.3594 - val_loss: 1.7415 - val_acc: 0.3438\n",
      "Epoch 335/1000\n",
      "1152/1152 [==============================] - 1s 708us/step - loss: 1.7001 - acc: 0.3793 - val_loss: 1.7426 - val_acc: 0.3472\n",
      "Epoch 336/1000\n",
      "1152/1152 [==============================] - 1s 751us/step - loss: 1.7008 - acc: 0.3602 - val_loss: 1.7496 - val_acc: 0.3472\n",
      "Epoch 337/1000\n",
      "1152/1152 [==============================] - 1s 751us/step - loss: 1.7061 - acc: 0.3385 - val_loss: 1.7424 - val_acc: 0.3611\n",
      "Epoch 338/1000\n",
      "1152/1152 [==============================] - 1s 771us/step - loss: 1.7103 - acc: 0.3481 - val_loss: 1.7483 - val_acc: 0.3507\n",
      "Epoch 339/1000\n",
      "1152/1152 [==============================] - 1s 725us/step - loss: 1.7027 - acc: 0.3724 - val_loss: 1.7439 - val_acc: 0.3299\n",
      "Epoch 340/1000\n",
      "1152/1152 [==============================] - 1s 745us/step - loss: 1.7134 - acc: 0.3611 - val_loss: 1.7395 - val_acc: 0.3507\n",
      "Epoch 341/1000\n",
      "1152/1152 [==============================] - 1s 731us/step - loss: 1.6995 - acc: 0.3707 - val_loss: 1.7451 - val_acc: 0.3403\n",
      "Epoch 342/1000\n",
      "1152/1152 [==============================] - 1s 686us/step - loss: 1.6967 - acc: 0.3741 - val_loss: 1.7355 - val_acc: 0.3403\n",
      "Epoch 343/1000\n",
      "1152/1152 [==============================] - 1s 707us/step - loss: 1.7054 - acc: 0.3542 - val_loss: 1.7357 - val_acc: 0.3507\n",
      "Epoch 344/1000\n",
      "1152/1152 [==============================] - 1s 710us/step - loss: 1.7077 - acc: 0.3550 - val_loss: 1.7491 - val_acc: 0.3194\n",
      "Epoch 345/1000\n",
      "1152/1152 [==============================] - 1s 707us/step - loss: 1.6930 - acc: 0.3689 - val_loss: 1.7359 - val_acc: 0.3542\n",
      "Epoch 346/1000\n",
      "1152/1152 [==============================] - 1s 694us/step - loss: 1.6903 - acc: 0.3741 - val_loss: 1.7464 - val_acc: 0.3299\n",
      "Epoch 347/1000\n",
      "1152/1152 [==============================] - 1s 710us/step - loss: 1.6958 - acc: 0.3750 - val_loss: 1.7415 - val_acc: 0.3542\n",
      "Epoch 348/1000\n",
      "1152/1152 [==============================] - 1s 708us/step - loss: 1.6884 - acc: 0.3733 - val_loss: 1.7488 - val_acc: 0.3333\n",
      "Epoch 349/1000\n",
      "1152/1152 [==============================] - 1s 681us/step - loss: 1.6902 - acc: 0.3698 - val_loss: 1.7430 - val_acc: 0.3507\n",
      "Epoch 350/1000\n",
      "1152/1152 [==============================] - 1s 737us/step - loss: 1.6956 - acc: 0.3750 - val_loss: 1.7385 - val_acc: 0.3576\n",
      "Epoch 351/1000\n",
      "1152/1152 [==============================] - 1s 786us/step - loss: 1.6967 - acc: 0.3741 - val_loss: 1.7367 - val_acc: 0.3611\n",
      "Epoch 352/1000\n",
      "1152/1152 [==============================] - 1s 624us/step - loss: 1.6871 - acc: 0.3646 - val_loss: 1.7348 - val_acc: 0.3715\n",
      "Epoch 353/1000\n",
      "1152/1152 [==============================] - 1s 688us/step - loss: 1.6932 - acc: 0.3776 - val_loss: 1.7413 - val_acc: 0.3507\n",
      "Epoch 354/1000\n",
      "1152/1152 [==============================] - 1s 719us/step - loss: 1.6892 - acc: 0.3828 - val_loss: 1.7353 - val_acc: 0.3368\n",
      "Epoch 355/1000\n",
      "1152/1152 [==============================] - 1s 740us/step - loss: 1.6985 - acc: 0.3637 - val_loss: 1.7429 - val_acc: 0.3368\n",
      "Epoch 356/1000\n",
      "1152/1152 [==============================] - 1s 659us/step - loss: 1.6987 - acc: 0.3672 - val_loss: 1.7332 - val_acc: 0.3646\n",
      "Epoch 357/1000\n",
      "1152/1152 [==============================] - 1s 732us/step - loss: 1.6858 - acc: 0.3802 - val_loss: 1.7280 - val_acc: 0.3438\n",
      "Epoch 358/1000\n",
      "1152/1152 [==============================] - 1s 716us/step - loss: 1.6840 - acc: 0.3793 - val_loss: 1.7418 - val_acc: 0.3368\n",
      "Epoch 359/1000\n",
      "1152/1152 [==============================] - 1s 747us/step - loss: 1.6820 - acc: 0.3845 - val_loss: 1.7294 - val_acc: 0.3611\n",
      "Epoch 360/1000\n",
      "1152/1152 [==============================] - 1s 694us/step - loss: 1.6810 - acc: 0.3733 - val_loss: 1.7361 - val_acc: 0.3542\n",
      "Epoch 361/1000\n",
      "1152/1152 [==============================] - 1s 734us/step - loss: 1.6920 - acc: 0.3733 - val_loss: 1.7253 - val_acc: 0.3542\n",
      "Epoch 362/1000\n",
      "1152/1152 [==============================] - 1s 777us/step - loss: 1.6957 - acc: 0.3637 - val_loss: 1.7298 - val_acc: 0.3576\n",
      "Epoch 363/1000\n",
      "1152/1152 [==============================] - 1s 699us/step - loss: 1.6947 - acc: 0.3620 - val_loss: 1.7351 - val_acc: 0.3403\n",
      "Epoch 364/1000\n",
      "1152/1152 [==============================] - 1s 754us/step - loss: 1.6866 - acc: 0.3698 - val_loss: 1.7248 - val_acc: 0.3472\n",
      "Epoch 365/1000\n",
      "1152/1152 [==============================] - 1s 723us/step - loss: 1.6802 - acc: 0.3663 - val_loss: 1.7254 - val_acc: 0.3681\n",
      "Epoch 366/1000\n",
      "1152/1152 [==============================] - 1s 652us/step - loss: 1.6842 - acc: 0.3715 - val_loss: 1.7269 - val_acc: 0.3681\n",
      "Epoch 367/1000\n",
      "1152/1152 [==============================] - 1s 608us/step - loss: 1.6774 - acc: 0.3828 - val_loss: 1.7214 - val_acc: 0.3472\n",
      "Epoch 368/1000\n",
      "1152/1152 [==============================] - 1s 553us/step - loss: 1.6907 - acc: 0.3750 - val_loss: 1.7483 - val_acc: 0.3229\n",
      "Epoch 369/1000\n",
      "1152/1152 [==============================] - 1s 650us/step - loss: 1.6982 - acc: 0.3767 - val_loss: 1.7243 - val_acc: 0.3611\n",
      "Epoch 370/1000\n",
      "1152/1152 [==============================] - 1s 710us/step - loss: 1.6840 - acc: 0.3698 - val_loss: 1.7255 - val_acc: 0.3542\n",
      "Epoch 371/1000\n",
      "1152/1152 [==============================] - 1s 628us/step - loss: 1.6720 - acc: 0.3863 - val_loss: 1.7164 - val_acc: 0.3507\n",
      "Epoch 372/1000\n",
      "1152/1152 [==============================] - 1s 559us/step - loss: 1.6816 - acc: 0.3724 - val_loss: 1.7310 - val_acc: 0.3611\n",
      "Epoch 373/1000\n",
      "1152/1152 [==============================] - 1s 562us/step - loss: 1.6736 - acc: 0.3759 - val_loss: 1.7314 - val_acc: 0.3611\n",
      "Epoch 374/1000\n",
      "1152/1152 [==============================] - 1s 552us/step - loss: 1.6686 - acc: 0.3741 - val_loss: 1.7211 - val_acc: 0.3576\n",
      "Epoch 375/1000\n",
      "1152/1152 [==============================] - 1s 561us/step - loss: 1.6750 - acc: 0.3889 - val_loss: 1.7237 - val_acc: 0.3542\n",
      "Epoch 376/1000\n",
      "1152/1152 [==============================] - 1s 581us/step - loss: 1.6837 - acc: 0.3802 - val_loss: 1.7160 - val_acc: 0.3611\n",
      "Epoch 377/1000\n",
      "1152/1152 [==============================] - 1s 558us/step - loss: 1.6594 - acc: 0.3863 - val_loss: 1.7263 - val_acc: 0.3715\n",
      "Epoch 378/1000\n",
      "1152/1152 [==============================] - 1s 625us/step - loss: 1.6712 - acc: 0.3741 - val_loss: 1.7258 - val_acc: 0.3472\n",
      "Epoch 379/1000\n",
      "1152/1152 [==============================] - 1s 590us/step - loss: 1.6799 - acc: 0.3698 - val_loss: 1.7293 - val_acc: 0.3333\n",
      "Epoch 380/1000\n",
      "1152/1152 [==============================] - 1s 560us/step - loss: 1.6721 - acc: 0.3707 - val_loss: 1.7226 - val_acc: 0.3542\n",
      "Epoch 381/1000\n",
      "1152/1152 [==============================] - 1s 553us/step - loss: 1.6713 - acc: 0.3724 - val_loss: 1.7152 - val_acc: 0.3646\n",
      "Epoch 382/1000\n",
      "1152/1152 [==============================] - 1s 550us/step - loss: 1.6596 - acc: 0.3811 - val_loss: 1.7332 - val_acc: 0.3403\n",
      "Epoch 383/1000\n",
      "1152/1152 [==============================] - 1s 586us/step - loss: 1.6660 - acc: 0.3845 - val_loss: 1.7264 - val_acc: 0.3576\n",
      "Epoch 384/1000\n",
      "1152/1152 [==============================] - 1s 625us/step - loss: 1.6705 - acc: 0.3802 - val_loss: 1.7193 - val_acc: 0.3542\n",
      "Epoch 385/1000\n",
      "1152/1152 [==============================] - 1s 571us/step - loss: 1.6643 - acc: 0.3715 - val_loss: 1.7103 - val_acc: 0.3542\n",
      "Epoch 386/1000\n",
      "1152/1152 [==============================] - 1s 594us/step - loss: 1.6619 - acc: 0.3872 - val_loss: 1.7258 - val_acc: 0.3264\n",
      "Epoch 387/1000\n",
      "1152/1152 [==============================] - 1s 606us/step - loss: 1.6751 - acc: 0.3594 - val_loss: 1.7211 - val_acc: 0.3472\n",
      "Epoch 388/1000\n",
      "1152/1152 [==============================] - 1s 607us/step - loss: 1.6564 - acc: 0.3898 - val_loss: 1.7160 - val_acc: 0.3542\n",
      "Epoch 389/1000\n",
      "1152/1152 [==============================] - 1s 616us/step - loss: 1.6666 - acc: 0.3733 - val_loss: 1.7115 - val_acc: 0.3472\n",
      "Epoch 390/1000\n",
      "1152/1152 [==============================] - 1s 745us/step - loss: 1.6700 - acc: 0.3906 - val_loss: 1.7081 - val_acc: 0.3611\n",
      "Epoch 391/1000\n",
      "1152/1152 [==============================] - 1s 661us/step - loss: 1.6742 - acc: 0.3941 - val_loss: 1.7070 - val_acc: 0.3785\n",
      "Epoch 392/1000\n",
      "1152/1152 [==============================] - 1s 645us/step - loss: 1.6627 - acc: 0.4028 - val_loss: 1.7216 - val_acc: 0.3542\n",
      "Epoch 393/1000\n",
      "1152/1152 [==============================] - 1s 1ms/step - loss: 1.6567 - acc: 0.3915 - val_loss: 1.7128 - val_acc: 0.3750\n",
      "Epoch 394/1000\n",
      "1152/1152 [==============================] - 1s 792us/step - loss: 1.6667 - acc: 0.3880 - val_loss: 1.7266 - val_acc: 0.3333\n",
      "Epoch 395/1000\n",
      "1152/1152 [==============================] - 1s 813us/step - loss: 1.6733 - acc: 0.3793 - val_loss: 1.7089 - val_acc: 0.3681\n",
      "Epoch 396/1000\n",
      "1152/1152 [==============================] - 1s 663us/step - loss: 1.6459 - acc: 0.4002 - val_loss: 1.7296 - val_acc: 0.3333\n",
      "Epoch 397/1000\n",
      "1152/1152 [==============================] - 1s 771us/step - loss: 1.6564 - acc: 0.3767 - val_loss: 1.7282 - val_acc: 0.3438\n",
      "Epoch 398/1000\n",
      "1152/1152 [==============================] - 1s 801us/step - loss: 1.6597 - acc: 0.4002 - val_loss: 1.7062 - val_acc: 0.3750\n",
      "Epoch 399/1000\n",
      "1152/1152 [==============================] - 1s 640us/step - loss: 1.6525 - acc: 0.3854 - val_loss: 1.7057 - val_acc: 0.3681\n",
      "Epoch 400/1000\n",
      "1152/1152 [==============================] - 1s 708us/step - loss: 1.6658 - acc: 0.3793 - val_loss: 1.7192 - val_acc: 0.3507\n",
      "Epoch 401/1000\n",
      "1152/1152 [==============================] - 1s 747us/step - loss: 1.6528 - acc: 0.3958 - val_loss: 1.7121 - val_acc: 0.3646\n",
      "Epoch 402/1000\n",
      "1152/1152 [==============================] - 1s 740us/step - loss: 1.6549 - acc: 0.4097 - val_loss: 1.7217 - val_acc: 0.3611\n",
      "Epoch 403/1000\n",
      "1152/1152 [==============================] - 1s 665us/step - loss: 1.6578 - acc: 0.3767 - val_loss: 1.7134 - val_acc: 0.3681\n",
      "Epoch 404/1000\n",
      "1152/1152 [==============================] - 1s 669us/step - loss: 1.6555 - acc: 0.3898 - val_loss: 1.7215 - val_acc: 0.3576\n",
      "Epoch 405/1000\n",
      "1152/1152 [==============================] - 1s 593us/step - loss: 1.6540 - acc: 0.3863 - val_loss: 1.7092 - val_acc: 0.3438\n",
      "Epoch 406/1000\n",
      "1152/1152 [==============================] - 1s 654us/step - loss: 1.6589 - acc: 0.3663 - val_loss: 1.7066 - val_acc: 0.3611\n",
      "Epoch 407/1000\n",
      "1152/1152 [==============================] - 1s 587us/step - loss: 1.6607 - acc: 0.3854 - val_loss: 1.7065 - val_acc: 0.3646\n",
      "Epoch 408/1000\n",
      "1152/1152 [==============================] - 1s 582us/step - loss: 1.6513 - acc: 0.4019 - val_loss: 1.7086 - val_acc: 0.3750\n",
      "Epoch 409/1000\n",
      "1152/1152 [==============================] - 1s 572us/step - loss: 1.6502 - acc: 0.3802 - val_loss: 1.7088 - val_acc: 0.3542\n",
      "Epoch 410/1000\n",
      "1152/1152 [==============================] - 1s 609us/step - loss: 1.6595 - acc: 0.3924 - val_loss: 1.7035 - val_acc: 0.3646\n",
      "Epoch 411/1000\n",
      "1152/1152 [==============================] - 1s 616us/step - loss: 1.6428 - acc: 0.4002 - val_loss: 1.7124 - val_acc: 0.3472\n",
      "Epoch 412/1000\n",
      "1152/1152 [==============================] - 1s 582us/step - loss: 1.6563 - acc: 0.3819 - val_loss: 1.7095 - val_acc: 0.3507\n",
      "Epoch 413/1000\n",
      "1152/1152 [==============================] - 1s 1ms/step - loss: 1.6516 - acc: 0.3845 - val_loss: 1.7099 - val_acc: 0.3438\n",
      "Epoch 414/1000\n",
      "1152/1152 [==============================] - 1s 723us/step - loss: 1.6512 - acc: 0.3889 - val_loss: 1.7121 - val_acc: 0.3576\n",
      "Epoch 415/1000\n",
      "1152/1152 [==============================] - 1s 459us/step - loss: 1.6516 - acc: 0.4115 - val_loss: 1.6998 - val_acc: 0.3576\n",
      "Epoch 416/1000\n",
      "1152/1152 [==============================] - 1s 654us/step - loss: 1.6311 - acc: 0.4158 - val_loss: 1.6978 - val_acc: 0.3646\n",
      "Epoch 417/1000\n",
      "1152/1152 [==============================] - 1s 657us/step - loss: 1.6574 - acc: 0.3785 - val_loss: 1.6968 - val_acc: 0.3715\n",
      "Epoch 418/1000\n",
      "1152/1152 [==============================] - 1s 727us/step - loss: 1.6395 - acc: 0.3915 - val_loss: 1.6996 - val_acc: 0.3646\n",
      "Epoch 419/1000\n",
      "1152/1152 [==============================] - 1s 616us/step - loss: 1.6332 - acc: 0.3889 - val_loss: 1.7077 - val_acc: 0.3542\n",
      "Epoch 420/1000\n",
      "1152/1152 [==============================] - 1s 588us/step - loss: 1.6397 - acc: 0.3976 - val_loss: 1.7018 - val_acc: 0.3611\n",
      "Epoch 421/1000\n",
      "1152/1152 [==============================] - 1s 548us/step - loss: 1.6389 - acc: 0.3872 - val_loss: 1.6954 - val_acc: 0.3750\n",
      "Epoch 422/1000\n",
      "1152/1152 [==============================] - 1s 545us/step - loss: 1.6458 - acc: 0.3906 - val_loss: 1.6981 - val_acc: 0.3542\n",
      "Epoch 423/1000\n",
      "1152/1152 [==============================] - 1s 743us/step - loss: 1.6463 - acc: 0.3785 - val_loss: 1.6982 - val_acc: 0.3750\n",
      "Epoch 424/1000\n",
      "1152/1152 [==============================] - 1s 681us/step - loss: 1.6385 - acc: 0.3924 - val_loss: 1.7122 - val_acc: 0.3715\n",
      "Epoch 425/1000\n",
      "1152/1152 [==============================] - 1s 692us/step - loss: 1.6382 - acc: 0.3976 - val_loss: 1.7110 - val_acc: 0.3438\n",
      "Epoch 426/1000\n",
      "1152/1152 [==============================] - 1s 618us/step - loss: 1.6456 - acc: 0.3819 - val_loss: 1.6976 - val_acc: 0.3715\n",
      "Epoch 427/1000\n",
      "1152/1152 [==============================] - 1s 753us/step - loss: 1.6422 - acc: 0.3880 - val_loss: 1.7081 - val_acc: 0.3576\n",
      "Epoch 428/1000\n",
      "1152/1152 [==============================] - 1s 685us/step - loss: 1.6372 - acc: 0.3941 - val_loss: 1.6950 - val_acc: 0.3785\n",
      "Epoch 429/1000\n",
      "1152/1152 [==============================] - 1s 651us/step - loss: 1.6344 - acc: 0.3976 - val_loss: 1.6896 - val_acc: 0.3854\n",
      "Epoch 430/1000\n",
      "1152/1152 [==============================] - 1s 679us/step - loss: 1.6260 - acc: 0.4184 - val_loss: 1.7025 - val_acc: 0.3403\n",
      "Epoch 431/1000\n",
      "1152/1152 [==============================] - 1s 688us/step - loss: 1.6354 - acc: 0.4028 - val_loss: 1.6981 - val_acc: 0.3715\n",
      "Epoch 432/1000\n",
      "1152/1152 [==============================] - 1s 624us/step - loss: 1.6207 - acc: 0.4019 - val_loss: 1.7165 - val_acc: 0.3368\n",
      "Epoch 433/1000\n",
      "1152/1152 [==============================] - 1s 635us/step - loss: 1.6372 - acc: 0.3932 - val_loss: 1.6983 - val_acc: 0.3611\n",
      "Epoch 434/1000\n",
      "1152/1152 [==============================] - 1s 637us/step - loss: 1.6302 - acc: 0.4089 - val_loss: 1.6970 - val_acc: 0.3507\n",
      "Epoch 435/1000\n",
      "1152/1152 [==============================] - 1s 705us/step - loss: 1.6317 - acc: 0.4019 - val_loss: 1.6858 - val_acc: 0.3542\n",
      "Epoch 436/1000\n",
      "1152/1152 [==============================] - 1s 531us/step - loss: 1.6351 - acc: 0.3984 - val_loss: 1.6993 - val_acc: 0.3819\n",
      "Epoch 437/1000\n",
      "1152/1152 [==============================] - 1s 698us/step - loss: 1.6416 - acc: 0.3984 - val_loss: 1.7022 - val_acc: 0.3646\n",
      "Epoch 438/1000\n",
      "1152/1152 [==============================] - 1s 647us/step - loss: 1.6204 - acc: 0.4002 - val_loss: 1.6891 - val_acc: 0.3646\n",
      "Epoch 439/1000\n",
      "1152/1152 [==============================] - 1s 693us/step - loss: 1.6329 - acc: 0.4036 - val_loss: 1.6959 - val_acc: 0.3611\n",
      "Epoch 440/1000\n",
      "1152/1152 [==============================] - 1s 710us/step - loss: 1.6353 - acc: 0.3967 - val_loss: 1.6850 - val_acc: 0.3715\n",
      "Epoch 441/1000\n",
      "1152/1152 [==============================] - 1s 652us/step - loss: 1.6287 - acc: 0.3984 - val_loss: 1.6975 - val_acc: 0.3611\n",
      "Epoch 442/1000\n",
      "1152/1152 [==============================] - 1s 717us/step - loss: 1.6180 - acc: 0.4080 - val_loss: 1.6985 - val_acc: 0.3542\n",
      "Epoch 443/1000\n",
      "1152/1152 [==============================] - 1s 979us/step - loss: 1.6296 - acc: 0.3863 - val_loss: 1.6939 - val_acc: 0.3785\n",
      "Epoch 444/1000\n",
      "1152/1152 [==============================] - 1s 1ms/step - loss: 1.6164 - acc: 0.4097 - val_loss: 1.6998 - val_acc: 0.3542\n",
      "Epoch 445/1000\n",
      "1152/1152 [==============================] - 1s 841us/step - loss: 1.6293 - acc: 0.3967 - val_loss: 1.6929 - val_acc: 0.3681\n",
      "Epoch 446/1000\n",
      "1152/1152 [==============================] - 1s 871us/step - loss: 1.6251 - acc: 0.3958 - val_loss: 1.7037 - val_acc: 0.3507\n",
      "Epoch 447/1000\n",
      "1152/1152 [==============================] - 1s 839us/step - loss: 1.6178 - acc: 0.4123 - val_loss: 1.6808 - val_acc: 0.3750\n",
      "Epoch 448/1000\n",
      "1152/1152 [==============================] - 1s 778us/step - loss: 1.6142 - acc: 0.4193 - val_loss: 1.6806 - val_acc: 0.3646\n",
      "Epoch 449/1000\n",
      "1152/1152 [==============================] - 1s 643us/step - loss: 1.6192 - acc: 0.4097 - val_loss: 1.6942 - val_acc: 0.3646\n",
      "Epoch 450/1000\n",
      "1152/1152 [==============================] - 1s 680us/step - loss: 1.6100 - acc: 0.4132 - val_loss: 1.6850 - val_acc: 0.3854\n",
      "Epoch 451/1000\n",
      "1152/1152 [==============================] - 1s 711us/step - loss: 1.6136 - acc: 0.4071 - val_loss: 1.6979 - val_acc: 0.3542\n",
      "Epoch 452/1000\n",
      "1152/1152 [==============================] - 1s 680us/step - loss: 1.6148 - acc: 0.3976 - val_loss: 1.6855 - val_acc: 0.3681\n",
      "Epoch 453/1000\n",
      "1152/1152 [==============================] - 1s 738us/step - loss: 1.6037 - acc: 0.4054 - val_loss: 1.6898 - val_acc: 0.3785\n",
      "Epoch 454/1000\n",
      "1152/1152 [==============================] - 1s 790us/step - loss: 1.6215 - acc: 0.4149 - val_loss: 1.6871 - val_acc: 0.3750\n",
      "Epoch 455/1000\n",
      "1152/1152 [==============================] - 1s 523us/step - loss: 1.6250 - acc: 0.4106 - val_loss: 1.6845 - val_acc: 0.3715\n",
      "Epoch 456/1000\n",
      "1152/1152 [==============================] - 1s 552us/step - loss: 1.6152 - acc: 0.3984 - val_loss: 1.7015 - val_acc: 0.3576\n",
      "Epoch 457/1000\n",
      "1152/1152 [==============================] - 1s 564us/step - loss: 1.6155 - acc: 0.4062 - val_loss: 1.6751 - val_acc: 0.3819\n",
      "Epoch 458/1000\n",
      "1152/1152 [==============================] - 1s 713us/step - loss: 1.6123 - acc: 0.4184 - val_loss: 1.6795 - val_acc: 0.3750\n",
      "Epoch 459/1000\n",
      "1152/1152 [==============================] - 1s 822us/step - loss: 1.6241 - acc: 0.4019 - val_loss: 1.6877 - val_acc: 0.3681\n",
      "Epoch 460/1000\n",
      "1152/1152 [==============================] - 1s 970us/step - loss: 1.6178 - acc: 0.3932 - val_loss: 1.6853 - val_acc: 0.3646\n",
      "Epoch 461/1000\n",
      "1152/1152 [==============================] - 1s 924us/step - loss: 1.6038 - acc: 0.4106 - val_loss: 1.6783 - val_acc: 0.3819\n",
      "Epoch 462/1000\n",
      "1152/1152 [==============================] - 1s 662us/step - loss: 1.6114 - acc: 0.4097 - val_loss: 1.6732 - val_acc: 0.3819\n",
      "Epoch 463/1000\n",
      "1152/1152 [==============================] - 1s 696us/step - loss: 1.6183 - acc: 0.4158 - val_loss: 1.6864 - val_acc: 0.3646\n",
      "Epoch 464/1000\n",
      "1152/1152 [==============================] - 1s 964us/step - loss: 1.6112 - acc: 0.4106 - val_loss: 1.6864 - val_acc: 0.3507\n",
      "Epoch 465/1000\n",
      "1152/1152 [==============================] - 1s 828us/step - loss: 1.6101 - acc: 0.4184 - val_loss: 1.6824 - val_acc: 0.3715\n",
      "Epoch 466/1000\n",
      "1152/1152 [==============================] - 1s 571us/step - loss: 1.6096 - acc: 0.4115 - val_loss: 1.6731 - val_acc: 0.3819\n",
      "Epoch 467/1000\n",
      "1152/1152 [==============================] - 1s 701us/step - loss: 1.6160 - acc: 0.4028 - val_loss: 1.6753 - val_acc: 0.3819\n",
      "Epoch 468/1000\n",
      "1152/1152 [==============================] - 1s 529us/step - loss: 1.6090 - acc: 0.4132 - val_loss: 1.6879 - val_acc: 0.3576\n",
      "Epoch 469/1000\n",
      "1152/1152 [==============================] - 1s 533us/step - loss: 1.6148 - acc: 0.3941 - val_loss: 1.6833 - val_acc: 0.3681\n",
      "Epoch 470/1000\n",
      "1152/1152 [==============================] - 1s 548us/step - loss: 1.6088 - acc: 0.4045 - val_loss: 1.6826 - val_acc: 0.3646\n",
      "Epoch 471/1000\n",
      "1152/1152 [==============================] - 1s 538us/step - loss: 1.6196 - acc: 0.4019 - val_loss: 1.6835 - val_acc: 0.3715\n",
      "Epoch 472/1000\n",
      "1152/1152 [==============================] - 1s 538us/step - loss: 1.6073 - acc: 0.4045 - val_loss: 1.6800 - val_acc: 0.3750\n",
      "Epoch 473/1000\n",
      "1152/1152 [==============================] - 1s 743us/step - loss: 1.6022 - acc: 0.4245 - val_loss: 1.6967 - val_acc: 0.3368\n",
      "Epoch 474/1000\n",
      "1152/1152 [==============================] - 1s 966us/step - loss: 1.6012 - acc: 0.4123 - val_loss: 1.6705 - val_acc: 0.3750\n",
      "Epoch 475/1000\n",
      "1152/1152 [==============================] - 1s 756us/step - loss: 1.6062 - acc: 0.4054 - val_loss: 1.6655 - val_acc: 0.3715\n",
      "Epoch 476/1000\n",
      "1152/1152 [==============================] - 1s 851us/step - loss: 1.5894 - acc: 0.4132 - val_loss: 1.6716 - val_acc: 0.3785\n",
      "Epoch 477/1000\n",
      "1152/1152 [==============================] - 1s 762us/step - loss: 1.5967 - acc: 0.4175 - val_loss: 1.6636 - val_acc: 0.3785\n",
      "Epoch 478/1000\n",
      "1152/1152 [==============================] - 1s 758us/step - loss: 1.5911 - acc: 0.4167 - val_loss: 1.6702 - val_acc: 0.3819\n",
      "Epoch 479/1000\n",
      "1152/1152 [==============================] - 1s 618us/step - loss: 1.5950 - acc: 0.4149 - val_loss: 1.6922 - val_acc: 0.3507\n",
      "Epoch 480/1000\n",
      "1152/1152 [==============================] - 1s 1ms/step - loss: 1.6132 - acc: 0.3958 - val_loss: 1.6718 - val_acc: 0.3646\n",
      "Epoch 481/1000\n",
      "1152/1152 [==============================] - 1s 733us/step - loss: 1.6014 - acc: 0.3958 - val_loss: 1.6707 - val_acc: 0.3750\n",
      "Epoch 482/1000\n",
      "1152/1152 [==============================] - 1s 539us/step - loss: 1.6077 - acc: 0.4036 - val_loss: 1.6739 - val_acc: 0.3785\n",
      "Epoch 483/1000\n",
      "1152/1152 [==============================] - 1s 735us/step - loss: 1.6073 - acc: 0.4028 - val_loss: 1.6743 - val_acc: 0.3819\n",
      "Epoch 484/1000\n",
      "1152/1152 [==============================] - 1s 578us/step - loss: 1.5965 - acc: 0.4149 - val_loss: 1.6718 - val_acc: 0.3750\n",
      "Epoch 485/1000\n",
      "1152/1152 [==============================] - 1s 561us/step - loss: 1.5878 - acc: 0.4167 - val_loss: 1.6652 - val_acc: 0.3646\n",
      "Epoch 486/1000\n",
      "1152/1152 [==============================] - 1s 747us/step - loss: 1.5824 - acc: 0.4236 - val_loss: 1.6732 - val_acc: 0.3611\n",
      "Epoch 487/1000\n",
      "1152/1152 [==============================] - 1s 556us/step - loss: 1.5909 - acc: 0.4158 - val_loss: 1.6645 - val_acc: 0.3576\n",
      "Epoch 488/1000\n",
      "1152/1152 [==============================] - 1s 549us/step - loss: 1.5877 - acc: 0.4045 - val_loss: 1.6720 - val_acc: 0.3785\n",
      "Epoch 489/1000\n",
      "1152/1152 [==============================] - 1s 562us/step - loss: 1.5976 - acc: 0.4019 - val_loss: 1.6604 - val_acc: 0.3785\n",
      "Epoch 490/1000\n",
      "1152/1152 [==============================] - 1s 793us/step - loss: 1.5837 - acc: 0.4158 - val_loss: 1.6659 - val_acc: 0.3750\n",
      "Epoch 491/1000\n",
      "1152/1152 [==============================] - 1s 761us/step - loss: 1.5897 - acc: 0.4097 - val_loss: 1.6587 - val_acc: 0.3785\n",
      "Epoch 492/1000\n",
      "1152/1152 [==============================] - 1s 944us/step - loss: 1.5860 - acc: 0.4201 - val_loss: 1.6827 - val_acc: 0.3611\n",
      "Epoch 493/1000\n",
      "1152/1152 [==============================] - 1s 636us/step - loss: 1.5780 - acc: 0.4236 - val_loss: 1.6634 - val_acc: 0.3646\n",
      "Epoch 494/1000\n",
      "1152/1152 [==============================] - 1s 493us/step - loss: 1.6005 - acc: 0.4062 - val_loss: 1.6671 - val_acc: 0.3854\n",
      "Epoch 495/1000\n",
      "1152/1152 [==============================] - 1s 572us/step - loss: 1.5838 - acc: 0.4280 - val_loss: 1.6610 - val_acc: 0.3750\n",
      "Epoch 496/1000\n",
      "1152/1152 [==============================] - 1s 535us/step - loss: 1.5919 - acc: 0.4036 - val_loss: 1.6651 - val_acc: 0.3715\n",
      "Epoch 497/1000\n",
      "1152/1152 [==============================] - 1s 603us/step - loss: 1.5827 - acc: 0.4340 - val_loss: 1.6810 - val_acc: 0.3576\n",
      "Epoch 498/1000\n",
      "1152/1152 [==============================] - 1s 952us/step - loss: 1.5838 - acc: 0.4245 - val_loss: 1.6598 - val_acc: 0.3819\n",
      "Epoch 499/1000\n",
      "1152/1152 [==============================] - 1s 1ms/step - loss: 1.5819 - acc: 0.4358 - val_loss: 1.6575 - val_acc: 0.3924\n",
      "Epoch 500/1000\n",
      "1152/1152 [==============================] - 1s 880us/step - loss: 1.5779 - acc: 0.4280 - val_loss: 1.6625 - val_acc: 0.3785\n",
      "Epoch 501/1000\n",
      "1152/1152 [==============================] - 1s 718us/step - loss: 1.5783 - acc: 0.4288 - val_loss: 1.6640 - val_acc: 0.3681\n",
      "Epoch 502/1000\n",
      "1152/1152 [==============================] - 1s 813us/step - loss: 1.5832 - acc: 0.4193 - val_loss: 1.6538 - val_acc: 0.3646\n",
      "Epoch 503/1000\n",
      "1152/1152 [==============================] - 1s 782us/step - loss: 1.5726 - acc: 0.4306 - val_loss: 1.6682 - val_acc: 0.3646\n",
      "Epoch 504/1000\n",
      "1152/1152 [==============================] - 1s 574us/step - loss: 1.5714 - acc: 0.4236 - val_loss: 1.6636 - val_acc: 0.3715\n",
      "Epoch 505/1000\n",
      "1152/1152 [==============================] - 1s 527us/step - loss: 1.5775 - acc: 0.4219 - val_loss: 1.6553 - val_acc: 0.3785\n",
      "Epoch 506/1000\n",
      "1152/1152 [==============================] - 1s 556us/step - loss: 1.5862 - acc: 0.4158 - val_loss: 1.6683 - val_acc: 0.3715\n",
      "Epoch 507/1000\n",
      "1152/1152 [==============================] - 1s 555us/step - loss: 1.5727 - acc: 0.4271 - val_loss: 1.6606 - val_acc: 0.3819\n",
      "Epoch 508/1000\n",
      "1152/1152 [==============================] - 1s 539us/step - loss: 1.5844 - acc: 0.4106 - val_loss: 1.6643 - val_acc: 0.3889\n",
      "Epoch 509/1000\n",
      "1152/1152 [==============================] - 1s 550us/step - loss: 1.5724 - acc: 0.4158 - val_loss: 1.6543 - val_acc: 0.3681\n",
      "Epoch 510/1000\n",
      "1152/1152 [==============================] - 1s 595us/step - loss: 1.5808 - acc: 0.4132 - val_loss: 1.6524 - val_acc: 0.3889\n",
      "Epoch 511/1000\n",
      "1152/1152 [==============================] - 1s 595us/step - loss: 1.5660 - acc: 0.4314 - val_loss: 1.6550 - val_acc: 0.3854\n",
      "Epoch 512/1000\n",
      "1152/1152 [==============================] - 1s 577us/step - loss: 1.5807 - acc: 0.3967 - val_loss: 1.6587 - val_acc: 0.3681\n",
      "Epoch 513/1000\n",
      "1152/1152 [==============================] - 1s 582us/step - loss: 1.5790 - acc: 0.4306 - val_loss: 1.6561 - val_acc: 0.3715\n",
      "Epoch 514/1000\n",
      "1152/1152 [==============================] - 1s 625us/step - loss: 1.5703 - acc: 0.4210 - val_loss: 1.6556 - val_acc: 0.3889\n",
      "Epoch 515/1000\n",
      "1152/1152 [==============================] - 1s 527us/step - loss: 1.5780 - acc: 0.4280 - val_loss: 1.6562 - val_acc: 0.3715\n",
      "Epoch 516/1000\n",
      "1152/1152 [==============================] - 1s 549us/step - loss: 1.5611 - acc: 0.4175 - val_loss: 1.6496 - val_acc: 0.3715\n",
      "Epoch 517/1000\n",
      "1152/1152 [==============================] - 1s 592us/step - loss: 1.5664 - acc: 0.4384 - val_loss: 1.6547 - val_acc: 0.3924\n",
      "Epoch 518/1000\n",
      "1152/1152 [==============================] - 1s 583us/step - loss: 1.5731 - acc: 0.4149 - val_loss: 1.6613 - val_acc: 0.3611\n",
      "Epoch 519/1000\n",
      "1152/1152 [==============================] - 1s 550us/step - loss: 1.5629 - acc: 0.4340 - val_loss: 1.6537 - val_acc: 0.3750\n",
      "Epoch 520/1000\n",
      "1152/1152 [==============================] - 1s 894us/step - loss: 1.5639 - acc: 0.4106 - val_loss: 1.6591 - val_acc: 0.3785\n",
      "Epoch 521/1000\n",
      "1152/1152 [==============================] - 1s 659us/step - loss: 1.5578 - acc: 0.4366 - val_loss: 1.6487 - val_acc: 0.3646\n",
      "Epoch 522/1000\n",
      "1152/1152 [==============================] - 1s 887us/step - loss: 1.5603 - acc: 0.4245 - val_loss: 1.6467 - val_acc: 0.3889\n",
      "Epoch 523/1000\n",
      "1152/1152 [==============================] - 1s 800us/step - loss: 1.5623 - acc: 0.4332 - val_loss: 1.6661 - val_acc: 0.3715\n",
      "Epoch 524/1000\n",
      "1152/1152 [==============================] - 1s 907us/step - loss: 1.5688 - acc: 0.4201 - val_loss: 1.6401 - val_acc: 0.3819\n",
      "Epoch 525/1000\n",
      "1152/1152 [==============================] - 1s 756us/step - loss: 1.5638 - acc: 0.4219 - val_loss: 1.6400 - val_acc: 0.3785\n",
      "Epoch 526/1000\n",
      "1152/1152 [==============================] - 1s 687us/step - loss: 1.5614 - acc: 0.4271 - val_loss: 1.6469 - val_acc: 0.3785\n",
      "Epoch 527/1000\n",
      "1152/1152 [==============================] - 1s 596us/step - loss: 1.5597 - acc: 0.4297 - val_loss: 1.6511 - val_acc: 0.3750\n",
      "Epoch 528/1000\n",
      "1152/1152 [==============================] - 1s 701us/step - loss: 1.5568 - acc: 0.4175 - val_loss: 1.6414 - val_acc: 0.3924\n",
      "Epoch 529/1000\n",
      "1152/1152 [==============================] - 1s 595us/step - loss: 1.5558 - acc: 0.4323 - val_loss: 1.6570 - val_acc: 0.3819\n",
      "Epoch 530/1000\n",
      "1152/1152 [==============================] - 1s 746us/step - loss: 1.5573 - acc: 0.4306 - val_loss: 1.6514 - val_acc: 0.3785\n",
      "Epoch 531/1000\n",
      "1152/1152 [==============================] - 1s 702us/step - loss: 1.5644 - acc: 0.4271 - val_loss: 1.6432 - val_acc: 0.3819\n",
      "Epoch 532/1000\n",
      "1152/1152 [==============================] - 1s 701us/step - loss: 1.5671 - acc: 0.4201 - val_loss: 1.6510 - val_acc: 0.3785\n",
      "Epoch 533/1000\n",
      "1152/1152 [==============================] - 1s 687us/step - loss: 1.5786 - acc: 0.4193 - val_loss: 1.6470 - val_acc: 0.3715\n",
      "Epoch 534/1000\n",
      "1152/1152 [==============================] - 1s 738us/step - loss: 1.5471 - acc: 0.4236 - val_loss: 1.6377 - val_acc: 0.3750\n",
      "Epoch 535/1000\n",
      "1152/1152 [==============================] - 1s 654us/step - loss: 1.5573 - acc: 0.4280 - val_loss: 1.6521 - val_acc: 0.3681\n",
      "Epoch 536/1000\n",
      "1152/1152 [==============================] - 1s 659us/step - loss: 1.5510 - acc: 0.4401 - val_loss: 1.6467 - val_acc: 0.3819\n",
      "Epoch 537/1000\n",
      "1152/1152 [==============================] - 1s 703us/step - loss: 1.5539 - acc: 0.4375 - val_loss: 1.6617 - val_acc: 0.3681\n",
      "Epoch 538/1000\n",
      "1152/1152 [==============================] - 1s 687us/step - loss: 1.5685 - acc: 0.4288 - val_loss: 1.6392 - val_acc: 0.3681\n",
      "Epoch 539/1000\n",
      "1152/1152 [==============================] - 1s 624us/step - loss: 1.5561 - acc: 0.4271 - val_loss: 1.6421 - val_acc: 0.3819\n",
      "Epoch 540/1000\n",
      "1152/1152 [==============================] - 1s 598us/step - loss: 1.5599 - acc: 0.4227 - val_loss: 1.6300 - val_acc: 0.3993\n",
      "Epoch 541/1000\n",
      "1152/1152 [==============================] - 1s 605us/step - loss: 1.5488 - acc: 0.4306 - val_loss: 1.6370 - val_acc: 0.3889\n",
      "Epoch 542/1000\n",
      "1152/1152 [==============================] - 1s 680us/step - loss: 1.5517 - acc: 0.4453 - val_loss: 1.6361 - val_acc: 0.3611\n",
      "Epoch 543/1000\n",
      "1152/1152 [==============================] - 1s 611us/step - loss: 1.5554 - acc: 0.4314 - val_loss: 1.6370 - val_acc: 0.3854\n",
      "Epoch 544/1000\n",
      "1152/1152 [==============================] - 1s 644us/step - loss: 1.5425 - acc: 0.4323 - val_loss: 1.6345 - val_acc: 0.3646\n",
      "Epoch 545/1000\n",
      "1152/1152 [==============================] - 1s 692us/step - loss: 1.5364 - acc: 0.4488 - val_loss: 1.6361 - val_acc: 0.3819\n",
      "Epoch 546/1000\n",
      "1152/1152 [==============================] - 1s 598us/step - loss: 1.5447 - acc: 0.4323 - val_loss: 1.6424 - val_acc: 0.3750\n",
      "Epoch 547/1000\n",
      "1152/1152 [==============================] - 1s 642us/step - loss: 1.5430 - acc: 0.4227 - val_loss: 1.6441 - val_acc: 0.3750\n",
      "Epoch 548/1000\n",
      "1152/1152 [==============================] - 1s 644us/step - loss: 1.5417 - acc: 0.4410 - val_loss: 1.6443 - val_acc: 0.3819\n",
      "Epoch 549/1000\n",
      "1152/1152 [==============================] - 1s 631us/step - loss: 1.5497 - acc: 0.4271 - val_loss: 1.6270 - val_acc: 0.3993\n",
      "Epoch 550/1000\n",
      "1152/1152 [==============================] - 1s 648us/step - loss: 1.5522 - acc: 0.4349 - val_loss: 1.6321 - val_acc: 0.3854\n",
      "Epoch 551/1000\n",
      "1152/1152 [==============================] - 1s 651us/step - loss: 1.5550 - acc: 0.4271 - val_loss: 1.6311 - val_acc: 0.3854\n",
      "Epoch 552/1000\n",
      "1152/1152 [==============================] - 1s 669us/step - loss: 1.5426 - acc: 0.4297 - val_loss: 1.6376 - val_acc: 0.3681\n",
      "Epoch 553/1000\n",
      "1152/1152 [==============================] - 1s 641us/step - loss: 1.5525 - acc: 0.4384 - val_loss: 1.6374 - val_acc: 0.3958\n",
      "Epoch 554/1000\n",
      "1152/1152 [==============================] - 1s 645us/step - loss: 1.5352 - acc: 0.4323 - val_loss: 1.6296 - val_acc: 0.3924\n",
      "Epoch 555/1000\n",
      "1152/1152 [==============================] - 1s 714us/step - loss: 1.5390 - acc: 0.4332 - val_loss: 1.6366 - val_acc: 0.3681\n",
      "Epoch 556/1000\n",
      "1152/1152 [==============================] - 1s 656us/step - loss: 1.5334 - acc: 0.4444 - val_loss: 1.6341 - val_acc: 0.3785\n",
      "Epoch 557/1000\n",
      "1152/1152 [==============================] - 1s 600us/step - loss: 1.5370 - acc: 0.4375 - val_loss: 1.6344 - val_acc: 0.3958\n",
      "Epoch 558/1000\n",
      "1152/1152 [==============================] - 1s 646us/step - loss: 1.5461 - acc: 0.4201 - val_loss: 1.6305 - val_acc: 0.3993\n",
      "Epoch 559/1000\n",
      "1152/1152 [==============================] - 1s 639us/step - loss: 1.5367 - acc: 0.4323 - val_loss: 1.6360 - val_acc: 0.3785\n",
      "Epoch 560/1000\n",
      "1152/1152 [==============================] - 1s 601us/step - loss: 1.5425 - acc: 0.4253 - val_loss: 1.6310 - val_acc: 0.3819\n",
      "Epoch 561/1000\n",
      "1152/1152 [==============================] - 1s 600us/step - loss: 1.5341 - acc: 0.4453 - val_loss: 1.6357 - val_acc: 0.3889\n",
      "Epoch 562/1000\n",
      "1152/1152 [==============================] - 1s 622us/step - loss: 1.5436 - acc: 0.4375 - val_loss: 1.6286 - val_acc: 0.3854\n",
      "Epoch 563/1000\n",
      "1152/1152 [==============================] - 1s 597us/step - loss: 1.5336 - acc: 0.4453 - val_loss: 1.6434 - val_acc: 0.3854\n",
      "Epoch 564/1000\n",
      "1152/1152 [==============================] - 1s 619us/step - loss: 1.5378 - acc: 0.4444 - val_loss: 1.6322 - val_acc: 0.3819\n",
      "Epoch 565/1000\n",
      "1152/1152 [==============================] - 1s 632us/step - loss: 1.5241 - acc: 0.4497 - val_loss: 1.6325 - val_acc: 0.3785\n",
      "Epoch 566/1000\n",
      "1152/1152 [==============================] - 1s 635us/step - loss: 1.5217 - acc: 0.4444 - val_loss: 1.6376 - val_acc: 0.3819\n",
      "Epoch 567/1000\n",
      "1152/1152 [==============================] - 1s 631us/step - loss: 1.5268 - acc: 0.4479 - val_loss: 1.6225 - val_acc: 0.3785\n",
      "Epoch 568/1000\n",
      "1152/1152 [==============================] - 1s 642us/step - loss: 1.5475 - acc: 0.4427 - val_loss: 1.6290 - val_acc: 0.3819\n",
      "Epoch 569/1000\n",
      "1152/1152 [==============================] - 1s 603us/step - loss: 1.5221 - acc: 0.4444 - val_loss: 1.6276 - val_acc: 0.3750\n",
      "Epoch 570/1000\n",
      "1152/1152 [==============================] - 1s 623us/step - loss: 1.5389 - acc: 0.4375 - val_loss: 1.6324 - val_acc: 0.3785\n",
      "Epoch 571/1000\n",
      "1152/1152 [==============================] - 1s 611us/step - loss: 1.5192 - acc: 0.4375 - val_loss: 1.6256 - val_acc: 0.3889\n",
      "Epoch 572/1000\n",
      "1152/1152 [==============================] - 1s 620us/step - loss: 1.5231 - acc: 0.4549 - val_loss: 1.6304 - val_acc: 0.3681\n",
      "Epoch 573/1000\n",
      "1152/1152 [==============================] - 1s 615us/step - loss: 1.5204 - acc: 0.4549 - val_loss: 1.6388 - val_acc: 0.3819\n",
      "Epoch 574/1000\n",
      "1152/1152 [==============================] - 1s 595us/step - loss: 1.5336 - acc: 0.4384 - val_loss: 1.6267 - val_acc: 0.3819\n",
      "Epoch 575/1000\n",
      "1152/1152 [==============================] - 1s 594us/step - loss: 1.5240 - acc: 0.4488 - val_loss: 1.6402 - val_acc: 0.3819\n",
      "Epoch 576/1000\n",
      "1152/1152 [==============================] - 1s 614us/step - loss: 1.5305 - acc: 0.4497 - val_loss: 1.6230 - val_acc: 0.3785\n",
      "Epoch 577/1000\n",
      "1152/1152 [==============================] - 1s 643us/step - loss: 1.5420 - acc: 0.4358 - val_loss: 1.6214 - val_acc: 0.3889\n",
      "Epoch 578/1000\n",
      "1152/1152 [==============================] - 1s 715us/step - loss: 1.5380 - acc: 0.4444 - val_loss: 1.6148 - val_acc: 0.3958\n",
      "Epoch 579/1000\n",
      "1152/1152 [==============================] - 1s 581us/step - loss: 1.5201 - acc: 0.4488 - val_loss: 1.6225 - val_acc: 0.3819\n",
      "Epoch 580/1000\n",
      "1152/1152 [==============================] - 1s 632us/step - loss: 1.5243 - acc: 0.4497 - val_loss: 1.6148 - val_acc: 0.4028\n",
      "Epoch 581/1000\n",
      "1152/1152 [==============================] - 1s 624us/step - loss: 1.5253 - acc: 0.4453 - val_loss: 1.6373 - val_acc: 0.3819\n",
      "Epoch 582/1000\n",
      "1152/1152 [==============================] - 1s 606us/step - loss: 1.5280 - acc: 0.4366 - val_loss: 1.6232 - val_acc: 0.3646\n",
      "Epoch 583/1000\n",
      "1152/1152 [==============================] - 1s 588us/step - loss: 1.5185 - acc: 0.4453 - val_loss: 1.6302 - val_acc: 0.3854\n",
      "Epoch 584/1000\n",
      "1152/1152 [==============================] - 1s 612us/step - loss: 1.5161 - acc: 0.4375 - val_loss: 1.6157 - val_acc: 0.3958\n",
      "Epoch 585/1000\n",
      "1152/1152 [==============================] - 1s 621us/step - loss: 1.5205 - acc: 0.4488 - val_loss: 1.6193 - val_acc: 0.3854\n",
      "Epoch 586/1000\n",
      "1152/1152 [==============================] - 1s 585us/step - loss: 1.5138 - acc: 0.4436 - val_loss: 1.6306 - val_acc: 0.3750\n",
      "Epoch 587/1000\n",
      "1152/1152 [==============================] - 1s 601us/step - loss: 1.5233 - acc: 0.4384 - val_loss: 1.6301 - val_acc: 0.3854\n",
      "Epoch 588/1000\n",
      "1152/1152 [==============================] - 1s 611us/step - loss: 1.5269 - acc: 0.4479 - val_loss: 1.6297 - val_acc: 0.3715\n",
      "Epoch 589/1000\n",
      "1152/1152 [==============================] - 1s 631us/step - loss: 1.5224 - acc: 0.4418 - val_loss: 1.6223 - val_acc: 0.3924\n",
      "Epoch 590/1000\n",
      "1152/1152 [==============================] - 1s 613us/step - loss: 1.5348 - acc: 0.4401 - val_loss: 1.6136 - val_acc: 0.3924\n",
      "Epoch 591/1000\n",
      "1152/1152 [==============================] - 1s 613us/step - loss: 1.5191 - acc: 0.4523 - val_loss: 1.6139 - val_acc: 0.3924\n",
      "Epoch 592/1000\n",
      "1152/1152 [==============================] - 1s 616us/step - loss: 1.5252 - acc: 0.4427 - val_loss: 1.6248 - val_acc: 0.3889\n",
      "Epoch 593/1000\n",
      "1152/1152 [==============================] - 1s 635us/step - loss: 1.5263 - acc: 0.4462 - val_loss: 1.6214 - val_acc: 0.3889\n",
      "Epoch 594/1000\n",
      "1152/1152 [==============================] - 1s 600us/step - loss: 1.5115 - acc: 0.4444 - val_loss: 1.6387 - val_acc: 0.3750\n",
      "Epoch 595/1000\n",
      "1152/1152 [==============================] - 1s 596us/step - loss: 1.5134 - acc: 0.4410 - val_loss: 1.6184 - val_acc: 0.3750\n",
      "Epoch 596/1000\n",
      "1152/1152 [==============================] - 1s 612us/step - loss: 1.5115 - acc: 0.4601 - val_loss: 1.6223 - val_acc: 0.3889\n",
      "Epoch 597/1000\n",
      "1152/1152 [==============================] - 1s 604us/step - loss: 1.5247 - acc: 0.4444 - val_loss: 1.6128 - val_acc: 0.4028\n",
      "Epoch 598/1000\n",
      "1152/1152 [==============================] - 1s 602us/step - loss: 1.5162 - acc: 0.4453 - val_loss: 1.6252 - val_acc: 0.3854\n",
      "Epoch 599/1000\n",
      "1152/1152 [==============================] - 1s 622us/step - loss: 1.5172 - acc: 0.4436 - val_loss: 1.6121 - val_acc: 0.4028\n",
      "Epoch 600/1000\n",
      "1152/1152 [==============================] - 1s 661us/step - loss: 1.5017 - acc: 0.4479 - val_loss: 1.6182 - val_acc: 0.3889\n",
      "Epoch 601/1000\n",
      "1152/1152 [==============================] - 1s 625us/step - loss: 1.5087 - acc: 0.4375 - val_loss: 1.6122 - val_acc: 0.3924\n",
      "Epoch 602/1000\n",
      "1152/1152 [==============================] - 1s 598us/step - loss: 1.5051 - acc: 0.4453 - val_loss: 1.6096 - val_acc: 0.3715\n",
      "Epoch 603/1000\n",
      "1152/1152 [==============================] - 1s 639us/step - loss: 1.5059 - acc: 0.4479 - val_loss: 1.6202 - val_acc: 0.3854\n",
      "Epoch 604/1000\n",
      "1152/1152 [==============================] - 1s 611us/step - loss: 1.5191 - acc: 0.4297 - val_loss: 1.6056 - val_acc: 0.3993\n",
      "Epoch 605/1000\n",
      "1152/1152 [==============================] - 1s 613us/step - loss: 1.5152 - acc: 0.4549 - val_loss: 1.6061 - val_acc: 0.3854\n",
      "Epoch 606/1000\n",
      "1152/1152 [==============================] - 1s 598us/step - loss: 1.5044 - acc: 0.4549 - val_loss: 1.6029 - val_acc: 0.4028\n",
      "Epoch 607/1000\n",
      "1152/1152 [==============================] - 1s 604us/step - loss: 1.5044 - acc: 0.4557 - val_loss: 1.6184 - val_acc: 0.3924\n",
      "Epoch 608/1000\n",
      "1152/1152 [==============================] - 1s 610us/step - loss: 1.5092 - acc: 0.4557 - val_loss: 1.6096 - val_acc: 0.3993\n",
      "Epoch 609/1000\n",
      "1152/1152 [==============================] - ETA: 0s - loss: 1.5177 - acc: 0.447 - 1s 644us/step - loss: 1.5134 - acc: 0.4497 - val_loss: 1.6070 - val_acc: 0.3993\n",
      "Epoch 610/1000\n",
      "1152/1152 [==============================] - 1s 588us/step - loss: 1.5096 - acc: 0.4306 - val_loss: 1.6070 - val_acc: 0.3924\n",
      "Epoch 611/1000\n",
      "1152/1152 [==============================] - 1s 593us/step - loss: 1.5097 - acc: 0.4470 - val_loss: 1.6232 - val_acc: 0.3958\n",
      "Epoch 612/1000\n",
      "1152/1152 [==============================] - 1s 574us/step - loss: 1.5052 - acc: 0.4358 - val_loss: 1.6088 - val_acc: 0.3993\n",
      "Epoch 613/1000\n",
      "1152/1152 [==============================] - 1s 607us/step - loss: 1.5117 - acc: 0.4540 - val_loss: 1.6118 - val_acc: 0.3958\n",
      "Epoch 614/1000\n",
      "1152/1152 [==============================] - 1s 603us/step - loss: 1.4956 - acc: 0.4583 - val_loss: 1.6114 - val_acc: 0.3889\n",
      "Epoch 615/1000\n",
      "1152/1152 [==============================] - 1s 623us/step - loss: 1.5011 - acc: 0.4549 - val_loss: 1.6103 - val_acc: 0.3889\n",
      "Epoch 616/1000\n",
      "1152/1152 [==============================] - 1s 623us/step - loss: 1.4911 - acc: 0.4566 - val_loss: 1.6149 - val_acc: 0.3576\n",
      "Epoch 617/1000\n",
      "1152/1152 [==============================] - 1s 657us/step - loss: 1.5070 - acc: 0.4592 - val_loss: 1.6072 - val_acc: 0.3819\n",
      "Epoch 618/1000\n",
      "1152/1152 [==============================] - 1s 598us/step - loss: 1.5008 - acc: 0.4583 - val_loss: 1.6062 - val_acc: 0.3958\n",
      "Epoch 619/1000\n",
      "1152/1152 [==============================] - 1s 612us/step - loss: 1.5071 - acc: 0.4575 - val_loss: 1.6085 - val_acc: 0.4028\n",
      "Epoch 620/1000\n",
      "1152/1152 [==============================] - 1s 596us/step - loss: 1.5134 - acc: 0.4410 - val_loss: 1.6018 - val_acc: 0.3854\n",
      "Epoch 621/1000\n",
      "1152/1152 [==============================] - 1s 602us/step - loss: 1.4974 - acc: 0.4488 - val_loss: 1.6055 - val_acc: 0.3993\n",
      "Epoch 622/1000\n",
      "1152/1152 [==============================] - 1s 598us/step - loss: 1.4982 - acc: 0.4627 - val_loss: 1.5967 - val_acc: 0.3924\n",
      "Epoch 623/1000\n",
      "1152/1152 [==============================] - 1s 713us/step - loss: 1.5020 - acc: 0.4627 - val_loss: 1.6035 - val_acc: 0.3993\n",
      "Epoch 624/1000\n",
      "1152/1152 [==============================] - 1s 532us/step - loss: 1.4976 - acc: 0.4696 - val_loss: 1.6064 - val_acc: 0.3854\n",
      "Epoch 625/1000\n",
      "1152/1152 [==============================] - 1s 629us/step - loss: 1.4932 - acc: 0.4479 - val_loss: 1.5953 - val_acc: 0.3854\n",
      "Epoch 626/1000\n",
      "1152/1152 [==============================] - 1s 605us/step - loss: 1.4877 - acc: 0.4731 - val_loss: 1.6045 - val_acc: 0.3854\n",
      "Epoch 627/1000\n",
      "1152/1152 [==============================] - 1s 592us/step - loss: 1.4919 - acc: 0.4470 - val_loss: 1.6066 - val_acc: 0.3889\n",
      "Epoch 628/1000\n",
      "1152/1152 [==============================] - 1s 614us/step - loss: 1.4989 - acc: 0.4488 - val_loss: 1.6093 - val_acc: 0.3715\n",
      "Epoch 629/1000\n",
      "1152/1152 [==============================] - 1s 592us/step - loss: 1.4990 - acc: 0.4462 - val_loss: 1.6169 - val_acc: 0.3889\n",
      "Epoch 630/1000\n",
      "1152/1152 [==============================] - 1s 596us/step - loss: 1.4761 - acc: 0.4601 - val_loss: 1.6249 - val_acc: 0.3750\n",
      "Epoch 631/1000\n",
      "1152/1152 [==============================] - 1s 581us/step - loss: 1.4958 - acc: 0.4609 - val_loss: 1.6096 - val_acc: 0.3993\n",
      "Epoch 632/1000\n",
      "1152/1152 [==============================] - 1s 576us/step - loss: 1.4922 - acc: 0.4479 - val_loss: 1.6056 - val_acc: 0.3924\n",
      "Epoch 633/1000\n",
      "1152/1152 [==============================] - 1s 626us/step - loss: 1.4876 - acc: 0.4470 - val_loss: 1.6003 - val_acc: 0.4062\n",
      "Epoch 634/1000\n",
      "1152/1152 [==============================] - 1s 635us/step - loss: 1.4983 - acc: 0.4601 - val_loss: 1.5943 - val_acc: 0.4167\n",
      "Epoch 635/1000\n",
      "1152/1152 [==============================] - 1s 628us/step - loss: 1.4882 - acc: 0.4661 - val_loss: 1.6162 - val_acc: 0.3750\n",
      "Epoch 636/1000\n",
      "1152/1152 [==============================] - 1s 599us/step - loss: 1.4930 - acc: 0.4661 - val_loss: 1.5957 - val_acc: 0.3993\n",
      "Epoch 637/1000\n",
      "1152/1152 [==============================] - 1s 676us/step - loss: 1.4816 - acc: 0.4774 - val_loss: 1.5969 - val_acc: 0.3889\n",
      "Epoch 638/1000\n",
      "1152/1152 [==============================] - 1s 589us/step - loss: 1.4822 - acc: 0.4609 - val_loss: 1.6052 - val_acc: 0.4062\n",
      "Epoch 639/1000\n",
      "1152/1152 [==============================] - 1s 590us/step - loss: 1.4994 - acc: 0.4470 - val_loss: 1.5974 - val_acc: 0.3924\n",
      "Epoch 640/1000\n",
      "1152/1152 [==============================] - 1s 606us/step - loss: 1.4719 - acc: 0.4601 - val_loss: 1.6080 - val_acc: 0.3854\n",
      "Epoch 641/1000\n",
      "1152/1152 [==============================] - 1s 627us/step - loss: 1.4927 - acc: 0.4366 - val_loss: 1.5954 - val_acc: 0.4062\n",
      "Epoch 642/1000\n",
      "1152/1152 [==============================] - 1s 629us/step - loss: 1.4884 - acc: 0.4436 - val_loss: 1.6007 - val_acc: 0.3993\n",
      "Epoch 643/1000\n",
      "1152/1152 [==============================] - 1s 639us/step - loss: 1.4707 - acc: 0.4644 - val_loss: 1.6095 - val_acc: 0.3889\n",
      "Epoch 644/1000\n",
      "1152/1152 [==============================] - 1s 589us/step - loss: 1.4783 - acc: 0.4497 - val_loss: 1.5922 - val_acc: 0.4028\n",
      "Epoch 645/1000\n",
      "1152/1152 [==============================] - 1s 634us/step - loss: 1.4779 - acc: 0.4418 - val_loss: 1.5936 - val_acc: 0.3958\n",
      "Epoch 646/1000\n",
      "1152/1152 [==============================] - 1s 681us/step - loss: 1.4759 - acc: 0.4627 - val_loss: 1.5927 - val_acc: 0.4028\n",
      "Epoch 647/1000\n",
      "1152/1152 [==============================] - 1s 572us/step - loss: 1.4737 - acc: 0.4349 - val_loss: 1.5884 - val_acc: 0.4028\n",
      "Epoch 648/1000\n",
      "1152/1152 [==============================] - 1s 661us/step - loss: 1.4841 - acc: 0.4583 - val_loss: 1.5907 - val_acc: 0.4062\n",
      "Epoch 649/1000\n",
      "1152/1152 [==============================] - 1s 619us/step - loss: 1.4760 - acc: 0.4644 - val_loss: 1.5835 - val_acc: 0.3681\n",
      "Epoch 650/1000\n",
      "1152/1152 [==============================] - 1s 589us/step - loss: 1.4819 - acc: 0.4575 - val_loss: 1.5922 - val_acc: 0.3958\n",
      "Epoch 651/1000\n",
      "1152/1152 [==============================] - 1s 603us/step - loss: 1.4777 - acc: 0.4549 - val_loss: 1.5918 - val_acc: 0.3993\n",
      "Epoch 652/1000\n",
      "1152/1152 [==============================] - 1s 608us/step - loss: 1.4847 - acc: 0.4705 - val_loss: 1.5902 - val_acc: 0.3785\n",
      "Epoch 653/1000\n",
      "1152/1152 [==============================] - 1s 633us/step - loss: 1.4689 - acc: 0.4644 - val_loss: 1.5930 - val_acc: 0.4028\n",
      "Epoch 654/1000\n",
      "1152/1152 [==============================] - 1s 608us/step - loss: 1.4767 - acc: 0.4566 - val_loss: 1.5942 - val_acc: 0.3958\n",
      "Epoch 655/1000\n",
      "1152/1152 [==============================] - 1s 621us/step - loss: 1.4778 - acc: 0.4705 - val_loss: 1.5855 - val_acc: 0.4236\n",
      "Epoch 656/1000\n",
      "1152/1152 [==============================] - 1s 626us/step - loss: 1.4710 - acc: 0.4566 - val_loss: 1.5810 - val_acc: 0.4097\n",
      "Epoch 657/1000\n",
      "1152/1152 [==============================] - 1s 625us/step - loss: 1.4757 - acc: 0.4670 - val_loss: 1.5979 - val_acc: 0.3785\n",
      "Epoch 658/1000\n",
      "1152/1152 [==============================] - 1s 611us/step - loss: 1.4788 - acc: 0.4549 - val_loss: 1.5829 - val_acc: 0.3993\n",
      "Epoch 659/1000\n",
      "1152/1152 [==============================] - 1s 584us/step - loss: 1.4692 - acc: 0.4740 - val_loss: 1.5961 - val_acc: 0.3924\n",
      "Epoch 660/1000\n",
      "1152/1152 [==============================] - 1s 618us/step - loss: 1.4801 - acc: 0.4505 - val_loss: 1.5871 - val_acc: 0.3889\n",
      "Epoch 661/1000\n",
      "1152/1152 [==============================] - 1s 603us/step - loss: 1.4610 - acc: 0.4653 - val_loss: 1.5807 - val_acc: 0.3854\n",
      "Epoch 662/1000\n",
      "1152/1152 [==============================] - 1s 617us/step - loss: 1.4663 - acc: 0.4826 - val_loss: 1.5831 - val_acc: 0.3993\n",
      "Epoch 663/1000\n",
      "1152/1152 [==============================] - 1s 597us/step - loss: 1.4765 - acc: 0.4583 - val_loss: 1.5855 - val_acc: 0.3958\n",
      "Epoch 664/1000\n",
      "1152/1152 [==============================] - 1s 605us/step - loss: 1.4691 - acc: 0.4688 - val_loss: 1.6105 - val_acc: 0.3715\n",
      "Epoch 665/1000\n",
      "1152/1152 [==============================] - 1s 610us/step - loss: 1.4714 - acc: 0.4757 - val_loss: 1.5815 - val_acc: 0.3854\n",
      "Epoch 666/1000\n",
      "1152/1152 [==============================] - 1s 585us/step - loss: 1.4707 - acc: 0.4627 - val_loss: 1.5935 - val_acc: 0.3889\n",
      "Epoch 667/1000\n",
      "1152/1152 [==============================] - 1s 610us/step - loss: 1.4670 - acc: 0.4783 - val_loss: 1.5859 - val_acc: 0.4132\n",
      "Epoch 668/1000\n",
      "1152/1152 [==============================] - 1s 671us/step - loss: 1.4679 - acc: 0.4627 - val_loss: 1.6030 - val_acc: 0.3958\n",
      "Epoch 669/1000\n",
      "1152/1152 [==============================] - 1s 634us/step - loss: 1.4672 - acc: 0.4722 - val_loss: 1.5868 - val_acc: 0.4028\n",
      "Epoch 670/1000\n",
      "1152/1152 [==============================] - 1s 609us/step - loss: 1.4757 - acc: 0.4653 - val_loss: 1.5794 - val_acc: 0.3924\n",
      "Epoch 671/1000\n",
      "1152/1152 [==============================] - 1s 600us/step - loss: 1.4521 - acc: 0.4740 - val_loss: 1.5931 - val_acc: 0.4097\n",
      "Epoch 672/1000\n",
      "1152/1152 [==============================] - 1s 611us/step - loss: 1.4698 - acc: 0.4644 - val_loss: 1.5833 - val_acc: 0.3819\n",
      "Epoch 673/1000\n",
      "1152/1152 [==============================] - 1s 594us/step - loss: 1.4640 - acc: 0.4488 - val_loss: 1.5838 - val_acc: 0.4028\n",
      "Epoch 674/1000\n",
      "1152/1152 [==============================] - 1s 613us/step - loss: 1.4517 - acc: 0.4766 - val_loss: 1.5829 - val_acc: 0.4097\n",
      "Epoch 675/1000\n",
      "1152/1152 [==============================] - 1s 591us/step - loss: 1.4575 - acc: 0.4661 - val_loss: 1.5775 - val_acc: 0.3958\n",
      "Epoch 676/1000\n",
      "1152/1152 [==============================] - 1s 578us/step - loss: 1.4616 - acc: 0.4479 - val_loss: 1.5849 - val_acc: 0.4062\n",
      "Epoch 677/1000\n",
      "1152/1152 [==============================] - 1s 564us/step - loss: 1.4653 - acc: 0.4635 - val_loss: 1.5814 - val_acc: 0.3924\n",
      "Epoch 678/1000\n",
      "1152/1152 [==============================] - 1s 621us/step - loss: 1.4485 - acc: 0.4757 - val_loss: 1.5805 - val_acc: 0.3924\n",
      "Epoch 679/1000\n",
      "1152/1152 [==============================] - 1s 603us/step - loss: 1.4564 - acc: 0.4913 - val_loss: 1.5778 - val_acc: 0.4062\n",
      "Epoch 680/1000\n",
      "1152/1152 [==============================] - 1s 601us/step - loss: 1.4546 - acc: 0.4688 - val_loss: 1.5843 - val_acc: 0.4062\n",
      "Epoch 681/1000\n",
      "1152/1152 [==============================] - 1s 597us/step - loss: 1.4640 - acc: 0.4696 - val_loss: 1.5771 - val_acc: 0.3958\n",
      "Epoch 682/1000\n",
      "1152/1152 [==============================] - 1s 621us/step - loss: 1.4553 - acc: 0.4861 - val_loss: 1.5892 - val_acc: 0.4097\n",
      "Epoch 683/1000\n",
      "1152/1152 [==============================] - 1s 608us/step - loss: 1.4614 - acc: 0.4748 - val_loss: 1.5875 - val_acc: 0.4028\n",
      "Epoch 684/1000\n",
      "1152/1152 [==============================] - 1s 614us/step - loss: 1.4529 - acc: 0.4835 - val_loss: 1.5769 - val_acc: 0.3889\n",
      "Epoch 685/1000\n",
      "1152/1152 [==============================] - 1s 595us/step - loss: 1.4471 - acc: 0.4766 - val_loss: 1.5778 - val_acc: 0.4167\n",
      "Epoch 686/1000\n",
      "1152/1152 [==============================] - 1s 582us/step - loss: 1.4536 - acc: 0.4714 - val_loss: 1.5859 - val_acc: 0.3819\n",
      "Epoch 687/1000\n",
      "1152/1152 [==============================] - 1s 607us/step - loss: 1.4582 - acc: 0.4714 - val_loss: 1.5640 - val_acc: 0.3958\n",
      "Epoch 688/1000\n",
      "1152/1152 [==============================] - 1s 621us/step - loss: 1.4526 - acc: 0.4653 - val_loss: 1.5864 - val_acc: 0.4028\n",
      "Epoch 689/1000\n",
      "1152/1152 [==============================] - 1s 619us/step - loss: 1.4559 - acc: 0.4783 - val_loss: 1.5779 - val_acc: 0.4062\n",
      "Epoch 690/1000\n",
      "1152/1152 [==============================] - 1s 554us/step - loss: 1.4733 - acc: 0.4688 - val_loss: 1.5751 - val_acc: 0.3924\n",
      "Epoch 691/1000\n",
      "1152/1152 [==============================] - 1s 663us/step - loss: 1.4451 - acc: 0.4809 - val_loss: 1.5805 - val_acc: 0.3854\n",
      "Epoch 692/1000\n",
      "1152/1152 [==============================] - 1s 627us/step - loss: 1.4606 - acc: 0.4670 - val_loss: 1.5712 - val_acc: 0.3993\n",
      "Epoch 693/1000\n",
      "1152/1152 [==============================] - 1s 598us/step - loss: 1.4503 - acc: 0.4696 - val_loss: 1.5804 - val_acc: 0.3993\n",
      "Epoch 694/1000\n",
      "1152/1152 [==============================] - 1s 592us/step - loss: 1.4528 - acc: 0.4870 - val_loss: 1.5773 - val_acc: 0.3993\n",
      "Epoch 695/1000\n",
      "1152/1152 [==============================] - 1s 622us/step - loss: 1.4484 - acc: 0.4783 - val_loss: 1.5742 - val_acc: 0.4167\n",
      "Epoch 696/1000\n",
      "1152/1152 [==============================] - 1s 614us/step - loss: 1.4425 - acc: 0.4861 - val_loss: 1.5768 - val_acc: 0.3958\n",
      "Epoch 697/1000\n",
      "1152/1152 [==============================] - 1s 612us/step - loss: 1.4482 - acc: 0.4714 - val_loss: 1.5775 - val_acc: 0.4132\n",
      "Epoch 698/1000\n",
      "1152/1152 [==============================] - 1s 618us/step - loss: 1.4426 - acc: 0.4757 - val_loss: 1.5721 - val_acc: 0.3958\n",
      "Epoch 699/1000\n",
      "1152/1152 [==============================] - 1s 608us/step - loss: 1.4459 - acc: 0.4609 - val_loss: 1.5702 - val_acc: 0.3993\n",
      "Epoch 700/1000\n",
      "1152/1152 [==============================] - 1s 598us/step - loss: 1.4246 - acc: 0.5017 - val_loss: 1.5629 - val_acc: 0.4132\n",
      "Epoch 701/1000\n",
      "1152/1152 [==============================] - 1s 596us/step - loss: 1.4492 - acc: 0.4792 - val_loss: 1.5749 - val_acc: 0.4062\n",
      "Epoch 702/1000\n",
      "1152/1152 [==============================] - 1s 643us/step - loss: 1.4438 - acc: 0.4722 - val_loss: 1.5714 - val_acc: 0.3924\n",
      "Epoch 703/1000\n",
      "1152/1152 [==============================] - 1s 601us/step - loss: 1.4396 - acc: 0.4679 - val_loss: 1.5669 - val_acc: 0.3993\n",
      "Epoch 704/1000\n",
      "1152/1152 [==============================] - 1s 608us/step - loss: 1.4547 - acc: 0.4618 - val_loss: 1.5848 - val_acc: 0.3958\n",
      "Epoch 705/1000\n",
      "1152/1152 [==============================] - 1s 636us/step - loss: 1.4313 - acc: 0.4670 - val_loss: 1.5784 - val_acc: 0.4236\n",
      "Epoch 706/1000\n",
      "1152/1152 [==============================] - 1s 627us/step - loss: 1.4519 - acc: 0.4479 - val_loss: 1.5781 - val_acc: 0.3993\n",
      "Epoch 707/1000\n",
      "1152/1152 [==============================] - 1s 595us/step - loss: 1.4294 - acc: 0.4792 - val_loss: 1.5710 - val_acc: 0.4062\n",
      "Epoch 708/1000\n",
      "1152/1152 [==============================] - 1s 612us/step - loss: 1.4327 - acc: 0.4887 - val_loss: 1.5638 - val_acc: 0.3889\n",
      "Epoch 709/1000\n",
      "1152/1152 [==============================] - 1s 619us/step - loss: 1.4399 - acc: 0.4731 - val_loss: 1.5647 - val_acc: 0.3958\n",
      "Epoch 710/1000\n",
      "1152/1152 [==============================] - 1s 589us/step - loss: 1.4418 - acc: 0.4774 - val_loss: 1.5714 - val_acc: 0.4062\n",
      "Epoch 711/1000\n",
      "1152/1152 [==============================] - 1s 657us/step - loss: 1.4400 - acc: 0.4792 - val_loss: 1.5688 - val_acc: 0.4271\n",
      "Epoch 712/1000\n",
      "1152/1152 [==============================] - 1s 625us/step - loss: 1.4504 - acc: 0.4757 - val_loss: 1.5691 - val_acc: 0.4167\n",
      "Epoch 713/1000\n",
      "1152/1152 [==============================] - 1s 655us/step - loss: 1.4317 - acc: 0.4800 - val_loss: 1.5779 - val_acc: 0.4132\n",
      "Epoch 714/1000\n",
      "1152/1152 [==============================] - 1s 701us/step - loss: 1.4506 - acc: 0.4644 - val_loss: 1.5610 - val_acc: 0.4132\n",
      "Epoch 715/1000\n",
      "1152/1152 [==============================] - 1s 660us/step - loss: 1.4415 - acc: 0.4748 - val_loss: 1.5817 - val_acc: 0.4132\n",
      "Epoch 716/1000\n",
      "1152/1152 [==============================] - 1s 599us/step - loss: 1.4243 - acc: 0.4783 - val_loss: 1.5645 - val_acc: 0.4236\n",
      "Epoch 717/1000\n",
      "1152/1152 [==============================] - 1s 599us/step - loss: 1.4377 - acc: 0.4670 - val_loss: 1.5589 - val_acc: 0.4097\n",
      "Epoch 718/1000\n",
      "1152/1152 [==============================] - 1s 613us/step - loss: 1.4497 - acc: 0.4635 - val_loss: 1.5724 - val_acc: 0.3924\n",
      "Epoch 719/1000\n",
      "1152/1152 [==============================] - 1s 615us/step - loss: 1.4256 - acc: 0.4792 - val_loss: 1.5643 - val_acc: 0.4028\n",
      "Epoch 720/1000\n",
      "1152/1152 [==============================] - 1s 646us/step - loss: 1.4331 - acc: 0.4774 - val_loss: 1.5684 - val_acc: 0.3958\n",
      "Epoch 721/1000\n",
      "1152/1152 [==============================] - 1s 630us/step - loss: 1.4267 - acc: 0.4983 - val_loss: 1.5733 - val_acc: 0.3958\n",
      "Epoch 722/1000\n",
      "1152/1152 [==============================] - 1s 595us/step - loss: 1.4286 - acc: 0.4939 - val_loss: 1.5701 - val_acc: 0.3924\n",
      "Epoch 723/1000\n",
      "1152/1152 [==============================] - 1s 637us/step - loss: 1.4327 - acc: 0.4835 - val_loss: 1.5580 - val_acc: 0.4132\n",
      "Epoch 724/1000\n",
      "1152/1152 [==============================] - 1s 647us/step - loss: 1.4407 - acc: 0.4783 - val_loss: 1.5622 - val_acc: 0.3819\n",
      "Epoch 725/1000\n",
      "1152/1152 [==============================] - 1s 631us/step - loss: 1.4259 - acc: 0.4809 - val_loss: 1.5663 - val_acc: 0.4028\n",
      "Epoch 726/1000\n",
      "1152/1152 [==============================] - 1s 618us/step - loss: 1.4187 - acc: 0.4809 - val_loss: 1.5632 - val_acc: 0.4167\n",
      "Epoch 727/1000\n",
      "1152/1152 [==============================] - 1s 612us/step - loss: 1.4471 - acc: 0.4670 - val_loss: 1.5706 - val_acc: 0.4028\n",
      "Epoch 728/1000\n",
      "1152/1152 [==============================] - 1s 600us/step - loss: 1.4143 - acc: 0.4896 - val_loss: 1.5649 - val_acc: 0.4167\n",
      "Epoch 729/1000\n",
      "1152/1152 [==============================] - 1s 599us/step - loss: 1.4270 - acc: 0.4818 - val_loss: 1.5572 - val_acc: 0.4132\n",
      "Epoch 730/1000\n",
      "1152/1152 [==============================] - 1s 635us/step - loss: 1.4297 - acc: 0.4653 - val_loss: 1.5649 - val_acc: 0.4236\n",
      "Epoch 731/1000\n",
      "1152/1152 [==============================] - 1s 629us/step - loss: 1.4236 - acc: 0.4731 - val_loss: 1.5623 - val_acc: 0.4236\n",
      "Epoch 732/1000\n",
      "1152/1152 [==============================] - 1s 614us/step - loss: 1.4248 - acc: 0.4783 - val_loss: 1.5617 - val_acc: 0.4028\n",
      "Epoch 733/1000\n",
      "1152/1152 [==============================] - 1s 609us/step - loss: 1.4291 - acc: 0.4661 - val_loss: 1.5525 - val_acc: 0.4201\n",
      "Epoch 734/1000\n",
      "1152/1152 [==============================] - 1s 596us/step - loss: 1.4356 - acc: 0.4844 - val_loss: 1.5538 - val_acc: 0.4028\n",
      "Epoch 735/1000\n",
      "1152/1152 [==============================] - 1s 631us/step - loss: 1.4224 - acc: 0.4809 - val_loss: 1.5576 - val_acc: 0.3924\n",
      "Epoch 736/1000\n",
      "1152/1152 [==============================] - 1s 699us/step - loss: 1.4126 - acc: 0.4844 - val_loss: 1.5712 - val_acc: 0.4132\n",
      "Epoch 737/1000\n",
      "1152/1152 [==============================] - 1s 541us/step - loss: 1.4272 - acc: 0.4870 - val_loss: 1.5580 - val_acc: 0.4062\n",
      "Epoch 738/1000\n",
      "1152/1152 [==============================] - 1s 644us/step - loss: 1.4325 - acc: 0.4835 - val_loss: 1.5546 - val_acc: 0.4028\n",
      "Epoch 739/1000\n",
      "1152/1152 [==============================] - 1s 619us/step - loss: 1.4186 - acc: 0.4774 - val_loss: 1.5576 - val_acc: 0.4236\n",
      "Epoch 740/1000\n",
      "1152/1152 [==============================] - 1s 605us/step - loss: 1.4276 - acc: 0.4766 - val_loss: 1.5476 - val_acc: 0.4097\n",
      "Epoch 741/1000\n",
      "1152/1152 [==============================] - 1s 599us/step - loss: 1.4213 - acc: 0.4991 - val_loss: 1.5507 - val_acc: 0.3854\n",
      "Epoch 742/1000\n",
      "1152/1152 [==============================] - 1s 651us/step - loss: 1.4142 - acc: 0.4792 - val_loss: 1.5533 - val_acc: 0.4201\n",
      "Epoch 743/1000\n",
      "1152/1152 [==============================] - 1s 604us/step - loss: 1.4109 - acc: 0.4965 - val_loss: 1.5621 - val_acc: 0.3854\n",
      "Epoch 744/1000\n",
      "1152/1152 [==============================] - 1s 632us/step - loss: 1.4189 - acc: 0.4905 - val_loss: 1.5568 - val_acc: 0.4132\n",
      "Epoch 745/1000\n",
      "1152/1152 [==============================] - 1s 615us/step - loss: 1.4141 - acc: 0.4809 - val_loss: 1.5535 - val_acc: 0.4132\n",
      "Epoch 746/1000\n",
      "1152/1152 [==============================] - 1s 627us/step - loss: 1.4194 - acc: 0.4766 - val_loss: 1.5521 - val_acc: 0.3924\n",
      "Epoch 747/1000\n",
      "1152/1152 [==============================] - 1s 617us/step - loss: 1.4153 - acc: 0.4913 - val_loss: 1.5440 - val_acc: 0.4097\n",
      "Epoch 748/1000\n",
      "1152/1152 [==============================] - 1s 626us/step - loss: 1.4106 - acc: 0.4852 - val_loss: 1.5486 - val_acc: 0.4236\n",
      "Epoch 749/1000\n",
      "1152/1152 [==============================] - 1s 645us/step - loss: 1.4159 - acc: 0.4705 - val_loss: 1.5559 - val_acc: 0.4306\n",
      "Epoch 750/1000\n",
      "1152/1152 [==============================] - 1s 622us/step - loss: 1.4009 - acc: 0.4931 - val_loss: 1.5535 - val_acc: 0.3958\n",
      "Epoch 751/1000\n",
      "1152/1152 [==============================] - 1s 643us/step - loss: 1.4177 - acc: 0.4983 - val_loss: 1.5629 - val_acc: 0.4028\n",
      "Epoch 752/1000\n",
      "1152/1152 [==============================] - 1s 641us/step - loss: 1.4110 - acc: 0.4878 - val_loss: 1.5525 - val_acc: 0.4271\n",
      "Epoch 753/1000\n",
      "1152/1152 [==============================] - 1s 615us/step - loss: 1.4236 - acc: 0.4783 - val_loss: 1.5510 - val_acc: 0.4306\n",
      "Epoch 754/1000\n",
      "1152/1152 [==============================] - 1s 640us/step - loss: 1.4092 - acc: 0.5000 - val_loss: 1.5464 - val_acc: 0.4236\n",
      "Epoch 755/1000\n",
      "1152/1152 [==============================] - 1s 643us/step - loss: 1.4113 - acc: 0.4826 - val_loss: 1.5502 - val_acc: 0.4132\n",
      "Epoch 756/1000\n",
      "1152/1152 [==============================] - 1s 642us/step - loss: 1.4025 - acc: 0.4965 - val_loss: 1.5632 - val_acc: 0.4132\n",
      "Epoch 757/1000\n",
      "1152/1152 [==============================] - 1s 633us/step - loss: 1.4268 - acc: 0.4800 - val_loss: 1.5679 - val_acc: 0.4097\n",
      "Epoch 758/1000\n",
      "1152/1152 [==============================] - 1s 705us/step - loss: 1.4089 - acc: 0.4887 - val_loss: 1.5549 - val_acc: 0.4201\n",
      "Epoch 759/1000\n",
      "1152/1152 [==============================] - 1s 524us/step - loss: 1.4014 - acc: 0.4887 - val_loss: 1.5408 - val_acc: 0.4097\n",
      "Epoch 760/1000\n",
      "1152/1152 [==============================] - 1s 657us/step - loss: 1.4040 - acc: 0.4835 - val_loss: 1.5453 - val_acc: 0.3993\n",
      "Epoch 761/1000\n",
      "1152/1152 [==============================] - 1s 620us/step - loss: 1.4118 - acc: 0.4896 - val_loss: 1.5550 - val_acc: 0.4201\n",
      "Epoch 762/1000\n",
      "1152/1152 [==============================] - 1s 648us/step - loss: 1.4088 - acc: 0.4835 - val_loss: 1.5449 - val_acc: 0.4236\n",
      "Epoch 763/1000\n",
      "1152/1152 [==============================] - 1s 646us/step - loss: 1.4065 - acc: 0.4957 - val_loss: 1.5412 - val_acc: 0.3924\n",
      "Epoch 764/1000\n",
      "1152/1152 [==============================] - 1s 653us/step - loss: 1.4093 - acc: 0.4826 - val_loss: 1.5452 - val_acc: 0.4306\n",
      "Epoch 765/1000\n",
      "1152/1152 [==============================] - 1s 594us/step - loss: 1.4018 - acc: 0.4896 - val_loss: 1.5396 - val_acc: 0.3993\n",
      "Epoch 766/1000\n",
      "1152/1152 [==============================] - 1s 608us/step - loss: 1.4087 - acc: 0.4913 - val_loss: 1.5515 - val_acc: 0.4097\n",
      "Epoch 767/1000\n",
      "1152/1152 [==============================] - 1s 599us/step - loss: 1.4078 - acc: 0.4844 - val_loss: 1.5456 - val_acc: 0.4062\n",
      "Epoch 768/1000\n",
      "1152/1152 [==============================] - 1s 613us/step - loss: 1.4103 - acc: 0.4870 - val_loss: 1.5496 - val_acc: 0.3889\n",
      "Epoch 769/1000\n",
      "1152/1152 [==============================] - 1s 634us/step - loss: 1.4330 - acc: 0.4661 - val_loss: 1.5475 - val_acc: 0.4062\n",
      "Epoch 770/1000\n",
      "1152/1152 [==============================] - 1s 616us/step - loss: 1.4100 - acc: 0.4774 - val_loss: 1.5586 - val_acc: 0.4340\n",
      "Epoch 771/1000\n",
      "1152/1152 [==============================] - 1s 615us/step - loss: 1.3927 - acc: 0.4922 - val_loss: 1.5421 - val_acc: 0.3889\n",
      "Epoch 772/1000\n",
      "1152/1152 [==============================] - 1s 633us/step - loss: 1.3959 - acc: 0.4905 - val_loss: 1.5424 - val_acc: 0.3854\n",
      "Epoch 773/1000\n",
      "1152/1152 [==============================] - 1s 634us/step - loss: 1.3882 - acc: 0.4974 - val_loss: 1.5483 - val_acc: 0.3993\n",
      "Epoch 774/1000\n",
      "1152/1152 [==============================] - 1s 588us/step - loss: 1.3981 - acc: 0.4974 - val_loss: 1.5380 - val_acc: 0.4028\n",
      "Epoch 775/1000\n",
      "1152/1152 [==============================] - 1s 601us/step - loss: 1.4039 - acc: 0.4783 - val_loss: 1.5552 - val_acc: 0.4167\n",
      "Epoch 776/1000\n",
      "1152/1152 [==============================] - 1s 630us/step - loss: 1.3970 - acc: 0.4809 - val_loss: 1.5425 - val_acc: 0.4028\n",
      "Epoch 777/1000\n",
      "1152/1152 [==============================] - 1s 626us/step - loss: 1.3957 - acc: 0.4887 - val_loss: 1.5466 - val_acc: 0.4132\n",
      "Epoch 778/1000\n",
      "1152/1152 [==============================] - 1s 613us/step - loss: 1.3920 - acc: 0.4991 - val_loss: 1.5412 - val_acc: 0.4062\n",
      "Epoch 779/1000\n",
      "1152/1152 [==============================] - 1s 633us/step - loss: 1.3843 - acc: 0.5069 - val_loss: 1.5508 - val_acc: 0.3993\n",
      "Epoch 780/1000\n",
      "1152/1152 [==============================] - 1s 694us/step - loss: 1.4017 - acc: 0.4957 - val_loss: 1.5414 - val_acc: 0.4062\n",
      "Epoch 781/1000\n",
      "1152/1152 [==============================] - 1s 672us/step - loss: 1.4062 - acc: 0.4740 - val_loss: 1.5454 - val_acc: 0.4132\n",
      "Epoch 782/1000\n",
      "1152/1152 [==============================] - 1s 603us/step - loss: 1.3860 - acc: 0.4983 - val_loss: 1.5350 - val_acc: 0.3993\n",
      "Epoch 783/1000\n",
      "1152/1152 [==============================] - 1s 607us/step - loss: 1.3885 - acc: 0.4948 - val_loss: 1.5402 - val_acc: 0.4132\n",
      "Epoch 784/1000\n",
      "1152/1152 [==============================] - 1s 682us/step - loss: 1.3914 - acc: 0.4835 - val_loss: 1.5408 - val_acc: 0.4271\n",
      "Epoch 785/1000\n",
      "1152/1152 [==============================] - 1s 643us/step - loss: 1.3955 - acc: 0.4887 - val_loss: 1.5398 - val_acc: 0.4167\n",
      "Epoch 786/1000\n",
      "1152/1152 [==============================] - 1s 627us/step - loss: 1.4006 - acc: 0.4740 - val_loss: 1.5244 - val_acc: 0.3924\n",
      "Epoch 787/1000\n",
      "1152/1152 [==============================] - 1s 608us/step - loss: 1.4039 - acc: 0.4826 - val_loss: 1.5307 - val_acc: 0.3924\n",
      "Epoch 788/1000\n",
      "1152/1152 [==============================] - 1s 641us/step - loss: 1.3941 - acc: 0.5000 - val_loss: 1.5418 - val_acc: 0.4132\n",
      "Epoch 789/1000\n",
      "1152/1152 [==============================] - 1s 634us/step - loss: 1.4006 - acc: 0.4870 - val_loss: 1.5392 - val_acc: 0.4410\n",
      "Epoch 790/1000\n",
      "1152/1152 [==============================] - 1s 624us/step - loss: 1.3642 - acc: 0.5122 - val_loss: 1.5486 - val_acc: 0.4271\n",
      "Epoch 791/1000\n",
      "1152/1152 [==============================] - 1s 617us/step - loss: 1.3850 - acc: 0.4852 - val_loss: 1.5357 - val_acc: 0.3958\n",
      "Epoch 792/1000\n",
      "1152/1152 [==============================] - 1s 631us/step - loss: 1.3889 - acc: 0.4931 - val_loss: 1.5328 - val_acc: 0.4375\n",
      "Epoch 793/1000\n",
      "1152/1152 [==============================] - 1s 635us/step - loss: 1.3862 - acc: 0.4991 - val_loss: 1.5325 - val_acc: 0.4097\n",
      "Epoch 794/1000\n",
      "1152/1152 [==============================] - 1s 642us/step - loss: 1.3890 - acc: 0.4931 - val_loss: 1.5477 - val_acc: 0.4132\n",
      "Epoch 795/1000\n",
      "1152/1152 [==============================] - 1s 649us/step - loss: 1.3837 - acc: 0.5035 - val_loss: 1.5270 - val_acc: 0.3924\n",
      "Epoch 796/1000\n",
      "1152/1152 [==============================] - 1s 624us/step - loss: 1.3902 - acc: 0.4939 - val_loss: 1.5307 - val_acc: 0.4167\n",
      "Epoch 797/1000\n",
      "1152/1152 [==============================] - 1s 623us/step - loss: 1.3807 - acc: 0.4948 - val_loss: 1.5390 - val_acc: 0.4132\n",
      "Epoch 798/1000\n",
      "1152/1152 [==============================] - 1s 619us/step - loss: 1.3859 - acc: 0.4913 - val_loss: 1.5360 - val_acc: 0.4062\n",
      "Epoch 799/1000\n",
      "1152/1152 [==============================] - 1s 646us/step - loss: 1.3839 - acc: 0.4905 - val_loss: 1.5399 - val_acc: 0.4132\n",
      "Epoch 800/1000\n",
      "1152/1152 [==============================] - 1s 608us/step - loss: 1.3819 - acc: 0.4905 - val_loss: 1.5316 - val_acc: 0.4201\n",
      "Epoch 801/1000\n",
      "1152/1152 [==============================] - 1s 629us/step - loss: 1.3756 - acc: 0.5017 - val_loss: 1.5338 - val_acc: 0.3958\n",
      "Epoch 802/1000\n",
      "1152/1152 [==============================] - 1s 729us/step - loss: 1.3845 - acc: 0.4870 - val_loss: 1.5283 - val_acc: 0.4340\n",
      "Epoch 803/1000\n",
      "1152/1152 [==============================] - 1s 581us/step - loss: 1.3962 - acc: 0.4844 - val_loss: 1.5420 - val_acc: 0.3819\n",
      "Epoch 804/1000\n",
      "1152/1152 [==============================] - 1s 647us/step - loss: 1.3802 - acc: 0.5035 - val_loss: 1.5395 - val_acc: 0.4201\n",
      "Epoch 805/1000\n",
      "1152/1152 [==============================] - 1s 622us/step - loss: 1.3818 - acc: 0.5000 - val_loss: 1.5420 - val_acc: 0.3785\n",
      "Epoch 806/1000\n",
      "1152/1152 [==============================] - 1s 637us/step - loss: 1.3721 - acc: 0.5035 - val_loss: 1.5395 - val_acc: 0.4132\n",
      "Epoch 807/1000\n",
      "1152/1152 [==============================] - 1s 597us/step - loss: 1.3738 - acc: 0.5078 - val_loss: 1.5326 - val_acc: 0.4097\n",
      "Epoch 808/1000\n",
      "1152/1152 [==============================] - 1s 610us/step - loss: 1.3841 - acc: 0.5078 - val_loss: 1.5442 - val_acc: 0.4097\n",
      "Epoch 809/1000\n",
      "1152/1152 [==============================] - 1s 624us/step - loss: 1.3797 - acc: 0.4922 - val_loss: 1.5317 - val_acc: 0.4097\n",
      "Epoch 810/1000\n",
      "1152/1152 [==============================] - 1s 654us/step - loss: 1.3770 - acc: 0.4939 - val_loss: 1.5395 - val_acc: 0.3993\n",
      "Epoch 811/1000\n",
      "1152/1152 [==============================] - 1s 611us/step - loss: 1.3735 - acc: 0.5061 - val_loss: 1.5382 - val_acc: 0.4132\n",
      "Epoch 812/1000\n",
      "1152/1152 [==============================] - 1s 601us/step - loss: 1.3850 - acc: 0.4931 - val_loss: 1.5406 - val_acc: 0.4201\n",
      "Epoch 813/1000\n",
      "1152/1152 [==============================] - 1s 601us/step - loss: 1.3914 - acc: 0.5017 - val_loss: 1.5315 - val_acc: 0.4167\n",
      "Epoch 814/1000\n",
      "1152/1152 [==============================] - 1s 623us/step - loss: 1.3809 - acc: 0.4939 - val_loss: 1.5298 - val_acc: 0.4340\n",
      "Epoch 815/1000\n",
      "1152/1152 [==============================] - 1s 635us/step - loss: 1.3588 - acc: 0.5148 - val_loss: 1.5195 - val_acc: 0.3958\n",
      "Epoch 816/1000\n",
      "1152/1152 [==============================] - 1s 626us/step - loss: 1.3649 - acc: 0.5061 - val_loss: 1.5357 - val_acc: 0.4062\n",
      "Epoch 817/1000\n",
      "1152/1152 [==============================] - 1s 647us/step - loss: 1.3725 - acc: 0.4826 - val_loss: 1.5283 - val_acc: 0.4375\n",
      "Epoch 818/1000\n",
      "1152/1152 [==============================] - 1s 632us/step - loss: 1.3739 - acc: 0.4974 - val_loss: 1.5314 - val_acc: 0.4410\n",
      "Epoch 819/1000\n",
      "1152/1152 [==============================] - 1s 642us/step - loss: 1.3825 - acc: 0.5148 - val_loss: 1.5209 - val_acc: 0.4375\n",
      "Epoch 820/1000\n",
      "1152/1152 [==============================] - 1s 616us/step - loss: 1.3853 - acc: 0.5026 - val_loss: 1.5222 - val_acc: 0.4097\n",
      "Epoch 821/1000\n",
      "1152/1152 [==============================] - 1s 643us/step - loss: 1.3672 - acc: 0.4983 - val_loss: 1.5231 - val_acc: 0.4132\n",
      "Epoch 822/1000\n",
      "1152/1152 [==============================] - 1s 640us/step - loss: 1.3820 - acc: 0.5026 - val_loss: 1.5270 - val_acc: 0.4375\n",
      "Epoch 823/1000\n",
      "1152/1152 [==============================] - 1s 642us/step - loss: 1.3804 - acc: 0.5165 - val_loss: 1.5315 - val_acc: 0.4236\n",
      "Epoch 824/1000\n",
      "1152/1152 [==============================] - 1s 758us/step - loss: 1.3741 - acc: 0.5009 - val_loss: 1.5179 - val_acc: 0.4410\n",
      "Epoch 825/1000\n",
      "1152/1152 [==============================] - 1s 543us/step - loss: 1.3575 - acc: 0.5043 - val_loss: 1.5246 - val_acc: 0.4028\n",
      "Epoch 826/1000\n",
      "1152/1152 [==============================] - 1s 685us/step - loss: 1.3767 - acc: 0.4939 - val_loss: 1.5217 - val_acc: 0.4410\n",
      "Epoch 827/1000\n",
      "1152/1152 [==============================] - 1s 632us/step - loss: 1.3761 - acc: 0.5061 - val_loss: 1.5243 - val_acc: 0.3889\n",
      "Epoch 828/1000\n",
      "1152/1152 [==============================] - 1s 619us/step - loss: 1.3502 - acc: 0.5156 - val_loss: 1.5327 - val_acc: 0.4236\n",
      "Epoch 829/1000\n",
      "1152/1152 [==============================] - 1s 628us/step - loss: 1.3622 - acc: 0.5113 - val_loss: 1.5144 - val_acc: 0.4132\n",
      "Epoch 830/1000\n",
      "1152/1152 [==============================] - 1s 616us/step - loss: 1.3724 - acc: 0.5122 - val_loss: 1.5281 - val_acc: 0.4132\n",
      "Epoch 831/1000\n",
      "1152/1152 [==============================] - 1s 648us/step - loss: 1.3710 - acc: 0.5052 - val_loss: 1.5148 - val_acc: 0.3958\n",
      "Epoch 832/1000\n",
      "1152/1152 [==============================] - 1s 684us/step - loss: 1.3725 - acc: 0.4931 - val_loss: 1.5234 - val_acc: 0.4306\n",
      "Epoch 833/1000\n",
      "1152/1152 [==============================] - 1s 622us/step - loss: 1.3616 - acc: 0.5061 - val_loss: 1.5273 - val_acc: 0.4097\n",
      "Epoch 834/1000\n",
      "1152/1152 [==============================] - 1s 608us/step - loss: 1.3619 - acc: 0.5095 - val_loss: 1.5135 - val_acc: 0.4028\n",
      "Epoch 835/1000\n",
      "1152/1152 [==============================] - 1s 634us/step - loss: 1.3605 - acc: 0.5043 - val_loss: 1.5320 - val_acc: 0.4271\n",
      "Epoch 836/1000\n",
      "1152/1152 [==============================] - 1s 635us/step - loss: 1.3720 - acc: 0.4948 - val_loss: 1.5390 - val_acc: 0.4028\n",
      "Epoch 837/1000\n",
      "1152/1152 [==============================] - 1s 694us/step - loss: 1.3520 - acc: 0.5113 - val_loss: 1.5218 - val_acc: 0.4236\n",
      "Epoch 838/1000\n",
      "1152/1152 [==============================] - 1s 626us/step - loss: 1.3774 - acc: 0.4844 - val_loss: 1.5207 - val_acc: 0.3958\n",
      "Epoch 839/1000\n",
      "1152/1152 [==============================] - 1s 629us/step - loss: 1.3688 - acc: 0.5026 - val_loss: 1.5231 - val_acc: 0.3993\n",
      "Epoch 840/1000\n",
      "1152/1152 [==============================] - 1s 614us/step - loss: 1.3672 - acc: 0.5000 - val_loss: 1.5352 - val_acc: 0.4340\n",
      "Epoch 841/1000\n",
      "1152/1152 [==============================] - 1s 641us/step - loss: 1.3570 - acc: 0.5078 - val_loss: 1.5173 - val_acc: 0.4306\n",
      "Epoch 842/1000\n",
      "1152/1152 [==============================] - 1s 611us/step - loss: 1.3480 - acc: 0.5139 - val_loss: 1.5351 - val_acc: 0.4236\n",
      "Epoch 843/1000\n",
      "1152/1152 [==============================] - 1s 630us/step - loss: 1.3593 - acc: 0.5035 - val_loss: 1.5189 - val_acc: 0.4062\n",
      "Epoch 844/1000\n",
      "1152/1152 [==============================] - 1s 629us/step - loss: 1.3610 - acc: 0.5148 - val_loss: 1.5300 - val_acc: 0.4271\n",
      "Epoch 845/1000\n",
      "1152/1152 [==============================] - 1s 623us/step - loss: 1.3448 - acc: 0.5200 - val_loss: 1.5298 - val_acc: 0.3924\n",
      "Epoch 846/1000\n",
      "1152/1152 [==============================] - 1s 701us/step - loss: 1.3510 - acc: 0.5061 - val_loss: 1.5293 - val_acc: 0.4271\n",
      "Epoch 847/1000\n",
      "1152/1152 [==============================] - 1s 537us/step - loss: 1.3615 - acc: 0.5165 - val_loss: 1.5246 - val_acc: 0.4479\n",
      "Epoch 848/1000\n",
      "1152/1152 [==============================] - 1s 622us/step - loss: 1.3432 - acc: 0.5043 - val_loss: 1.5188 - val_acc: 0.4097\n",
      "Epoch 849/1000\n",
      "1152/1152 [==============================] - 1s 622us/step - loss: 1.3537 - acc: 0.5095 - val_loss: 1.5074 - val_acc: 0.4062\n",
      "Epoch 850/1000\n",
      "1152/1152 [==============================] - 1s 604us/step - loss: 1.3451 - acc: 0.5104 - val_loss: 1.5239 - val_acc: 0.4340\n",
      "Epoch 851/1000\n",
      "1152/1152 [==============================] - 1s 654us/step - loss: 1.3538 - acc: 0.5182 - val_loss: 1.5197 - val_acc: 0.4201\n",
      "Epoch 852/1000\n",
      "1152/1152 [==============================] - 1s 656us/step - loss: 1.3556 - acc: 0.5139 - val_loss: 1.5077 - val_acc: 0.4132\n",
      "Epoch 853/1000\n",
      "1152/1152 [==============================] - 1s 652us/step - loss: 1.3576 - acc: 0.5078 - val_loss: 1.5134 - val_acc: 0.4340\n",
      "Epoch 854/1000\n",
      "1152/1152 [==============================] - 1s 615us/step - loss: 1.3616 - acc: 0.4913 - val_loss: 1.5163 - val_acc: 0.4167\n",
      "Epoch 855/1000\n",
      "1152/1152 [==============================] - 1s 619us/step - loss: 1.3563 - acc: 0.5113 - val_loss: 1.5091 - val_acc: 0.3993\n",
      "Epoch 856/1000\n",
      "1152/1152 [==============================] - 1s 642us/step - loss: 1.3528 - acc: 0.5217 - val_loss: 1.5300 - val_acc: 0.4340\n",
      "Epoch 857/1000\n",
      "1152/1152 [==============================] - 1s 595us/step - loss: 1.3619 - acc: 0.5069 - val_loss: 1.5210 - val_acc: 0.4167\n",
      "Epoch 858/1000\n",
      "1152/1152 [==============================] - 1s 595us/step - loss: 1.3570 - acc: 0.5130 - val_loss: 1.5114 - val_acc: 0.4132\n",
      "Epoch 859/1000\n",
      "1152/1152 [==============================] - 1s 640us/step - loss: 1.3561 - acc: 0.4991 - val_loss: 1.5172 - val_acc: 0.4201\n",
      "Epoch 860/1000\n",
      "1152/1152 [==============================] - 1s 623us/step - loss: 1.3349 - acc: 0.5061 - val_loss: 1.5196 - val_acc: 0.4201\n",
      "Epoch 861/1000\n",
      "1152/1152 [==============================] - 1s 625us/step - loss: 1.3658 - acc: 0.5122 - val_loss: 1.5154 - val_acc: 0.4236\n",
      "Epoch 862/1000\n",
      "1152/1152 [==============================] - 1s 639us/step - loss: 1.3370 - acc: 0.5122 - val_loss: 1.5124 - val_acc: 0.4271\n",
      "Epoch 863/1000\n",
      "1152/1152 [==============================] - 1s 617us/step - loss: 1.3465 - acc: 0.5243 - val_loss: 1.5141 - val_acc: 0.4444\n",
      "Epoch 864/1000\n",
      "1152/1152 [==============================] - 1s 640us/step - loss: 1.3553 - acc: 0.4983 - val_loss: 1.5248 - val_acc: 0.4340\n",
      "Epoch 865/1000\n",
      "1152/1152 [==============================] - 1s 627us/step - loss: 1.3413 - acc: 0.5191 - val_loss: 1.5071 - val_acc: 0.4132\n",
      "Epoch 866/1000\n",
      "1152/1152 [==============================] - 1s 635us/step - loss: 1.3446 - acc: 0.5217 - val_loss: 1.5112 - val_acc: 0.4167\n",
      "Epoch 867/1000\n",
      "1152/1152 [==============================] - 1s 612us/step - loss: 1.3504 - acc: 0.5208 - val_loss: 1.5231 - val_acc: 0.4167\n",
      "Epoch 868/1000\n",
      "1152/1152 [==============================] - 1s 702us/step - loss: 1.3471 - acc: 0.5191 - val_loss: 1.5095 - val_acc: 0.4201\n",
      "Epoch 869/1000\n",
      "1152/1152 [==============================] - 1s 524us/step - loss: 1.3371 - acc: 0.5148 - val_loss: 1.5368 - val_acc: 0.3924\n",
      "Epoch 870/1000\n",
      "1152/1152 [==============================] - 1s 616us/step - loss: 1.3412 - acc: 0.5122 - val_loss: 1.5121 - val_acc: 0.4340\n",
      "Epoch 871/1000\n",
      "1152/1152 [==============================] - 1s 629us/step - loss: 1.3578 - acc: 0.5148 - val_loss: 1.5181 - val_acc: 0.4236\n",
      "Epoch 872/1000\n",
      "1152/1152 [==============================] - 1s 744us/step - loss: 1.3264 - acc: 0.5217 - val_loss: 1.5135 - val_acc: 0.3924\n",
      "Epoch 873/1000\n",
      "1152/1152 [==============================] - 1s 728us/step - loss: 1.3619 - acc: 0.4957 - val_loss: 1.5014 - val_acc: 0.4236\n",
      "Epoch 874/1000\n",
      "1152/1152 [==============================] - 1s 637us/step - loss: 1.3377 - acc: 0.5174 - val_loss: 1.5058 - val_acc: 0.4201\n",
      "Epoch 875/1000\n",
      "1152/1152 [==============================] - 1s 616us/step - loss: 1.3468 - acc: 0.5139 - val_loss: 1.5005 - val_acc: 0.4201\n",
      "Epoch 876/1000\n",
      "1152/1152 [==============================] - 1s 660us/step - loss: 1.3384 - acc: 0.5278 - val_loss: 1.5168 - val_acc: 0.3958\n",
      "Epoch 877/1000\n",
      "1152/1152 [==============================] - 1s 636us/step - loss: 1.3409 - acc: 0.5260 - val_loss: 1.5000 - val_acc: 0.4236\n",
      "Epoch 878/1000\n",
      "1152/1152 [==============================] - 1s 632us/step - loss: 1.3422 - acc: 0.5052 - val_loss: 1.5040 - val_acc: 0.4479\n",
      "Epoch 879/1000\n",
      "1152/1152 [==============================] - 1s 672us/step - loss: 1.3482 - acc: 0.5061 - val_loss: 1.5224 - val_acc: 0.4132\n",
      "Epoch 880/1000\n",
      "1152/1152 [==============================] - 1s 642us/step - loss: 1.3333 - acc: 0.5269 - val_loss: 1.5041 - val_acc: 0.4375\n",
      "Epoch 881/1000\n",
      "1152/1152 [==============================] - 1s 596us/step - loss: 1.3511 - acc: 0.5043 - val_loss: 1.5146 - val_acc: 0.4236\n",
      "Epoch 882/1000\n",
      "1152/1152 [==============================] - 1s 620us/step - loss: 1.3425 - acc: 0.5130 - val_loss: 1.5087 - val_acc: 0.4375\n",
      "Epoch 883/1000\n",
      "1152/1152 [==============================] - 1s 617us/step - loss: 1.3358 - acc: 0.5148 - val_loss: 1.5011 - val_acc: 0.4375\n",
      "Epoch 884/1000\n",
      "1152/1152 [==============================] - 1s 625us/step - loss: 1.3499 - acc: 0.5113 - val_loss: 1.5044 - val_acc: 0.4062\n",
      "Epoch 885/1000\n",
      "1152/1152 [==============================] - 1s 635us/step - loss: 1.3420 - acc: 0.5243 - val_loss: 1.5085 - val_acc: 0.4410\n",
      "Epoch 886/1000\n",
      "1152/1152 [==============================] - 1s 617us/step - loss: 1.3321 - acc: 0.5095 - val_loss: 1.5192 - val_acc: 0.4340\n",
      "Epoch 887/1000\n",
      "1152/1152 [==============================] - 1s 569us/step - loss: 1.3415 - acc: 0.5087 - val_loss: 1.5129 - val_acc: 0.4167\n",
      "Epoch 888/1000\n",
      "1152/1152 [==============================] - 1s 620us/step - loss: 1.3301 - acc: 0.5252 - val_loss: 1.5110 - val_acc: 0.4132\n",
      "Epoch 889/1000\n",
      "1152/1152 [==============================] - 1s 651us/step - loss: 1.3236 - acc: 0.5148 - val_loss: 1.5236 - val_acc: 0.4097\n",
      "Epoch 890/1000\n",
      "1152/1152 [==============================] - 1s 691us/step - loss: 1.3344 - acc: 0.5113 - val_loss: 1.5187 - val_acc: 0.4097\n",
      "Epoch 891/1000\n",
      "1152/1152 [==============================] - 1s 555us/step - loss: 1.3308 - acc: 0.5286 - val_loss: 1.5068 - val_acc: 0.4306\n",
      "Epoch 892/1000\n",
      "1152/1152 [==============================] - 1s 697us/step - loss: 1.3387 - acc: 0.5052 - val_loss: 1.5063 - val_acc: 0.3993\n",
      "Epoch 893/1000\n",
      "1152/1152 [==============================] - 1s 638us/step - loss: 1.3429 - acc: 0.5148 - val_loss: 1.5081 - val_acc: 0.4236\n",
      "Epoch 894/1000\n",
      "1152/1152 [==============================] - 1s 618us/step - loss: 1.3406 - acc: 0.5139 - val_loss: 1.5063 - val_acc: 0.4201\n",
      "Epoch 895/1000\n",
      "1152/1152 [==============================] - 1s 633us/step - loss: 1.3390 - acc: 0.5139 - val_loss: 1.5056 - val_acc: 0.4479\n",
      "Epoch 896/1000\n",
      "1152/1152 [==============================] - 1s 650us/step - loss: 1.3216 - acc: 0.5269 - val_loss: 1.5165 - val_acc: 0.4132\n",
      "Epoch 897/1000\n",
      "1152/1152 [==============================] - 1s 642us/step - loss: 1.3210 - acc: 0.5391 - val_loss: 1.5080 - val_acc: 0.4132\n",
      "Epoch 898/1000\n",
      "1152/1152 [==============================] - 1s 639us/step - loss: 1.3346 - acc: 0.5113 - val_loss: 1.5027 - val_acc: 0.4271\n",
      "Epoch 899/1000\n",
      "1152/1152 [==============================] - 1s 633us/step - loss: 1.3403 - acc: 0.5165 - val_loss: 1.5069 - val_acc: 0.4167\n",
      "Epoch 900/1000\n",
      "1152/1152 [==============================] - 1s 647us/step - loss: 1.3298 - acc: 0.5191 - val_loss: 1.5033 - val_acc: 0.4410\n",
      "Epoch 901/1000\n",
      "1152/1152 [==============================] - 1s 602us/step - loss: 1.3238 - acc: 0.5330 - val_loss: 1.4933 - val_acc: 0.3958\n",
      "Epoch 902/1000\n",
      "1152/1152 [==============================] - 1s 608us/step - loss: 1.3251 - acc: 0.5278 - val_loss: 1.5011 - val_acc: 0.4062\n",
      "Epoch 903/1000\n",
      "1152/1152 [==============================] - 1s 642us/step - loss: 1.3374 - acc: 0.5165 - val_loss: 1.4992 - val_acc: 0.4340\n",
      "Epoch 904/1000\n",
      "1152/1152 [==============================] - 1s 609us/step - loss: 1.3339 - acc: 0.5139 - val_loss: 1.4984 - val_acc: 0.4236\n",
      "Epoch 905/1000\n",
      "1152/1152 [==============================] - 1s 630us/step - loss: 1.3221 - acc: 0.5286 - val_loss: 1.5029 - val_acc: 0.4375\n",
      "Epoch 906/1000\n",
      "1152/1152 [==============================] - 1s 639us/step - loss: 1.3232 - acc: 0.5191 - val_loss: 1.5085 - val_acc: 0.4375\n",
      "Epoch 907/1000\n",
      "1152/1152 [==============================] - 1s 664us/step - loss: 1.3245 - acc: 0.5174 - val_loss: 1.4939 - val_acc: 0.4236\n",
      "Epoch 908/1000\n",
      "1152/1152 [==============================] - 1s 703us/step - loss: 1.3114 - acc: 0.5330 - val_loss: 1.5025 - val_acc: 0.4375\n",
      "Epoch 909/1000\n",
      "1152/1152 [==============================] - 1s 710us/step - loss: 1.3325 - acc: 0.5122 - val_loss: 1.5008 - val_acc: 0.4271\n",
      "Epoch 910/1000\n",
      "1152/1152 [==============================] - 1s 673us/step - loss: 1.3284 - acc: 0.5339 - val_loss: 1.5012 - val_acc: 0.4167\n",
      "Epoch 911/1000\n",
      "1152/1152 [==============================] - 1s 698us/step - loss: 1.3214 - acc: 0.5252 - val_loss: 1.5042 - val_acc: 0.4340\n",
      "Epoch 912/1000\n",
      "1152/1152 [==============================] - 1s 622us/step - loss: 1.3201 - acc: 0.5191 - val_loss: 1.5049 - val_acc: 0.4410\n",
      "Epoch 913/1000\n",
      "1152/1152 [==============================] - 1s 663us/step - loss: 1.3318 - acc: 0.5191 - val_loss: 1.4975 - val_acc: 0.4306\n",
      "Epoch 914/1000\n",
      "1152/1152 [==============================] - 1s 612us/step - loss: 1.3248 - acc: 0.5269 - val_loss: 1.5120 - val_acc: 0.4062\n",
      "Epoch 915/1000\n",
      "1152/1152 [==============================] - 1s 633us/step - loss: 1.3167 - acc: 0.5295 - val_loss: 1.5022 - val_acc: 0.4375\n",
      "Epoch 916/1000\n",
      "1152/1152 [==============================] - 1s 643us/step - loss: 1.3271 - acc: 0.5234 - val_loss: 1.5029 - val_acc: 0.4410\n",
      "Epoch 917/1000\n",
      "1152/1152 [==============================] - 1s 633us/step - loss: 1.3161 - acc: 0.5460 - val_loss: 1.4840 - val_acc: 0.4236\n",
      "Epoch 918/1000\n",
      "1152/1152 [==============================] - 1s 701us/step - loss: 1.3256 - acc: 0.5226 - val_loss: 1.4993 - val_acc: 0.4167\n",
      "Epoch 919/1000\n",
      "1152/1152 [==============================] - 1s 664us/step - loss: 1.2952 - acc: 0.5373 - val_loss: 1.5187 - val_acc: 0.4062\n",
      "Epoch 920/1000\n",
      "1152/1152 [==============================] - 1s 667us/step - loss: 1.3129 - acc: 0.5243 - val_loss: 1.4930 - val_acc: 0.3924\n",
      "Epoch 921/1000\n",
      "1152/1152 [==============================] - 1s 671us/step - loss: 1.3126 - acc: 0.5139 - val_loss: 1.4946 - val_acc: 0.4306\n",
      "Epoch 922/1000\n",
      "1152/1152 [==============================] - 1s 721us/step - loss: 1.3323 - acc: 0.5321 - val_loss: 1.5170 - val_acc: 0.4097\n",
      "Epoch 923/1000\n",
      "1152/1152 [==============================] - 1s 741us/step - loss: 1.3256 - acc: 0.5095 - val_loss: 1.5134 - val_acc: 0.4028\n",
      "Epoch 924/1000\n",
      "1152/1152 [==============================] - 1s 680us/step - loss: 1.3207 - acc: 0.5208 - val_loss: 1.4953 - val_acc: 0.4167\n",
      "Epoch 925/1000\n",
      "1152/1152 [==============================] - 1s 634us/step - loss: 1.3212 - acc: 0.5156 - val_loss: 1.4907 - val_acc: 0.3993\n",
      "Epoch 926/1000\n",
      "1152/1152 [==============================] - 1s 615us/step - loss: 1.3178 - acc: 0.5312 - val_loss: 1.4967 - val_acc: 0.4062\n",
      "Epoch 927/1000\n",
      "1152/1152 [==============================] - 1s 624us/step - loss: 1.3175 - acc: 0.5295 - val_loss: 1.4952 - val_acc: 0.4236\n",
      "Epoch 928/1000\n",
      "1152/1152 [==============================] - 1s 656us/step - loss: 1.3030 - acc: 0.5286 - val_loss: 1.5082 - val_acc: 0.4549\n",
      "Epoch 929/1000\n",
      "1152/1152 [==============================] - 1s 636us/step - loss: 1.3176 - acc: 0.5286 - val_loss: 1.4857 - val_acc: 0.4167\n",
      "Epoch 930/1000\n",
      "1152/1152 [==============================] - 1s 618us/step - loss: 1.3134 - acc: 0.5148 - val_loss: 1.4921 - val_acc: 0.4062\n",
      "Epoch 931/1000\n",
      "1152/1152 [==============================] - 1s 638us/step - loss: 1.3237 - acc: 0.5226 - val_loss: 1.4997 - val_acc: 0.4271\n",
      "Epoch 932/1000\n",
      "1152/1152 [==============================] - 1s 710us/step - loss: 1.3185 - acc: 0.5243 - val_loss: 1.4983 - val_acc: 0.4340\n",
      "Epoch 933/1000\n",
      "1152/1152 [==============================] - 1s 649us/step - loss: 1.3137 - acc: 0.5286 - val_loss: 1.4971 - val_acc: 0.4340\n",
      "Epoch 934/1000\n",
      "1152/1152 [==============================] - 1s 640us/step - loss: 1.3083 - acc: 0.5243 - val_loss: 1.4942 - val_acc: 0.4167\n",
      "Epoch 935/1000\n",
      "1152/1152 [==============================] - 1s 643us/step - loss: 1.3096 - acc: 0.5321 - val_loss: 1.5049 - val_acc: 0.4271\n",
      "Epoch 936/1000\n",
      "1152/1152 [==============================] - 1s 640us/step - loss: 1.3142 - acc: 0.5339 - val_loss: 1.4851 - val_acc: 0.4201\n",
      "Epoch 937/1000\n",
      "1152/1152 [==============================] - 1s 625us/step - loss: 1.3082 - acc: 0.5191 - val_loss: 1.5001 - val_acc: 0.4306\n",
      "Epoch 938/1000\n",
      "1152/1152 [==============================] - 1s 647us/step - loss: 1.3152 - acc: 0.5191 - val_loss: 1.4918 - val_acc: 0.4028\n",
      "Epoch 939/1000\n",
      "1152/1152 [==============================] - 1s 618us/step - loss: 1.2973 - acc: 0.5356 - val_loss: 1.4864 - val_acc: 0.4410\n",
      "Epoch 940/1000\n",
      "1152/1152 [==============================] - 1s 633us/step - loss: 1.2958 - acc: 0.5312 - val_loss: 1.5164 - val_acc: 0.4479\n",
      "Epoch 941/1000\n",
      "1152/1152 [==============================] - 1s 668us/step - loss: 1.3113 - acc: 0.5408 - val_loss: 1.4900 - val_acc: 0.4306\n",
      "Epoch 942/1000\n",
      "1152/1152 [==============================] - 1s 662us/step - loss: 1.3005 - acc: 0.5295 - val_loss: 1.4888 - val_acc: 0.4340\n",
      "Epoch 943/1000\n",
      "1152/1152 [==============================] - 1s 660us/step - loss: 1.3065 - acc: 0.5339 - val_loss: 1.4894 - val_acc: 0.4306\n",
      "Epoch 944/1000\n",
      "1152/1152 [==============================] - 1s 628us/step - loss: 1.3078 - acc: 0.5226 - val_loss: 1.4863 - val_acc: 0.4201\n",
      "Epoch 945/1000\n",
      "1152/1152 [==============================] - 1s 609us/step - loss: 1.3156 - acc: 0.5321 - val_loss: 1.4841 - val_acc: 0.4375\n",
      "Epoch 946/1000\n",
      "1152/1152 [==============================] - 1s 636us/step - loss: 1.3014 - acc: 0.5391 - val_loss: 1.4922 - val_acc: 0.4444\n",
      "Epoch 947/1000\n",
      "1152/1152 [==============================] - 1s 603us/step - loss: 1.3139 - acc: 0.5330 - val_loss: 1.4893 - val_acc: 0.4340\n",
      "Epoch 948/1000\n",
      "1152/1152 [==============================] - 1s 630us/step - loss: 1.3155 - acc: 0.5217 - val_loss: 1.4927 - val_acc: 0.4062\n",
      "Epoch 949/1000\n",
      "1152/1152 [==============================] - 1s 637us/step - loss: 1.3127 - acc: 0.5165 - val_loss: 1.4931 - val_acc: 0.4514\n",
      "Epoch 950/1000\n",
      "1152/1152 [==============================] - 1s 644us/step - loss: 1.3015 - acc: 0.5295 - val_loss: 1.4863 - val_acc: 0.4132\n",
      "Epoch 951/1000\n",
      "1152/1152 [==============================] - 1s 628us/step - loss: 1.2954 - acc: 0.5382 - val_loss: 1.4988 - val_acc: 0.4410\n",
      "Epoch 952/1000\n",
      "1152/1152 [==============================] - 1s 643us/step - loss: 1.2925 - acc: 0.5443 - val_loss: 1.4833 - val_acc: 0.4062\n",
      "Epoch 953/1000\n",
      "1152/1152 [==============================] - 1s 635us/step - loss: 1.2997 - acc: 0.5243 - val_loss: 1.4867 - val_acc: 0.4167\n",
      "Epoch 954/1000\n",
      "1152/1152 [==============================] - 1s 751us/step - loss: 1.2919 - acc: 0.5252 - val_loss: 1.4880 - val_acc: 0.4306\n",
      "Epoch 955/1000\n",
      "1152/1152 [==============================] - 1s 542us/step - loss: 1.2973 - acc: 0.5148 - val_loss: 1.4825 - val_acc: 0.4549\n",
      "Epoch 956/1000\n",
      "1152/1152 [==============================] - 1s 636us/step - loss: 1.2960 - acc: 0.5417 - val_loss: 1.4838 - val_acc: 0.4236\n",
      "Epoch 957/1000\n",
      "1152/1152 [==============================] - 1s 629us/step - loss: 1.2958 - acc: 0.5408 - val_loss: 1.4910 - val_acc: 0.4028\n",
      "Epoch 958/1000\n",
      "1152/1152 [==============================] - 1s 634us/step - loss: 1.3167 - acc: 0.5269 - val_loss: 1.4857 - val_acc: 0.4062\n",
      "Epoch 959/1000\n",
      "1152/1152 [==============================] - 1s 629us/step - loss: 1.3109 - acc: 0.5330 - val_loss: 1.4822 - val_acc: 0.4375\n",
      "Epoch 960/1000\n",
      "1152/1152 [==============================] - 1s 641us/step - loss: 1.3040 - acc: 0.5217 - val_loss: 1.4788 - val_acc: 0.4132\n",
      "Epoch 961/1000\n",
      "1152/1152 [==============================] - 1s 652us/step - loss: 1.2913 - acc: 0.5278 - val_loss: 1.4869 - val_acc: 0.4201\n",
      "Epoch 962/1000\n",
      "1152/1152 [==============================] - 1s 658us/step - loss: 1.2935 - acc: 0.5382 - val_loss: 1.4793 - val_acc: 0.4167\n",
      "Epoch 963/1000\n",
      "1152/1152 [==============================] - 1s 611us/step - loss: 1.2803 - acc: 0.5391 - val_loss: 1.4958 - val_acc: 0.4410\n",
      "Epoch 964/1000\n",
      "1152/1152 [==============================] - 1s 643us/step - loss: 1.3104 - acc: 0.5434 - val_loss: 1.4828 - val_acc: 0.4306\n",
      "Epoch 965/1000\n",
      "1152/1152 [==============================] - 1s 662us/step - loss: 1.3268 - acc: 0.5026 - val_loss: 1.4765 - val_acc: 0.4236\n",
      "Epoch 966/1000\n",
      "1152/1152 [==============================] - 1s 670us/step - loss: 1.2872 - acc: 0.5451 - val_loss: 1.4855 - val_acc: 0.4410\n",
      "Epoch 967/1000\n",
      "1152/1152 [==============================] - 1s 645us/step - loss: 1.2765 - acc: 0.5304 - val_loss: 1.4808 - val_acc: 0.4514\n",
      "Epoch 968/1000\n",
      "1152/1152 [==============================] - 1s 623us/step - loss: 1.2819 - acc: 0.5269 - val_loss: 1.4805 - val_acc: 0.4306\n",
      "Epoch 969/1000\n",
      "1152/1152 [==============================] - 1s 635us/step - loss: 1.2966 - acc: 0.5260 - val_loss: 1.4879 - val_acc: 0.3958\n",
      "Epoch 970/1000\n",
      "1152/1152 [==============================] - 1s 647us/step - loss: 1.2765 - acc: 0.5599 - val_loss: 1.4831 - val_acc: 0.4514\n",
      "Epoch 971/1000\n",
      "1152/1152 [==============================] - 1s 647us/step - loss: 1.2981 - acc: 0.5286 - val_loss: 1.4772 - val_acc: 0.4479\n",
      "Epoch 972/1000\n",
      "1152/1152 [==============================] - 1s 646us/step - loss: 1.2888 - acc: 0.5460 - val_loss: 1.4972 - val_acc: 0.4514\n",
      "Epoch 973/1000\n",
      "1152/1152 [==============================] - 1s 638us/step - loss: 1.2934 - acc: 0.5339 - val_loss: 1.4838 - val_acc: 0.4410\n",
      "Epoch 974/1000\n",
      "1152/1152 [==============================] - 1s 644us/step - loss: 1.2956 - acc: 0.5399 - val_loss: 1.4811 - val_acc: 0.4132\n",
      "Epoch 975/1000\n",
      "1152/1152 [==============================] - 1s 695us/step - loss: 1.2899 - acc: 0.5304 - val_loss: 1.4938 - val_acc: 0.4062\n",
      "Epoch 976/1000\n",
      "1152/1152 [==============================] - 1s 691us/step - loss: 1.2816 - acc: 0.5304 - val_loss: 1.4817 - val_acc: 0.4410\n",
      "Epoch 977/1000\n",
      "1152/1152 [==============================] - 1s 636us/step - loss: 1.3033 - acc: 0.5286 - val_loss: 1.4781 - val_acc: 0.4444\n",
      "Epoch 978/1000\n",
      "1152/1152 [==============================] - 1s 626us/step - loss: 1.3008 - acc: 0.5451 - val_loss: 1.4860 - val_acc: 0.4410\n",
      "Epoch 979/1000\n",
      "1152/1152 [==============================] - 1s 634us/step - loss: 1.2914 - acc: 0.5391 - val_loss: 1.4740 - val_acc: 0.4306\n",
      "Epoch 980/1000\n",
      "1152/1152 [==============================] - 1s 628us/step - loss: 1.3011 - acc: 0.5234 - val_loss: 1.4854 - val_acc: 0.4549\n",
      "Epoch 981/1000\n",
      "1152/1152 [==============================] - 1s 629us/step - loss: 1.2804 - acc: 0.5391 - val_loss: 1.4773 - val_acc: 0.4062\n",
      "Epoch 982/1000\n",
      "1152/1152 [==============================] - 1s 632us/step - loss: 1.2801 - acc: 0.5234 - val_loss: 1.4861 - val_acc: 0.4479\n",
      "Epoch 983/1000\n",
      "1152/1152 [==============================] - 1s 639us/step - loss: 1.3026 - acc: 0.5321 - val_loss: 1.4684 - val_acc: 0.4062\n",
      "Epoch 984/1000\n",
      "1152/1152 [==============================] - 1s 642us/step - loss: 1.2729 - acc: 0.5408 - val_loss: 1.4773 - val_acc: 0.4375\n",
      "Epoch 985/1000\n",
      "1152/1152 [==============================] - 1s 631us/step - loss: 1.3107 - acc: 0.5304 - val_loss: 1.4784 - val_acc: 0.4340\n",
      "Epoch 986/1000\n",
      "1152/1152 [==============================] - 1s 651us/step - loss: 1.2862 - acc: 0.5226 - val_loss: 1.4842 - val_acc: 0.4236\n",
      "Epoch 987/1000\n",
      "1152/1152 [==============================] - 1s 653us/step - loss: 1.2763 - acc: 0.5556 - val_loss: 1.4869 - val_acc: 0.4167\n",
      "Epoch 988/1000\n",
      "1152/1152 [==============================] - 1s 613us/step - loss: 1.2865 - acc: 0.5330 - val_loss: 1.4633 - val_acc: 0.4444\n",
      "Epoch 989/1000\n",
      "1152/1152 [==============================] - 1s 637us/step - loss: 1.2692 - acc: 0.5503 - val_loss: 1.4885 - val_acc: 0.4444\n",
      "Epoch 990/1000\n",
      "1152/1152 [==============================] - 1s 654us/step - loss: 1.2690 - acc: 0.5495 - val_loss: 1.4753 - val_acc: 0.4340\n",
      "Epoch 991/1000\n",
      "1152/1152 [==============================] - 1s 624us/step - loss: 1.2880 - acc: 0.5391 - val_loss: 1.4922 - val_acc: 0.4271\n",
      "Epoch 992/1000\n",
      "1152/1152 [==============================] - 1s 608us/step - loss: 1.2726 - acc: 0.5425 - val_loss: 1.4764 - val_acc: 0.4097\n",
      "Epoch 993/1000\n",
      "1152/1152 [==============================] - 1s 729us/step - loss: 1.2686 - acc: 0.5451 - val_loss: 1.4711 - val_acc: 0.4271\n",
      "Epoch 994/1000\n",
      "1152/1152 [==============================] - 1s 630us/step - loss: 1.2773 - acc: 0.5391 - val_loss: 1.4835 - val_acc: 0.4306\n",
      "Epoch 995/1000\n",
      "1152/1152 [==============================] - 1s 655us/step - loss: 1.2646 - acc: 0.5391 - val_loss: 1.4769 - val_acc: 0.4167\n",
      "Epoch 996/1000\n",
      "1152/1152 [==============================] - 1s 629us/step - loss: 1.2534 - acc: 0.5391 - val_loss: 1.4705 - val_acc: 0.4306\n",
      "Epoch 997/1000\n",
      "1152/1152 [==============================] - 1s 748us/step - loss: 1.2851 - acc: 0.5451 - val_loss: 1.4791 - val_acc: 0.4410\n",
      "Epoch 998/1000\n",
      "1152/1152 [==============================] - 1s 586us/step - loss: 1.2914 - acc: 0.5208 - val_loss: 1.4654 - val_acc: 0.4062\n",
      "Epoch 999/1000\n",
      "1152/1152 [==============================] - 1s 661us/step - loss: 1.2872 - acc: 0.5356 - val_loss: 1.4599 - val_acc: 0.4340\n",
      "Epoch 1000/1000\n",
      "1152/1152 [==============================] - 1s 636us/step - loss: 1.2789 - acc: 0.5512 - val_loss: 1.4770 - val_acc: 0.4306\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['acc'])\n",
    "plt.plot(cnnhistory.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(x_testcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 3, 1, 6, 1, 1, 2, 6, 1, 2, 7, 6, 3, 6, 2, 7, 7, 1, 2, 2, 1,\n",
       "       6, 1, 3, 7, 6, 6, 6, 6, 6, 4, 7, 1, 1, 1, 6, 4, 5, 4, 1, 1, 1, 4,\n",
       "       7, 6, 6, 0, 3, 2, 7, 5, 7, 4, 1, 1, 7, 1, 6, 3, 1, 5, 7, 4, 5, 4,\n",
       "       6, 6, 1, 1, 7, 6, 0, 4, 7, 1, 4, 7, 6, 1, 2, 2, 7, 1, 2, 4, 5, 1,\n",
       "       5, 3, 6, 1, 6, 6, 6, 6, 6, 4, 6, 4, 6, 5, 5, 7, 6, 5, 2, 6, 4, 1,\n",
       "       7, 4, 7, 1, 6, 4, 5, 6, 5, 5, 7, 1, 7, 5, 2, 4, 7, 6, 2, 5, 2, 5,\n",
       "       1, 6, 6, 3, 1, 1, 4, 6, 6, 6, 2, 7, 5, 6, 4, 1, 7, 5, 5, 6, 1, 5,\n",
       "       5, 1, 7, 1, 7, 5, 6, 6, 4, 1, 1, 4, 4, 6, 5, 7, 1, 4, 5, 6, 4, 1,\n",
       "       6, 6, 7, 6, 4, 5, 2, 1, 0, 6, 7, 2, 2, 3, 6, 5, 6, 1, 1, 5, 6, 7,\n",
       "       2, 6, 2, 1, 7, 3, 5, 4, 6, 1, 4, 7, 7, 6, 7, 5, 1, 3, 7, 4, 4, 2,\n",
       "       2, 6, 6, 7, 3, 6, 3, 6, 6, 6, 6, 7, 7, 7, 7, 6, 6, 6, 4, 3, 6, 1,\n",
       "       4, 5, 7, 5, 5, 1, 1, 1, 7, 1, 2, 1, 4, 6, 3, 7, 6, 1, 1, 3, 1, 0,\n",
       "       2, 3, 4, 7, 6, 1, 7, 1, 3, 7, 6, 6, 6, 7, 5, 6, 4, 5, 7, 6, 3, 4,\n",
       "       6, 6], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 1, 1, 4, 1, 1, 5, 7, 1, 6, 7, 3, 5, 3, 6, 4, 5, 1, 6, 7, 0,\n",
       "       0, 3, 5, 3, 7, 7, 6, 4, 7, 4, 2, 5, 7, 1, 6, 4, 2, 4, 1, 0, 1, 4,\n",
       "       7, 1, 1, 0, 5, 3, 3, 7, 7, 4, 0, 1, 1, 7, 2, 0, 7, 5, 7, 7, 5, 2,\n",
       "       1, 6, 6, 3, 2, 7, 1, 2, 7, 1, 4, 7, 3, 6, 2, 2, 7, 1, 2, 4, 5, 1,\n",
       "       2, 1, 0, 1, 4, 4, 0, 6, 7, 2, 2, 7, 6, 5, 4, 5, 3, 7, 2, 6, 5, 0,\n",
       "       7, 4, 7, 1, 6, 4, 5, 6, 6, 5, 6, 1, 7, 5, 3, 4, 7, 2, 5, 5, 2, 2,\n",
       "       3, 5, 2, 3, 1, 1, 6, 6, 4, 4, 2, 2, 4, 2, 4, 1, 7, 5, 5, 3, 1, 5,\n",
       "       2, 0, 5, 3, 7, 5, 3, 4, 4, 3, 2, 0, 4, 1, 3, 7, 1, 5, 4, 6, 5, 1,\n",
       "       4, 7, 2, 3, 2, 5, 2, 3, 0, 0, 7, 4, 4, 3, 6, 5, 3, 1, 3, 5, 7, 7,\n",
       "       6, 1, 5, 3, 7, 3, 1, 4, 6, 3, 2, 7, 2, 6, 7, 5, 0, 5, 4, 4, 7, 7,\n",
       "       3, 7, 6, 5, 3, 6, 1, 3, 3, 0, 3, 7, 3, 6, 7, 4, 4, 6, 4, 0, 6, 1,\n",
       "       7, 0, 2, 2, 0, 1, 1, 3, 4, 3, 4, 1, 4, 6, 3, 7, 1, 1, 4, 1, 1, 1,\n",
       "       4, 0, 6, 7, 7, 1, 2, 0, 3, 7, 3, 4, 4, 2, 4, 2, 4, 2, 3, 6, 3, 6,\n",
       "       2, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Ytest = y_test.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 1, 1, 4, 1, 1, 5, 7, 1, 6, 7, 3, 5, 3, 6, 4, 5, 1, 6, 7, 0,\n",
       "       0, 3, 5, 3, 7, 7, 6, 4, 7, 4, 2, 5, 7, 1, 6, 4, 2, 4, 1, 0, 1, 4,\n",
       "       7, 1, 1, 0, 5, 3, 3, 7, 7, 4, 0, 1, 1, 7, 2, 0, 7, 5, 7, 7, 5, 2,\n",
       "       1, 6, 6, 3, 2, 7, 1, 2, 7, 1, 4, 7, 3, 6, 2, 2, 7, 1, 2, 4, 5, 1,\n",
       "       2, 1, 0, 1, 4, 4, 0, 6, 7, 2, 2, 7, 6, 5, 4, 5, 3, 7, 2, 6, 5, 0,\n",
       "       7, 4, 7, 1, 6, 4, 5, 6, 6, 5, 6, 1, 7, 5, 3, 4, 7, 2, 5, 5, 2, 2,\n",
       "       3, 5, 2, 3, 1, 1, 6, 6, 4, 4, 2, 2, 4, 2, 4, 1, 7, 5, 5, 3, 1, 5,\n",
       "       2, 0, 5, 3, 7, 5, 3, 4, 4, 3, 2, 0, 4, 1, 3, 7, 1, 5, 4, 6, 5, 1,\n",
       "       4, 7, 2, 3, 2, 5, 2, 3, 0, 0, 7, 4, 4, 3, 6, 5, 3, 1, 3, 5, 7, 7,\n",
       "       6, 1, 5, 3, 7, 3, 1, 4, 6, 3, 2, 7, 2, 6, 7, 5, 0, 5, 4, 4, 7, 7,\n",
       "       3, 7, 6, 5, 3, 6, 1, 3, 3, 0, 3, 7, 3, 6, 7, 4, 4, 6, 4, 0, 6, 1,\n",
       "       7, 0, 2, 2, 0, 1, 1, 3, 4, 3, 4, 1, 4, 6, 3, 7, 1, 1, 4, 1, 1, 1,\n",
       "       4, 0, 6, 7, 7, 1, 2, 0, 3, 7, 3, 4, 4, 2, 4, 2, 4, 2, 3, 6, 3, 6,\n",
       "       2, 3])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.10      0.17        20\n",
      "           1       0.54      0.68      0.60        44\n",
      "           2       0.30      0.21      0.25        34\n",
      "           3       0.39      0.18      0.25        39\n",
      "           4       0.53      0.43      0.47        42\n",
      "           5       0.48      0.50      0.49        32\n",
      "           6       0.27      0.62      0.38        32\n",
      "           7       0.52      0.53      0.53        45\n",
      "\n",
      "    accuracy                           0.43       288\n",
      "   macro avg       0.44      0.41      0.39       288\n",
      "weighted avg       0.45      0.43      0.41       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(new_Ytest, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  7  0  3  1  2  5  0]\n",
      " [ 2 30  0  4  0  1  6  1]\n",
      " [ 0  1  7  0  5  6  7  8]\n",
      " [ 0 11  3  7  0  1 13  4]\n",
      " [ 0  1  4  0 18  4 12  3]\n",
      " [ 0  1  3  4  3 16  1  4]\n",
      " [ 0  2  4  0  3  1 20  2]\n",
      " [ 0  3  2  0  4  2 10 24]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(new_Ytest, predictions)\n",
    "print (matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:/another_model/Emotion_Voice_model_sig.h5 \n"
     ]
    }
   ],
   "source": [
    "#Save the model---/\n",
    "model_name = 'Emotion_Voice_model_sig.h5'\n",
    "save_dir = 'C:/another_model/'\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_11 (Conv1D)           (None, 40, 128)           768       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5, 128)            82048     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 5128      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 87,944\n",
      "Trainable params: 87,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model = keras.models.load_model('C:/another_model/Emotion_Voice_model_sig.h5')\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 0s 980us/step\n",
      "Restored model, accuracy: 43.06%\n"
     ]
    }
   ],
   "source": [
    "oss, acc = loaded_model.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
