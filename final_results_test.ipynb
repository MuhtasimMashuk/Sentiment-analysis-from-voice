{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist= os.listdir('C:/Voice_all/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-05-02-01-02-09.wav\n"
     ]
    }
   ],
   "source": [
    "print(mylist[800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03\n"
     ]
    }
   ],
   "source": [
    "print(mylist[400][6:-16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the audio file's waveform and its spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('C:/Voice_all/03-01-05-02-01-02-09.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x1d3ee241d48>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeling_list=[]\n",
    "for item in mylist:\n",
    "    if item[6:-16]=='02' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_calm')\n",
    "    elif item[6:-16]=='02' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_calm')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_happy')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_happy')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_sad')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_sad')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_angry')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_angry')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_fearful')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_fearful')\n",
    "    elif item[:1]=='a':\n",
    "        feeling_list.append('male_angry')\n",
    "    elif item[:1]=='f':\n",
    "        feeling_list.append('male_fearful')\n",
    "    elif item[:1]=='h':\n",
    "        feeling_list.append('male_happy')\n",
    "    #elif item[:1]=='n':\n",
    "        #feeling_list.append('neutral')\n",
    "    elif item[:2]=='sa':\n",
    "        feeling_list.append('male_sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(feeling_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    male_calm\n",
       "1  female_calm\n",
       "2    male_calm\n",
       "3  female_calm\n",
       "4    male_calm\n",
       "5  female_calm\n",
       "6    male_calm\n",
       "7  female_calm\n",
       "8    male_calm\n",
       "9  female_calm"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the features of audio files using librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for index,y in enumerate(mylist):\n",
    "    if mylist[index][6:-16]!='01' and mylist[index][6:-16]!='07' and mylist[index][6:-16]!='08' and mylist[index][:2]!='su' and mylist[index][:1]!='n' and mylist[index][:1]!='d':\n",
    "        X, sample_rate = librosa.load('C:/Voice_all/'+y, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "        sample_rate = np.array(sample_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        #[float(i) for i in feature]\n",
    "        #feature1=feature[:135]\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark=bookmark+1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-70.2677641610773, -70.2677641610773, -70.267...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-65.70765240065282, -65.70765240065282, -63.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-65.4824988827423, -65.4824988827423, -65.482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-64.52844910346735, -64.52844910346735, -64.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-62.36431052745468, -59.93472513811134, -61.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature\n",
       "0  [-70.2677641610773, -70.2677641610773, -70.267...\n",
       "1  [-65.70765240065282, -65.70765240065282, -63.1...\n",
       "2  [-65.4824988827423, -65.4824988827423, -65.482...\n",
       "3  [-64.52844910346735, -64.52844910346735, -64.5...\n",
       "4  [-62.36431052745468, -59.93472513811134, -61.8..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(df['feature'].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.concat([df3,labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf = newdf.rename(index=str, columns={\"0\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-70.267764</td>\n",
       "      <td>-70.267764</td>\n",
       "      <td>-70.267764</td>\n",
       "      <td>-70.267764</td>\n",
       "      <td>-70.267764</td>\n",
       "      <td>-70.267764</td>\n",
       "      <td>-70.267764</td>\n",
       "      <td>-70.267764</td>\n",
       "      <td>-70.267764</td>\n",
       "      <td>-70.267764</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.447461</td>\n",
       "      <td>-58.896493</td>\n",
       "      <td>-58.751002</td>\n",
       "      <td>-57.405669</td>\n",
       "      <td>-60.078475</td>\n",
       "      <td>-63.426811</td>\n",
       "      <td>-62.638537</td>\n",
       "      <td>-61.082741</td>\n",
       "      <td>-60.234652</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-65.707652</td>\n",
       "      <td>-65.707652</td>\n",
       "      <td>-63.114722</td>\n",
       "      <td>-61.518999</td>\n",
       "      <td>-61.097138</td>\n",
       "      <td>-63.424602</td>\n",
       "      <td>-63.720067</td>\n",
       "      <td>-56.854608</td>\n",
       "      <td>-55.168972</td>\n",
       "      <td>-54.640002</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.792147</td>\n",
       "      <td>-40.613166</td>\n",
       "      <td>-41.209201</td>\n",
       "      <td>-41.439204</td>\n",
       "      <td>-43.994282</td>\n",
       "      <td>-49.399616</td>\n",
       "      <td>-50.591601</td>\n",
       "      <td>-49.144064</td>\n",
       "      <td>-48.705645</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-65.482499</td>\n",
       "      <td>-65.482499</td>\n",
       "      <td>-65.482499</td>\n",
       "      <td>-65.482499</td>\n",
       "      <td>-65.482499</td>\n",
       "      <td>-65.482499</td>\n",
       "      <td>-65.482499</td>\n",
       "      <td>-65.482499</td>\n",
       "      <td>-65.482499</td>\n",
       "      <td>-65.482499</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.346553</td>\n",
       "      <td>-34.310774</td>\n",
       "      <td>-35.800705</td>\n",
       "      <td>-35.936112</td>\n",
       "      <td>-37.631846</td>\n",
       "      <td>-40.119408</td>\n",
       "      <td>-41.662903</td>\n",
       "      <td>-41.323644</td>\n",
       "      <td>-40.710780</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-64.528449</td>\n",
       "      <td>-64.528449</td>\n",
       "      <td>-64.528449</td>\n",
       "      <td>-64.528449</td>\n",
       "      <td>-64.528449</td>\n",
       "      <td>-64.528449</td>\n",
       "      <td>-64.528449</td>\n",
       "      <td>-64.528449</td>\n",
       "      <td>-64.528449</td>\n",
       "      <td>-65.928222</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.674306</td>\n",
       "      <td>-48.596082</td>\n",
       "      <td>-47.602751</td>\n",
       "      <td>-43.049195</td>\n",
       "      <td>-42.659546</td>\n",
       "      <td>-43.188561</td>\n",
       "      <td>-44.001237</td>\n",
       "      <td>-43.610100</td>\n",
       "      <td>-44.698259</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-62.364311</td>\n",
       "      <td>-59.934725</td>\n",
       "      <td>-61.869600</td>\n",
       "      <td>-67.495764</td>\n",
       "      <td>-71.071811</td>\n",
       "      <td>-65.679826</td>\n",
       "      <td>-63.394396</td>\n",
       "      <td>-65.503349</td>\n",
       "      <td>-61.856639</td>\n",
       "      <td>-60.005421</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.071328</td>\n",
       "      <td>-41.897121</td>\n",
       "      <td>-40.865430</td>\n",
       "      <td>-38.290605</td>\n",
       "      <td>-36.372397</td>\n",
       "      <td>-37.915779</td>\n",
       "      <td>-40.026125</td>\n",
       "      <td>-43.383777</td>\n",
       "      <td>-43.965398</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "0 -70.267764 -70.267764 -70.267764 -70.267764 -70.267764 -70.267764   \n",
       "1 -65.707652 -65.707652 -63.114722 -61.518999 -61.097138 -63.424602   \n",
       "2 -65.482499 -65.482499 -65.482499 -65.482499 -65.482499 -65.482499   \n",
       "3 -64.528449 -64.528449 -64.528449 -64.528449 -64.528449 -64.528449   \n",
       "4 -62.364311 -59.934725 -61.869600 -67.495764 -71.071811 -65.679826   \n",
       "\n",
       "         6          7          8          9    ...        207        208  \\\n",
       "0 -70.267764 -70.267764 -70.267764 -70.267764  ... -57.447461 -58.896493   \n",
       "1 -63.720067 -56.854608 -55.168972 -54.640002  ... -39.792147 -40.613166   \n",
       "2 -65.482499 -65.482499 -65.482499 -65.482499  ... -31.346553 -34.310774   \n",
       "3 -64.528449 -64.528449 -64.528449 -65.928222  ... -48.674306 -48.596082   \n",
       "4 -63.394396 -65.503349 -61.856639 -60.005421  ... -39.071328 -41.897121   \n",
       "\n",
       "         209        210        211        212        213        214  \\\n",
       "0 -58.751002 -57.405669 -60.078475 -63.426811 -62.638537 -61.082741   \n",
       "1 -41.209201 -41.439204 -43.994282 -49.399616 -50.591601 -49.144064   \n",
       "2 -35.800705 -35.936112 -37.631846 -40.119408 -41.662903 -41.323644   \n",
       "3 -47.602751 -43.049195 -42.659546 -43.188561 -44.001237 -43.610100   \n",
       "4 -40.865430 -38.290605 -36.372397 -37.915779 -40.026125 -43.383777   \n",
       "\n",
       "         215          0    \n",
       "0 -60.234652    male_calm  \n",
       "1 -48.705645  female_calm  \n",
       "2 -40.710780    male_calm  \n",
       "3 -44.698259  female_calm  \n",
       "4 -43.965398    male_calm  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnewdf[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>-55.432984</td>\n",
       "      <td>-56.202228</td>\n",
       "      <td>-57.184010</td>\n",
       "      <td>-57.505661</td>\n",
       "      <td>-56.593266</td>\n",
       "      <td>-55.006390</td>\n",
       "      <td>-54.756210</td>\n",
       "      <td>-56.295744</td>\n",
       "      <td>-58.478039</td>\n",
       "      <td>-57.118607</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.977090</td>\n",
       "      <td>-25.839029</td>\n",
       "      <td>-24.558172</td>\n",
       "      <td>-24.293968</td>\n",
       "      <td>-23.481319</td>\n",
       "      <td>-22.684277</td>\n",
       "      <td>-21.958473</td>\n",
       "      <td>-20.250398</td>\n",
       "      <td>-18.629301</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>-50.545312</td>\n",
       "      <td>-48.991972</td>\n",
       "      <td>-48.865521</td>\n",
       "      <td>-49.207718</td>\n",
       "      <td>-50.144840</td>\n",
       "      <td>-48.545571</td>\n",
       "      <td>-49.289383</td>\n",
       "      <td>-50.947019</td>\n",
       "      <td>-50.168514</td>\n",
       "      <td>-50.172467</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.672711</td>\n",
       "      <td>-49.168897</td>\n",
       "      <td>-48.626179</td>\n",
       "      <td>-49.492818</td>\n",
       "      <td>-49.116773</td>\n",
       "      <td>-48.921223</td>\n",
       "      <td>-46.197038</td>\n",
       "      <td>-45.821223</td>\n",
       "      <td>-48.995852</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-66.471029</td>\n",
       "      <td>-66.464810</td>\n",
       "      <td>-66.471029</td>\n",
       "      <td>-66.471029</td>\n",
       "      <td>-66.471029</td>\n",
       "      <td>-66.471029</td>\n",
       "      <td>-66.471029</td>\n",
       "      <td>-66.471029</td>\n",
       "      <td>-66.471029</td>\n",
       "      <td>-66.471029</td>\n",
       "      <td>...</td>\n",
       "      <td>-64.386411</td>\n",
       "      <td>-62.351795</td>\n",
       "      <td>-64.222398</td>\n",
       "      <td>-66.152031</td>\n",
       "      <td>-63.642780</td>\n",
       "      <td>-63.769040</td>\n",
       "      <td>-66.471029</td>\n",
       "      <td>-66.471029</td>\n",
       "      <td>-65.012717</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>-48.981466</td>\n",
       "      <td>-47.696597</td>\n",
       "      <td>-47.206740</td>\n",
       "      <td>-48.770675</td>\n",
       "      <td>-46.975942</td>\n",
       "      <td>-46.064501</td>\n",
       "      <td>-45.844486</td>\n",
       "      <td>-45.215074</td>\n",
       "      <td>-46.174046</td>\n",
       "      <td>-46.502808</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.041735</td>\n",
       "      <td>-47.311513</td>\n",
       "      <td>-48.412880</td>\n",
       "      <td>-48.155535</td>\n",
       "      <td>-44.662251</td>\n",
       "      <td>-45.211056</td>\n",
       "      <td>-47.680673</td>\n",
       "      <td>-48.981466</td>\n",
       "      <td>-48.981466</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>-66.323343</td>\n",
       "      <td>-66.323343</td>\n",
       "      <td>-66.323343</td>\n",
       "      <td>-66.323343</td>\n",
       "      <td>-66.323343</td>\n",
       "      <td>-66.323343</td>\n",
       "      <td>-66.323343</td>\n",
       "      <td>-66.323343</td>\n",
       "      <td>-66.323343</td>\n",
       "      <td>-66.323343</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.012368</td>\n",
       "      <td>-49.231145</td>\n",
       "      <td>-47.134626</td>\n",
       "      <td>-46.901940</td>\n",
       "      <td>-45.832007</td>\n",
       "      <td>-45.729526</td>\n",
       "      <td>-46.371648</td>\n",
       "      <td>-47.507066</td>\n",
       "      <td>-48.348944</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>-43.827917</td>\n",
       "      <td>-43.578338</td>\n",
       "      <td>-43.234601</td>\n",
       "      <td>-43.572731</td>\n",
       "      <td>-43.827917</td>\n",
       "      <td>-43.827917</td>\n",
       "      <td>-43.827917</td>\n",
       "      <td>-43.558638</td>\n",
       "      <td>-43.596133</td>\n",
       "      <td>-43.827917</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.646369</td>\n",
       "      <td>-17.103772</td>\n",
       "      <td>-18.060084</td>\n",
       "      <td>-18.300959</td>\n",
       "      <td>-18.904725</td>\n",
       "      <td>-19.821105</td>\n",
       "      <td>-20.766101</td>\n",
       "      <td>-22.422723</td>\n",
       "      <td>-21.765500</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>-53.681973</td>\n",
       "      <td>-53.438813</td>\n",
       "      <td>-53.929762</td>\n",
       "      <td>-54.572111</td>\n",
       "      <td>-55.788444</td>\n",
       "      <td>-53.071579</td>\n",
       "      <td>-52.550545</td>\n",
       "      <td>-51.727692</td>\n",
       "      <td>-52.331120</td>\n",
       "      <td>-55.029013</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.898227</td>\n",
       "      <td>-48.781587</td>\n",
       "      <td>-49.259988</td>\n",
       "      <td>-48.016841</td>\n",
       "      <td>-49.829879</td>\n",
       "      <td>-50.776049</td>\n",
       "      <td>-49.930760</td>\n",
       "      <td>-52.789976</td>\n",
       "      <td>-55.869079</td>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>-53.700269</td>\n",
       "      <td>-53.832939</td>\n",
       "      <td>-55.695274</td>\n",
       "      <td>-55.929055</td>\n",
       "      <td>-54.200609</td>\n",
       "      <td>-53.187270</td>\n",
       "      <td>-53.727313</td>\n",
       "      <td>-55.705841</td>\n",
       "      <td>-56.291958</td>\n",
       "      <td>-55.521416</td>\n",
       "      <td>...</td>\n",
       "      <td>-53.805988</td>\n",
       "      <td>-54.251546</td>\n",
       "      <td>-54.206439</td>\n",
       "      <td>-53.196967</td>\n",
       "      <td>-54.226904</td>\n",
       "      <td>-55.663953</td>\n",
       "      <td>-53.149880</td>\n",
       "      <td>-51.462828</td>\n",
       "      <td>-52.426772</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>-29.514870</td>\n",
       "      <td>-31.776139</td>\n",
       "      <td>-36.120101</td>\n",
       "      <td>-35.954008</td>\n",
       "      <td>-35.894216</td>\n",
       "      <td>-35.951364</td>\n",
       "      <td>-34.607066</td>\n",
       "      <td>-35.883417</td>\n",
       "      <td>-36.135357</td>\n",
       "      <td>-37.427406</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.210504</td>\n",
       "      <td>-46.084817</td>\n",
       "      <td>-45.995474</td>\n",
       "      <td>-46.169773</td>\n",
       "      <td>-46.866463</td>\n",
       "      <td>-47.589461</td>\n",
       "      <td>-48.592283</td>\n",
       "      <td>-48.842870</td>\n",
       "      <td>-50.810683</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-46.148892</td>\n",
       "      <td>-45.965900</td>\n",
       "      <td>-46.465774</td>\n",
       "      <td>-50.426823</td>\n",
       "      <td>-50.016897</td>\n",
       "      <td>-49.716412</td>\n",
       "      <td>-49.669726</td>\n",
       "      <td>-49.205231</td>\n",
       "      <td>-50.857016</td>\n",
       "      <td>-52.708616</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.640589</td>\n",
       "      <td>-25.523332</td>\n",
       "      <td>-25.462610</td>\n",
       "      <td>-25.559839</td>\n",
       "      <td>-25.279617</td>\n",
       "      <td>-25.475659</td>\n",
       "      <td>-26.474084</td>\n",
       "      <td>-24.673720</td>\n",
       "      <td>-23.300059</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "146 -55.432984 -56.202228 -57.184010 -57.505661 -56.593266 -55.006390   \n",
       "583 -50.545312 -48.991972 -48.865521 -49.207718 -50.144840 -48.545571   \n",
       "161 -66.471029 -66.464810 -66.471029 -66.471029 -66.471029 -66.471029   \n",
       "201 -48.981466 -47.696597 -47.206740 -48.770675 -46.975942 -46.064501   \n",
       "608 -66.323343 -66.323343 -66.323343 -66.323343 -66.323343 -66.323343   \n",
       "644 -43.827917 -43.578338 -43.234601 -43.572731 -43.827917 -43.827917   \n",
       "802 -53.681973 -53.438813 -53.929762 -54.572111 -55.788444 -53.071579   \n",
       "612 -53.700269 -53.832939 -55.695274 -55.929055 -54.200609 -53.187270   \n",
       "562 -29.514870 -31.776139 -36.120101 -35.954008 -35.894216 -35.951364   \n",
       "98  -46.148892 -45.965900 -46.465774 -50.426823 -50.016897 -49.716412   \n",
       "\n",
       "           6          7          8          9    ...        207        208  \\\n",
       "146 -54.756210 -56.295744 -58.478039 -57.118607  ... -24.977090 -25.839029   \n",
       "583 -49.289383 -50.947019 -50.168514 -50.172467  ... -44.672711 -49.168897   \n",
       "161 -66.471029 -66.471029 -66.471029 -66.471029  ... -64.386411 -62.351795   \n",
       "201 -45.844486 -45.215074 -46.174046 -46.502808  ... -48.041735 -47.311513   \n",
       "608 -66.323343 -66.323343 -66.323343 -66.323343  ... -49.012368 -49.231145   \n",
       "644 -43.827917 -43.558638 -43.596133 -43.827917  ... -15.646369 -17.103772   \n",
       "802 -52.550545 -51.727692 -52.331120 -55.029013  ... -49.898227 -48.781587   \n",
       "612 -53.727313 -55.705841 -56.291958 -55.521416  ... -53.805988 -54.251546   \n",
       "562 -34.607066 -35.883417 -36.135357 -37.427406  ... -45.210504 -46.084817   \n",
       "98  -49.669726 -49.205231 -50.857016 -52.708616  ... -24.640589 -25.523332   \n",
       "\n",
       "           209        210        211        212        213        214  \\\n",
       "146 -24.558172 -24.293968 -23.481319 -22.684277 -21.958473 -20.250398   \n",
       "583 -48.626179 -49.492818 -49.116773 -48.921223 -46.197038 -45.821223   \n",
       "161 -64.222398 -66.152031 -63.642780 -63.769040 -66.471029 -66.471029   \n",
       "201 -48.412880 -48.155535 -44.662251 -45.211056 -47.680673 -48.981466   \n",
       "608 -47.134626 -46.901940 -45.832007 -45.729526 -46.371648 -47.507066   \n",
       "644 -18.060084 -18.300959 -18.904725 -19.821105 -20.766101 -22.422723   \n",
       "802 -49.259988 -48.016841 -49.829879 -50.776049 -49.930760 -52.789976   \n",
       "612 -54.206439 -53.196967 -54.226904 -55.663953 -53.149880 -51.462828   \n",
       "562 -45.995474 -46.169773 -46.866463 -47.589461 -48.592283 -48.842870   \n",
       "98  -25.462610 -25.559839 -25.279617 -25.475659 -26.474084 -24.673720   \n",
       "\n",
       "           215           0    \n",
       "146 -18.629301     male_calm  \n",
       "583 -48.995852  female_angry  \n",
       "161 -65.012717   female_calm  \n",
       "201 -48.981466  female_happy  \n",
       "608 -48.348944    male_angry  \n",
       "644 -21.765500    male_angry  \n",
       "802 -55.869079  male_fearful  \n",
       "612 -52.426772    male_angry  \n",
       "562 -50.810683      male_sad  \n",
       "98  -23.300059     male_calm  \n",
       "\n",
       "[10 rows x 217 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "rnewdf = shuffle(newdf)\n",
    "rnewdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf=rnewdf.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1 = np.random.rand(len(rnewdf)) < 0.8\n",
    "train = rnewdf[newdf1]\n",
    "test = rnewdf[~newdf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>-56.741266</td>\n",
       "      <td>-57.096956</td>\n",
       "      <td>-60.335412</td>\n",
       "      <td>-62.451952</td>\n",
       "      <td>-59.003335</td>\n",
       "      <td>-60.339123</td>\n",
       "      <td>-63.469751</td>\n",
       "      <td>-66.836010</td>\n",
       "      <td>-64.909165</td>\n",
       "      <td>-64.727420</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.501543</td>\n",
       "      <td>-55.001044</td>\n",
       "      <td>-56.785555</td>\n",
       "      <td>-51.061866</td>\n",
       "      <td>-49.443464</td>\n",
       "      <td>-54.635694</td>\n",
       "      <td>-55.019453</td>\n",
       "      <td>-56.437112</td>\n",
       "      <td>-55.552043</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>-65.616624</td>\n",
       "      <td>-65.616624</td>\n",
       "      <td>-65.616624</td>\n",
       "      <td>-65.629987</td>\n",
       "      <td>-64.431612</td>\n",
       "      <td>-64.589771</td>\n",
       "      <td>-65.616624</td>\n",
       "      <td>-65.616624</td>\n",
       "      <td>-65.616624</td>\n",
       "      <td>-65.616624</td>\n",
       "      <td>...</td>\n",
       "      <td>-59.438908</td>\n",
       "      <td>-62.978231</td>\n",
       "      <td>-60.258270</td>\n",
       "      <td>-57.235445</td>\n",
       "      <td>-55.851677</td>\n",
       "      <td>-58.888949</td>\n",
       "      <td>-59.853692</td>\n",
       "      <td>-61.910080</td>\n",
       "      <td>-61.882730</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>-77.300767</td>\n",
       "      <td>-77.871972</td>\n",
       "      <td>-78.612838</td>\n",
       "      <td>-79.002560</td>\n",
       "      <td>-79.325658</td>\n",
       "      <td>-79.323007</td>\n",
       "      <td>-79.323007</td>\n",
       "      <td>-79.323007</td>\n",
       "      <td>-79.323007</td>\n",
       "      <td>-79.323007</td>\n",
       "      <td>...</td>\n",
       "      <td>-63.696232</td>\n",
       "      <td>-67.464793</td>\n",
       "      <td>-65.756060</td>\n",
       "      <td>-66.345690</td>\n",
       "      <td>-66.215256</td>\n",
       "      <td>-60.145253</td>\n",
       "      <td>-62.800592</td>\n",
       "      <td>-62.715150</td>\n",
       "      <td>-62.603528</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>-52.150201</td>\n",
       "      <td>-52.054038</td>\n",
       "      <td>-52.210037</td>\n",
       "      <td>-52.210308</td>\n",
       "      <td>-52.117225</td>\n",
       "      <td>-52.057665</td>\n",
       "      <td>-52.019825</td>\n",
       "      <td>-52.019825</td>\n",
       "      <td>-52.019825</td>\n",
       "      <td>-52.019825</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.654898</td>\n",
       "      <td>-47.466899</td>\n",
       "      <td>-47.735275</td>\n",
       "      <td>-48.166131</td>\n",
       "      <td>-47.081075</td>\n",
       "      <td>-46.531241</td>\n",
       "      <td>-45.782631</td>\n",
       "      <td>-46.428393</td>\n",
       "      <td>-46.711735</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>-50.683447</td>\n",
       "      <td>-49.582845</td>\n",
       "      <td>-49.573145</td>\n",
       "      <td>-49.530697</td>\n",
       "      <td>-51.778389</td>\n",
       "      <td>-49.248276</td>\n",
       "      <td>-49.240766</td>\n",
       "      <td>-49.972067</td>\n",
       "      <td>-51.259530</td>\n",
       "      <td>-50.161117</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.108314</td>\n",
       "      <td>-50.828198</td>\n",
       "      <td>-51.525122</td>\n",
       "      <td>-50.562866</td>\n",
       "      <td>-49.983553</td>\n",
       "      <td>-52.057093</td>\n",
       "      <td>-50.964304</td>\n",
       "      <td>-50.562960</td>\n",
       "      <td>-51.980808</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-64.663055</td>\n",
       "      <td>-64.448593</td>\n",
       "      <td>-65.173871</td>\n",
       "      <td>-65.662805</td>\n",
       "      <td>-65.662805</td>\n",
       "      <td>-65.662805</td>\n",
       "      <td>-65.662805</td>\n",
       "      <td>-65.662805</td>\n",
       "      <td>-65.662805</td>\n",
       "      <td>-65.662805</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.964399</td>\n",
       "      <td>-38.152092</td>\n",
       "      <td>-39.424238</td>\n",
       "      <td>-39.348848</td>\n",
       "      <td>-39.895474</td>\n",
       "      <td>-39.905080</td>\n",
       "      <td>-42.550736</td>\n",
       "      <td>-43.243879</td>\n",
       "      <td>-39.797571</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>-45.182998</td>\n",
       "      <td>-47.211669</td>\n",
       "      <td>-50.592894</td>\n",
       "      <td>-53.360218</td>\n",
       "      <td>-51.247242</td>\n",
       "      <td>-50.312643</td>\n",
       "      <td>-51.028291</td>\n",
       "      <td>-51.513125</td>\n",
       "      <td>-50.413727</td>\n",
       "      <td>-48.315339</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.372282</td>\n",
       "      <td>-47.701173</td>\n",
       "      <td>-50.583976</td>\n",
       "      <td>-51.380535</td>\n",
       "      <td>-51.403674</td>\n",
       "      <td>-51.627796</td>\n",
       "      <td>-48.571527</td>\n",
       "      <td>-48.987322</td>\n",
       "      <td>-47.773933</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-57.895241</td>\n",
       "      <td>-56.911636</td>\n",
       "      <td>-57.946421</td>\n",
       "      <td>-58.111761</td>\n",
       "      <td>-55.472795</td>\n",
       "      <td>-56.331500</td>\n",
       "      <td>-57.309017</td>\n",
       "      <td>-60.092864</td>\n",
       "      <td>-59.959078</td>\n",
       "      <td>-58.216662</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.844675</td>\n",
       "      <td>-33.636118</td>\n",
       "      <td>-33.725746</td>\n",
       "      <td>-34.900446</td>\n",
       "      <td>-38.407901</td>\n",
       "      <td>-38.195317</td>\n",
       "      <td>-38.506610</td>\n",
       "      <td>-38.173440</td>\n",
       "      <td>-34.352565</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>-52.144882</td>\n",
       "      <td>-53.959018</td>\n",
       "      <td>-55.145461</td>\n",
       "      <td>-53.612339</td>\n",
       "      <td>-52.147070</td>\n",
       "      <td>-49.463857</td>\n",
       "      <td>-49.172999</td>\n",
       "      <td>-52.111884</td>\n",
       "      <td>-53.611675</td>\n",
       "      <td>-50.524048</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.998890</td>\n",
       "      <td>-52.317006</td>\n",
       "      <td>-51.349279</td>\n",
       "      <td>-51.088707</td>\n",
       "      <td>-51.130629</td>\n",
       "      <td>-50.069041</td>\n",
       "      <td>-50.267326</td>\n",
       "      <td>-51.520944</td>\n",
       "      <td>-52.932136</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>-56.143983</td>\n",
       "      <td>-56.115295</td>\n",
       "      <td>-56.115295</td>\n",
       "      <td>-56.115295</td>\n",
       "      <td>-56.115295</td>\n",
       "      <td>-56.115295</td>\n",
       "      <td>-56.115295</td>\n",
       "      <td>-56.115295</td>\n",
       "      <td>-56.115295</td>\n",
       "      <td>-56.115295</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.816833</td>\n",
       "      <td>-53.152288</td>\n",
       "      <td>-50.878348</td>\n",
       "      <td>-51.290188</td>\n",
       "      <td>-51.298487</td>\n",
       "      <td>-53.192987</td>\n",
       "      <td>-52.801656</td>\n",
       "      <td>-50.226913</td>\n",
       "      <td>-51.494558</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "560 -56.741266 -57.096956 -60.335412 -62.451952 -59.003335 -60.339123   \n",
       "387 -65.616624 -65.616624 -65.616624 -65.629987 -64.431612 -64.589771   \n",
       "475 -77.300767 -77.871972 -78.612838 -79.002560 -79.325658 -79.323007   \n",
       "539 -52.150201 -52.054038 -52.210037 -52.210308 -52.117225 -52.057665   \n",
       "280 -50.683447 -49.582845 -49.573145 -49.530697 -51.778389 -49.248276   \n",
       "11  -64.663055 -64.448593 -65.173871 -65.662805 -65.662805 -65.662805   \n",
       "511 -45.182998 -47.211669 -50.592894 -53.360218 -51.247242 -50.312643   \n",
       "196 -57.895241 -56.911636 -57.946421 -58.111761 -55.472795 -56.331500   \n",
       "393 -52.144882 -53.959018 -55.145461 -53.612339 -52.147070 -49.463857   \n",
       "231 -56.143983 -56.115295 -56.115295 -56.115295 -56.115295 -56.115295   \n",
       "\n",
       "           6          7          8          9    ...        207        208  \\\n",
       "560 -63.469751 -66.836010 -64.909165 -64.727420  ... -49.501543 -55.001044   \n",
       "387 -65.616624 -65.616624 -65.616624 -65.616624  ... -59.438908 -62.978231   \n",
       "475 -79.323007 -79.323007 -79.323007 -79.323007  ... -63.696232 -67.464793   \n",
       "539 -52.019825 -52.019825 -52.019825 -52.019825  ... -47.654898 -47.466899   \n",
       "280 -49.240766 -49.972067 -51.259530 -50.161117  ... -50.108314 -50.828198   \n",
       "11  -65.662805 -65.662805 -65.662805 -65.662805  ... -35.964399 -38.152092   \n",
       "511 -51.028291 -51.513125 -50.413727 -48.315339  ... -49.372282 -47.701173   \n",
       "196 -57.309017 -60.092864 -59.959078 -58.216662  ... -33.844675 -33.636118   \n",
       "393 -49.172999 -52.111884 -53.611675 -50.524048  ... -50.998890 -52.317006   \n",
       "231 -56.115295 -56.115295 -56.115295 -56.115295  ... -49.816833 -53.152288   \n",
       "\n",
       "           209        210        211        212        213        214  \\\n",
       "560 -56.785555 -51.061866 -49.443464 -54.635694 -55.019453 -56.437112   \n",
       "387 -60.258270 -57.235445 -55.851677 -58.888949 -59.853692 -61.910080   \n",
       "475 -65.756060 -66.345690 -66.215256 -60.145253 -62.800592 -62.715150   \n",
       "539 -47.735275 -48.166131 -47.081075 -46.531241 -45.782631 -46.428393   \n",
       "280 -51.525122 -50.562866 -49.983553 -52.057093 -50.964304 -50.562960   \n",
       "11  -39.424238 -39.348848 -39.895474 -39.905080 -42.550736 -43.243879   \n",
       "511 -50.583976 -51.380535 -51.403674 -51.627796 -48.571527 -48.987322   \n",
       "196 -33.725746 -34.900446 -38.407901 -38.195317 -38.506610 -38.173440   \n",
       "393 -51.349279 -51.088707 -51.130629 -50.069041 -50.267326 -51.520944   \n",
       "231 -50.878348 -51.290188 -51.298487 -53.192987 -52.801656 -50.226913   \n",
       "\n",
       "           215           0    \n",
       "560 -55.552043      male_sad  \n",
       "387 -61.882730    female_sad  \n",
       "475 -62.603528    female_sad  \n",
       "539 -46.711735    female_sad  \n",
       "280 -51.980808    male_happy  \n",
       "11  -39.797571   female_calm  \n",
       "511 -47.773933    female_sad  \n",
       "196 -34.352565    male_happy  \n",
       "393 -52.932136    female_sad  \n",
       "231 -51.494558  female_happy  \n",
       "\n",
       "[10 rows x 217 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[250:260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfeatures = train.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabel = train.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = test.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlabel = test.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\sklearn\\preprocessing\\label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabel)\n",
    "X_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabel)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(766, 216)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing dimension for CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Conv1D(128, 5,padding='same',))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv1D(128, 5,padding='same',))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 216, 256)          1536      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 216, 128)          163968    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                34570     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 364,170\n",
      "Trainable params: 364,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 766 samples, validate on 194 samples\n",
      "Epoch 1/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 2.8134 - acc: 0.1057 - val_loss: 2.3677 - val_acc: 0.1031\n",
      "Epoch 2/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 2.3431 - acc: 0.0979 - val_loss: 2.3181 - val_acc: 0.1443\n",
      "Epoch 3/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 2.2976 - acc: 0.1292 - val_loss: 2.3019 - val_acc: 0.0825\n",
      "Epoch 4/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 2.2656 - acc: 0.1384 - val_loss: 2.2683 - val_acc: 0.1443\n",
      "Epoch 5/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 2.2425 - acc: 0.1580 - val_loss: 2.2468 - val_acc: 0.2268\n",
      "Epoch 6/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 2.2251 - acc: 0.1645 - val_loss: 2.2326 - val_acc: 0.2113: 1s - loss: 2.2268 - acc: 0.1 - ETA: 1s - loss: 2.224\n",
      "Epoch 7/700\n",
      "766/766 [==============================] - 4s 6ms/step - loss: 2.2004 - acc: 0.2128 - val_loss: 2.2290 - val_acc: 0.1186\n",
      "Epoch 8/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 2.1780 - acc: 0.2050 - val_loss: 2.2082 - val_acc: 0.2474\n",
      "Epoch 9/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 2.1589 - acc: 0.2128 - val_loss: 2.1888 - val_acc: 0.2268\n",
      "Epoch 10/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 2.1348 - acc: 0.2311 - val_loss: 2.1484 - val_acc: 0.2474\n",
      "Epoch 11/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 2.1173 - acc: 0.2363 - val_loss: 2.1340 - val_acc: 0.2680\n",
      "Epoch 12/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 2.0980 - acc: 0.2598 - val_loss: 2.1347 - val_acc: 0.2629c: 0.260\n",
      "Epoch 13/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 2.0778 - acc: 0.2611 - val_loss: 2.1160 - val_acc: 0.2577\n",
      "Epoch 14/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 2.0581 - acc: 0.2650 - val_loss: 2.0952 - val_acc: 0.2938\n",
      "Epoch 15/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 2.0409 - acc: 0.2728 - val_loss: 2.0819 - val_acc: 0.2784\n",
      "Epoch 16/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 2.0220 - acc: 0.2755 - val_loss: 2.0693 - val_acc: 0.2629\n",
      "Epoch 17/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 2.0016 - acc: 0.3042 - val_loss: 2.0693 - val_acc: 0.2835\n",
      "Epoch 18/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.9892 - acc: 0.3133 - val_loss: 2.0518 - val_acc: 0.2732\n",
      "Epoch 19/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.9671 - acc: 0.3198 - val_loss: 2.0246 - val_acc: 0.3144\n",
      "Epoch 20/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.9515 - acc: 0.3198 - val_loss: 2.0094 - val_acc: 0.3351\n",
      "Epoch 21/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.9298 - acc: 0.3368 - val_loss: 1.9985 - val_acc: 0.3454\n",
      "Epoch 22/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.9146 - acc: 0.3433 - val_loss: 1.9712 - val_acc: 0.3299\n",
      "Epoch 23/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.9010 - acc: 0.3316 - val_loss: 1.9713 - val_acc: 0.3454\n",
      "Epoch 24/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.8824 - acc: 0.3668 - val_loss: 1.9655 - val_acc: 0.2990\n",
      "Epoch 25/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.8716 - acc: 0.3499 - val_loss: 1.9444 - val_acc: 0.3351\n",
      "Epoch 26/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.8449 - acc: 0.3773 - val_loss: 1.9572 - val_acc: 0.3196\n",
      "Epoch 27/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.8389 - acc: 0.3747 - val_loss: 1.9136 - val_acc: 0.3763- \n",
      "Epoch 28/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.8204 - acc: 0.3786 - val_loss: 1.9236 - val_acc: 0.3351\n",
      "Epoch 29/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 1.8065 - acc: 0.3747 - val_loss: 1.9014 - val_acc: 0.3557\n",
      "Epoch 30/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.7962 - acc: 0.3681 - val_loss: 1.9023 - val_acc: 0.3299\n",
      "Epoch 31/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.7811 - acc: 0.4060 - val_loss: 1.8760 - val_acc: 0.3557\n",
      "Epoch 32/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.7622 - acc: 0.3930 - val_loss: 1.8672 - val_acc: 0.3402\n",
      "Epoch 33/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.7451 - acc: 0.4034 - val_loss: 1.8482 - val_acc: 0.3608\n",
      "Epoch 34/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.7325 - acc: 0.3903 - val_loss: 1.8569 - val_acc: 0.3299\n",
      "Epoch 35/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.7182 - acc: 0.3930 - val_loss: 1.8433 - val_acc: 0.3557\n",
      "Epoch 36/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.7033 - acc: 0.4073 - val_loss: 1.8215 - val_acc: 0.3763\n",
      "Epoch 37/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.6958 - acc: 0.4034 - val_loss: 1.8126 - val_acc: 0.3660\n",
      "Epoch 38/700\n",
      "766/766 [==============================] - 4s 6ms/step - loss: 1.6785 - acc: 0.4399 - val_loss: 1.8232 - val_acc: 0.3608\n",
      "Epoch 39/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 1.6641 - acc: 0.4099 - val_loss: 1.8017 - val_acc: 0.3711\n",
      "Epoch 40/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.6521 - acc: 0.4230 - val_loss: 1.7948 - val_acc: 0.3711\n",
      "Epoch 41/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.6451 - acc: 0.4086 - val_loss: 1.7994 - val_acc: 0.3247\n",
      "Epoch 42/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.6295 - acc: 0.4269 - val_loss: 1.7717 - val_acc: 0.3557\n",
      "Epoch 43/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.6169 - acc: 0.4347 - val_loss: 1.7755 - val_acc: 0.3608\n",
      "Epoch 44/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.6110 - acc: 0.4191 - val_loss: 1.7593 - val_acc: 0.4021\n",
      "Epoch 45/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.6030 - acc: 0.4230 - val_loss: 1.7483 - val_acc: 0.3814\n",
      "Epoch 46/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 1.5857 - acc: 0.4256 - val_loss: 1.7470 - val_acc: 0.3660\n",
      "Epoch 47/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.5798 - acc: 0.4530 - val_loss: 1.7409 - val_acc: 0.3814\n",
      "Epoch 48/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 1.5719 - acc: 0.4426 - val_loss: 1.7134 - val_acc: 0.4072\n",
      "Epoch 49/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.5606 - acc: 0.4504 - val_loss: 1.7319 - val_acc: 0.3505\n",
      "Epoch 50/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.5581 - acc: 0.4295 - val_loss: 1.7205 - val_acc: 0.3505\n",
      "Epoch 51/700\n",
      "766/766 [==============================] - 4s 6ms/step - loss: 1.5453 - acc: 0.4465 - val_loss: 1.7228 - val_acc: 0.3711\n",
      "Epoch 52/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.5271 - acc: 0.4634 - val_loss: 1.7156 - val_acc: 0.3711\n",
      "Epoch 53/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.5290 - acc: 0.4569 - val_loss: 1.7110 - val_acc: 0.3918\n",
      "Epoch 54/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.5218 - acc: 0.4517 - val_loss: 1.6864 - val_acc: 0.3814\n",
      "Epoch 55/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.5071 - acc: 0.4608 - val_loss: 1.6948 - val_acc: 0.3557\n",
      "Epoch 56/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.5033 - acc: 0.4687 - val_loss: 1.6887 - val_acc: 0.3608\n",
      "Epoch 57/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 1.4945 - acc: 0.4504 - val_loss: 1.6892 - val_acc: 0.3660\n",
      "Epoch 58/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 1.4943 - acc: 0.4752 - val_loss: 1.7095 - val_acc: 0.3402\n",
      "Epoch 59/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.4856 - acc: 0.4648 - val_loss: 1.6989 - val_acc: 0.3660\n",
      "Epoch 60/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.4663 - acc: 0.4608 - val_loss: 1.6774 - val_acc: 0.3711\n",
      "Epoch 61/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.4610 - acc: 0.4700 - val_loss: 1.6914 - val_acc: 0.3505\n",
      "Epoch 62/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.4632 - acc: 0.4830 - val_loss: 1.6921 - val_acc: 0.3660\n",
      "Epoch 63/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 1.4481 - acc: 0.4791 - val_loss: 1.6958 - val_acc: 0.3814\n",
      "Epoch 64/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.4603 - acc: 0.4726 - val_loss: 1.6601 - val_acc: 0.3608\n",
      "Epoch 65/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.4458 - acc: 0.4765 - val_loss: 1.6646 - val_acc: 0.3763\n",
      "Epoch 66/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.4392 - acc: 0.4804 - val_loss: 1.6438 - val_acc: 0.3918\n",
      "Epoch 67/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.4338 - acc: 0.4974 - val_loss: 1.6249 - val_acc: 0.4072\n",
      "Epoch 68/700\n",
      "766/766 [==============================] - 4s 6ms/step - loss: 1.4275 - acc: 0.4909 - val_loss: 1.6284 - val_acc: 0.3918\n",
      "Epoch 69/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.4216 - acc: 0.4791 - val_loss: 1.6240 - val_acc: 0.3866\n",
      "Epoch 70/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.4107 - acc: 0.4922 - val_loss: 1.6184 - val_acc: 0.3918\n",
      "Epoch 71/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.4014 - acc: 0.4909 - val_loss: 1.6321 - val_acc: 0.3763\n",
      "Epoch 72/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.4065 - acc: 0.4726 - val_loss: 1.6289 - val_acc: 0.4021\n",
      "Epoch 73/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.3973 - acc: 0.4935 - val_loss: 1.6256 - val_acc: 0.3763\n",
      "Epoch 74/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.3936 - acc: 0.4869 - val_loss: 1.6406 - val_acc: 0.3711\n",
      "Epoch 75/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3906 - acc: 0.4817 - val_loss: 1.6436 - val_acc: 0.4072\n",
      "Epoch 76/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 1.3923 - acc: 0.4935 - val_loss: 1.5974 - val_acc: 0.3918\n",
      "Epoch 77/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.3766 - acc: 0.5157 - val_loss: 1.6259 - val_acc: 0.4175\n",
      "Epoch 78/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.3745 - acc: 0.5078 - val_loss: 1.6102 - val_acc: 0.4175\n",
      "Epoch 79/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3751 - acc: 0.4987 - val_loss: 1.6259 - val_acc: 0.3814\n",
      "Epoch 80/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3626 - acc: 0.4987 - val_loss: 1.5994 - val_acc: 0.4021\n",
      "Epoch 81/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3661 - acc: 0.4804 - val_loss: 1.5903 - val_acc: 0.4124\n",
      "Epoch 82/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3583 - acc: 0.5157 - val_loss: 1.6072 - val_acc: 0.4330\n",
      "Epoch 83/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.3480 - acc: 0.4974 - val_loss: 1.6221 - val_acc: 0.3711\n",
      "Epoch 84/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3579 - acc: 0.5000 - val_loss: 1.5929 - val_acc: 0.4175\n",
      "Epoch 85/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.3475 - acc: 0.5065 - val_loss: 1.5793 - val_acc: 0.4381\n",
      "Epoch 86/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3391 - acc: 0.5222 - val_loss: 1.5699 - val_acc: 0.4175\n",
      "Epoch 87/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3423 - acc: 0.5013 - val_loss: 1.5766 - val_acc: 0.4124\n",
      "Epoch 88/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.3295 - acc: 0.5131 - val_loss: 1.5810 - val_acc: 0.3918\n",
      "Epoch 89/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3265 - acc: 0.5039 - val_loss: 1.5854 - val_acc: 0.4072\n",
      "Epoch 90/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3226 - acc: 0.5117 - val_loss: 1.6029 - val_acc: 0.4021\n",
      "Epoch 91/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3264 - acc: 0.5196 - val_loss: 1.5803 - val_acc: 0.3866\n",
      "Epoch 92/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3219 - acc: 0.5013 - val_loss: 1.5836 - val_acc: 0.4072\n",
      "Epoch 93/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3117 - acc: 0.5157 - val_loss: 1.5455 - val_acc: 0.4072\n",
      "Epoch 94/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3205 - acc: 0.5052 - val_loss: 1.5692 - val_acc: 0.4278\n",
      "Epoch 95/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3102 - acc: 0.5157 - val_loss: 1.5589 - val_acc: 0.4072\n",
      "Epoch 96/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3070 - acc: 0.5235 - val_loss: 1.5682 - val_acc: 0.4124\n",
      "Epoch 97/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.3118 - acc: 0.5131 - val_loss: 1.5637 - val_acc: 0.4381\n",
      "Epoch 98/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2877 - acc: 0.5196 - val_loss: 1.5818 - val_acc: 0.3969cc: \n",
      "Epoch 99/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2938 - acc: 0.5091 - val_loss: 1.5770 - val_acc: 0.4021\n",
      "Epoch 100/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2947 - acc: 0.5065 - val_loss: 1.5473 - val_acc: 0.4278\n",
      "Epoch 101/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2923 - acc: 0.5287 - val_loss: 1.5589 - val_acc: 0.4381\n",
      "Epoch 102/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2847 - acc: 0.5287 - val_loss: 1.5729 - val_acc: 0.4330\n",
      "Epoch 103/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2834 - acc: 0.5300 - val_loss: 1.5386 - val_acc: 0.4536\n",
      "Epoch 104/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2781 - acc: 0.5248 - val_loss: 1.5695 - val_acc: 0.4433\n",
      "Epoch 105/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2836 - acc: 0.5339 - val_loss: 1.5837 - val_acc: 0.4072\n",
      "Epoch 106/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2828 - acc: 0.5117 - val_loss: 1.5545 - val_acc: 0.4227\n",
      "Epoch 107/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2723 - acc: 0.5274 - val_loss: 1.5791 - val_acc: 0.4175\n",
      "Epoch 108/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2689 - acc: 0.5248 - val_loss: 1.5318 - val_acc: 0.4588 acc: 0.51 - ETA: 0s - loss: 1.2773 - acc: 0.\n",
      "Epoch 109/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2640 - acc: 0.5339 - val_loss: 1.5680 - val_acc: 0.4536\n",
      "Epoch 110/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2660 - acc: 0.5392 - val_loss: 1.5312 - val_acc: 0.4485\n",
      "Epoch 111/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2664 - acc: 0.5470 - val_loss: 1.5685 - val_acc: 0.4021\n",
      "Epoch 112/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2613 - acc: 0.5287 - val_loss: 1.6514 - val_acc: 0.3402\n",
      "Epoch 113/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2584 - acc: 0.5222 - val_loss: 1.5520 - val_acc: 0.4278\n",
      "Epoch 114/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 1.2511 - acc: 0.5535 - val_loss: 1.5639 - val_acc: 0.4072\n",
      "Epoch 115/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2609 - acc: 0.5274 - val_loss: 1.5598 - val_acc: 0.4381\n",
      "Epoch 116/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2435 - acc: 0.5313 - val_loss: 1.5812 - val_acc: 0.3969\n",
      "Epoch 117/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2439 - acc: 0.5313 - val_loss: 1.5622 - val_acc: 0.4278\n",
      "Epoch 118/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2471 - acc: 0.5483 - val_loss: 1.5358 - val_acc: 0.4433\n",
      "Epoch 119/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2400 - acc: 0.5379 - val_loss: 1.5250 - val_acc: 0.4691\n",
      "Epoch 120/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.2402 - acc: 0.5405 - val_loss: 1.5181 - val_acc: 0.4639\n",
      "Epoch 121/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2408 - acc: 0.5666 - val_loss: 1.5353 - val_acc: 0.4278\n",
      "Epoch 122/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2257 - acc: 0.5574 - val_loss: 1.5179 - val_acc: 0.4639\n",
      "Epoch 123/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2374 - acc: 0.5392 - val_loss: 1.5564 - val_acc: 0.4278\n",
      "Epoch 124/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2233 - acc: 0.5692 - val_loss: 1.5548 - val_acc: 0.4175\n",
      "Epoch 125/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.2332 - acc: 0.5418 - val_loss: 1.5757 - val_acc: 0.3814\n",
      "Epoch 126/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2216 - acc: 0.5496 - val_loss: 1.5507 - val_acc: 0.4433\n",
      "Epoch 127/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.2150 - acc: 0.5496 - val_loss: 1.5261 - val_acc: 0.4691s: 1.2166 - acc: \n",
      "Epoch 128/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2186 - acc: 0.5614 - val_loss: 1.5333 - val_acc: 0.4381\n",
      "Epoch 129/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.2201 - acc: 0.5379 - val_loss: 1.5292 - val_acc: 0.4433\n",
      "Epoch 130/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2148 - acc: 0.5522 - val_loss: 1.5513 - val_acc: 0.4175\n",
      "Epoch 131/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.2105 - acc: 0.5705 - val_loss: 1.5539 - val_acc: 0.4227\n",
      "Epoch 132/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2060 - acc: 0.5574 - val_loss: 1.5248 - val_acc: 0.4588 - acc: 0.5\n",
      "Epoch 133/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2081 - acc: 0.5731 - val_loss: 1.5474 - val_acc: 0.4227\n",
      "Epoch 134/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.2144 - acc: 0.5496 - val_loss: 1.5408 - val_acc: 0.4278\n",
      "Epoch 135/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1979 - acc: 0.5535 - val_loss: 1.5302 - val_acc: 0.4742\n",
      "Epoch 136/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1911 - acc: 0.5692 - val_loss: 1.5464 - val_acc: 0.4330\n",
      "Epoch 137/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1876 - acc: 0.5614 - val_loss: 1.5600 - val_acc: 0.4433\n",
      "Epoch 138/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1933 - acc: 0.5587 - val_loss: 1.5423 - val_acc: 0.4330\n",
      "Epoch 139/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1806 - acc: 0.5653 - val_loss: 1.5331 - val_acc: 0.4536\n",
      "Epoch 140/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1906 - acc: 0.5692 - val_loss: 1.5648 - val_acc: 0.4175\n",
      "Epoch 141/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1859 - acc: 0.5744 - val_loss: 1.5440 - val_acc: 0.4536\n",
      "Epoch 142/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1911 - acc: 0.5483 - val_loss: 1.5540 - val_acc: 0.4124\n",
      "Epoch 143/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1866 - acc: 0.5627 - val_loss: 1.5286 - val_acc: 0.4381\n",
      "Epoch 144/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1919 - acc: 0.5862 - val_loss: 1.5111 - val_acc: 0.4588\n",
      "Epoch 145/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1774 - acc: 0.5640 - val_loss: 1.5787 - val_acc: 0.4330\n",
      "Epoch 146/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.1820 - acc: 0.5679 - val_loss: 1.5252 - val_acc: 0.4433\n",
      "Epoch 147/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.1774 - acc: 0.5927 - val_loss: 1.5203 - val_acc: 0.4536\n",
      "Epoch 148/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1751 - acc: 0.5692 - val_loss: 1.5403 - val_acc: 0.4330\n",
      "Epoch 149/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.1688 - acc: 0.5796 - val_loss: 1.5084 - val_acc: 0.4433\n",
      "Epoch 150/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1712 - acc: 0.5796 - val_loss: 1.5152 - val_acc: 0.4485\n",
      "Epoch 151/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1596 - acc: 0.5849 - val_loss: 1.5141 - val_acc: 0.4485\n",
      "Epoch 152/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1630 - acc: 0.5875 - val_loss: 1.5003 - val_acc: 0.4536\n",
      "Epoch 153/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1519 - acc: 0.5862 - val_loss: 1.5433 - val_acc: 0.4381\n",
      "Epoch 154/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.1574 - acc: 0.5692 - val_loss: 1.5192 - val_acc: 0.4742\n",
      "Epoch 155/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1588 - acc: 0.5809 - val_loss: 1.5402 - val_acc: 0.4639\n",
      "Epoch 156/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1445 - acc: 0.5796 - val_loss: 1.5318 - val_acc: 0.4536\n",
      "Epoch 157/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1539 - acc: 0.5862 - val_loss: 1.5383 - val_acc: 0.4227\n",
      "Epoch 158/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1445 - acc: 0.5914 - val_loss: 1.5160 - val_acc: 0.4381\n",
      "Epoch 159/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.1506 - acc: 0.5796 - val_loss: 1.5767 - val_acc: 0.4485\n",
      "Epoch 160/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1459 - acc: 0.5875 - val_loss: 1.5023 - val_acc: 0.4794\n",
      "Epoch 161/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 1.1420 - acc: 0.5809 - val_loss: 1.5427 - val_acc: 0.4639\n",
      "Epoch 162/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 1.1494 - acc: 0.5718 - val_loss: 1.5050 - val_acc: 0.4485\n",
      "Epoch 163/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.1297 - acc: 0.5822 - val_loss: 1.5691 - val_acc: 0.4124\n",
      "Epoch 164/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.1336 - acc: 0.5940 - val_loss: 1.5281 - val_acc: 0.4691\n",
      "Epoch 165/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.1531 - acc: 0.5809 - val_loss: 1.5341 - val_acc: 0.4691\n",
      "Epoch 166/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.1381 - acc: 0.5901 - val_loss: 1.4763 - val_acc: 0.4639\n",
      "Epoch 167/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.1296 - acc: 0.5979 - val_loss: 1.5208 - val_acc: 0.4588\n",
      "Epoch 168/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.1326 - acc: 0.5992 - val_loss: 1.5054 - val_acc: 0.4639\n",
      "Epoch 169/700\n",
      "766/766 [==============================] - 6s 7ms/step - loss: 1.1297 - acc: 0.6123 - val_loss: 1.5370 - val_acc: 0.4227\n",
      "Epoch 170/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.1352 - acc: 0.5914 - val_loss: 1.5186 - val_acc: 0.4588\n",
      "Epoch 171/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.1162 - acc: 0.5862 - val_loss: 1.5203 - val_acc: 0.4227\n",
      "Epoch 172/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.1251 - acc: 0.5914 - val_loss: 1.5114 - val_acc: 0.4742\n",
      "Epoch 173/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.1183 - acc: 0.6110 - val_loss: 1.5402 - val_acc: 0.4433\n",
      "Epoch 174/700\n",
      "766/766 [==============================] - 6s 7ms/step - loss: 1.1078 - acc: 0.6070 - val_loss: 1.5142 - val_acc: 0.4485\n",
      "Epoch 175/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.1179 - acc: 0.5992 - val_loss: 1.5144 - val_acc: 0.4485\n",
      "Epoch 176/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.1100 - acc: 0.5953 - val_loss: 1.4912 - val_acc: 0.4691\n",
      "Epoch 177/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.1173 - acc: 0.6031 - val_loss: 1.5028 - val_acc: 0.4794\n",
      "Epoch 178/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.1098 - acc: 0.5979 - val_loss: 1.5127 - val_acc: 0.4639\n",
      "Epoch 179/700\n",
      "766/766 [==============================] - 7s 9ms/step - loss: 1.1137 - acc: 0.5901 - val_loss: 1.5397 - val_acc: 0.4278\n",
      "Epoch 180/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.1053 - acc: 0.5901 - val_loss: 1.5027 - val_acc: 0.4381\n",
      "Epoch 181/700\n",
      "766/766 [==============================] - 6s 7ms/step - loss: 1.1037 - acc: 0.6031 - val_loss: 1.5079 - val_acc: 0.4691\n",
      "Epoch 182/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.1050 - acc: 0.6044 - val_loss: 1.5088 - val_acc: 0.4485\n",
      "Epoch 183/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.1014 - acc: 0.5862 - val_loss: 1.5226 - val_acc: 0.4742\n",
      "Epoch 184/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0998 - acc: 0.5953 - val_loss: 1.5030 - val_acc: 0.4691\n",
      "Epoch 185/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.0951 - acc: 0.5940 - val_loss: 1.5319 - val_acc: 0.4278\n",
      "Epoch 186/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.0983 - acc: 0.6044 - val_loss: 1.5253 - val_acc: 0.4381\n",
      "Epoch 187/700\n",
      "766/766 [==============================] - 6s 7ms/step - loss: 1.0956 - acc: 0.6044 - val_loss: 1.5187 - val_acc: 0.4742\n",
      "Epoch 188/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.0944 - acc: 0.6070 - val_loss: 1.4919 - val_acc: 0.4691\n",
      "Epoch 189/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0912 - acc: 0.6018 - val_loss: 1.5159 - val_acc: 0.4485\n",
      "Epoch 190/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0831 - acc: 0.6175 - val_loss: 1.5173 - val_acc: 0.4433\n",
      "Epoch 191/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0876 - acc: 0.5992 - val_loss: 1.5244 - val_acc: 0.4536\n",
      "Epoch 192/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0814 - acc: 0.6266 - val_loss: 1.4993 - val_acc: 0.4588\n",
      "Epoch 193/700\n",
      "766/766 [==============================] - 7s 9ms/step - loss: 1.0811 - acc: 0.6201 - val_loss: 1.4997 - val_acc: 0.4691\n",
      "Epoch 194/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0813 - acc: 0.6227 - val_loss: 1.5058 - val_acc: 0.4588\n",
      "Epoch 195/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0765 - acc: 0.6214 - val_loss: 1.4891 - val_acc: 0.4897\n",
      "Epoch 196/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0784 - acc: 0.6188 - val_loss: 1.5058 - val_acc: 0.4691\n",
      "Epoch 197/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0768 - acc: 0.6110 - val_loss: 1.4872 - val_acc: 0.4639\n",
      "Epoch 198/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0725 - acc: 0.6057 - val_loss: 1.4979 - val_acc: 0.4742\n",
      "Epoch 199/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0671 - acc: 0.6188 - val_loss: 1.4715 - val_acc: 0.4794\n",
      "Epoch 200/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0678 - acc: 0.6149 - val_loss: 1.5106 - val_acc: 0.4433\n",
      "Epoch 201/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0706 - acc: 0.6123 - val_loss: 1.4984 - val_acc: 0.4794\n",
      "Epoch 202/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0575 - acc: 0.6384 - val_loss: 1.4930 - val_acc: 0.4794\n",
      "Epoch 203/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0600 - acc: 0.6358 - val_loss: 1.5289 - val_acc: 0.4588\n",
      "Epoch 204/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0619 - acc: 0.6279 - val_loss: 1.5083 - val_acc: 0.4794\n",
      "Epoch 205/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0574 - acc: 0.6332 - val_loss: 1.5081 - val_acc: 0.4588\n",
      "Epoch 206/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0629 - acc: 0.6162 - val_loss: 1.5102 - val_acc: 0.4536\n",
      "Epoch 207/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0547 - acc: 0.6227 - val_loss: 1.5592 - val_acc: 0.4433\n",
      "Epoch 208/700\n",
      "766/766 [==============================] - 6s 7ms/step - loss: 1.0602 - acc: 0.6292 - val_loss: 1.5205 - val_acc: 0.4536\n",
      "Epoch 209/700\n",
      "766/766 [==============================] - 6s 7ms/step - loss: 1.0596 - acc: 0.6305 - val_loss: 1.5027 - val_acc: 0.4639\n",
      "Epoch 210/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0550 - acc: 0.6175 - val_loss: 1.5040 - val_acc: 0.4227\n",
      "Epoch 211/700\n",
      "766/766 [==============================] - 6s 7ms/step - loss: 1.0493 - acc: 0.6475 - val_loss: 1.4909 - val_acc: 0.4639\n",
      "Epoch 212/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0544 - acc: 0.6266 - val_loss: 1.5028 - val_acc: 0.4485\n",
      "Epoch 213/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.0434 - acc: 0.6097 - val_loss: 1.5180 - val_acc: 0.4485\n",
      "Epoch 214/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.0479 - acc: 0.6397 - val_loss: 1.5151 - val_acc: 0.4433\n",
      "Epoch 215/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.0321 - acc: 0.6397 - val_loss: 1.5308 - val_acc: 0.4433\n",
      "Epoch 216/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0364 - acc: 0.6345 - val_loss: 1.4892 - val_acc: 0.4588\n",
      "Epoch 217/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0443 - acc: 0.6188 - val_loss: 1.5059 - val_acc: 0.4639\n",
      "Epoch 218/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.0326 - acc: 0.6279 - val_loss: 1.5508 - val_acc: 0.4485\n",
      "Epoch 219/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0442 - acc: 0.6319 - val_loss: 1.4808 - val_acc: 0.4639\n",
      "Epoch 220/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.0313 - acc: 0.6332 - val_loss: 1.5155 - val_acc: 0.4588\n",
      "Epoch 221/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0308 - acc: 0.6227 - val_loss: 1.5186 - val_acc: 0.4588\n",
      "Epoch 222/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0254 - acc: 0.6266 - val_loss: 1.5390 - val_acc: 0.4691\n",
      "Epoch 223/700\n",
      "766/766 [==============================] - 7s 9ms/step - loss: 1.0273 - acc: 0.6514 - val_loss: 1.5619 - val_acc: 0.4278\n",
      "Epoch 224/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0177 - acc: 0.6279 - val_loss: 1.4887 - val_acc: 0.4536\n",
      "Epoch 225/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0381 - acc: 0.6292 - val_loss: 1.5020 - val_acc: 0.4485\n",
      "Epoch 226/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0218 - acc: 0.6292 - val_loss: 1.5000 - val_acc: 0.4227\n",
      "Epoch 227/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.0150 - acc: 0.6384 - val_loss: 1.5634 - val_acc: 0.4639\n",
      "Epoch 228/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0247 - acc: 0.6449 - val_loss: 1.5509 - val_acc: 0.4124\n",
      "Epoch 229/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.0250 - acc: 0.6384 - val_loss: 1.5163 - val_acc: 0.4794\n",
      "Epoch 230/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0146 - acc: 0.6488 - val_loss: 1.5341 - val_acc: 0.4536\n",
      "Epoch 231/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0187 - acc: 0.6488 - val_loss: 1.5093 - val_acc: 0.4639\n",
      "Epoch 232/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.0129 - acc: 0.6540 - val_loss: 1.5427 - val_acc: 0.4588\n",
      "Epoch 233/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.0096 - acc: 0.6488 - val_loss: 1.5118 - val_acc: 0.4639\n",
      "Epoch 234/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0145 - acc: 0.6292 - val_loss: 1.5083 - val_acc: 0.4485\n",
      "Epoch 235/700\n",
      "766/766 [==============================] - 6s 7ms/step - loss: 1.0054 - acc: 0.6554 - val_loss: 1.5162 - val_acc: 0.4639\n",
      "Epoch 236/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 1.0163 - acc: 0.6397 - val_loss: 1.4911 - val_acc: 0.4691\n",
      "Epoch 237/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9931 - acc: 0.6554 - val_loss: 1.5066 - val_acc: 0.4536\n",
      "Epoch 238/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.0002 - acc: 0.6554 - val_loss: 1.5123 - val_acc: 0.4691\n",
      "Epoch 239/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 1.0051 - acc: 0.6384 - val_loss: 1.5201 - val_acc: 0.4742\n",
      "Epoch 240/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 1.0001 - acc: 0.6397 - val_loss: 1.4962 - val_acc: 0.4588\n",
      "Epoch 241/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9989 - acc: 0.6462 - val_loss: 1.4973 - val_acc: 0.4639\n",
      "Epoch 242/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9945 - acc: 0.6358 - val_loss: 1.5101 - val_acc: 0.4691\n",
      "Epoch 243/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9960 - acc: 0.6436 - val_loss: 1.5384 - val_acc: 0.4330\n",
      "Epoch 244/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9946 - acc: 0.6475 - val_loss: 1.5368 - val_acc: 0.4588\n",
      "Epoch 245/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9997 - acc: 0.6423 - val_loss: 1.5052 - val_acc: 0.4433\n",
      "Epoch 246/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9919 - acc: 0.6697 - val_loss: 1.4978 - val_acc: 0.4639\n",
      "Epoch 247/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9897 - acc: 0.6410 - val_loss: 1.5047 - val_acc: 0.4588\n",
      "Epoch 248/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9838 - acc: 0.6554 - val_loss: 1.5703 - val_acc: 0.4433\n",
      "Epoch 249/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9929 - acc: 0.6462 - val_loss: 1.4844 - val_acc: 0.4794\n",
      "Epoch 250/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9874 - acc: 0.6475 - val_loss: 1.4940 - val_acc: 0.4536\n",
      "Epoch 251/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9827 - acc: 0.6488 - val_loss: 1.5042 - val_acc: 0.4639\n",
      "Epoch 252/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9805 - acc: 0.6619 - val_loss: 1.5239 - val_acc: 0.4691\n",
      "Epoch 253/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9787 - acc: 0.6462 - val_loss: 1.5604 - val_acc: 0.4485\n",
      "Epoch 254/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9750 - acc: 0.6658 - val_loss: 1.5258 - val_acc: 0.4948\n",
      "Epoch 255/700\n",
      "766/766 [==============================] - 4s 6ms/step - loss: 0.9737 - acc: 0.6619 - val_loss: 1.5056 - val_acc: 0.4278\n",
      "Epoch 256/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9728 - acc: 0.6632 - val_loss: 1.4944 - val_acc: 0.4691\n",
      "Epoch 257/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9697 - acc: 0.6762 - val_loss: 1.5169 - val_acc: 0.4588\n",
      "Epoch 258/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9663 - acc: 0.6802 - val_loss: 1.4884 - val_acc: 0.4588\n",
      "Epoch 259/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9656 - acc: 0.6619 - val_loss: 1.5698 - val_acc: 0.4433\n",
      "Epoch 260/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9716 - acc: 0.6632 - val_loss: 1.5147 - val_acc: 0.4794\n",
      "Epoch 261/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9669 - acc: 0.6723 - val_loss: 1.5807 - val_acc: 0.4072\n",
      "Epoch 262/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9670 - acc: 0.6606 - val_loss: 1.5021 - val_acc: 0.4845\n",
      "Epoch 263/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9663 - acc: 0.6749 - val_loss: 1.5048 - val_acc: 0.4794\n",
      "Epoch 264/700\n",
      "766/766 [==============================] - 4s 6ms/step - loss: 0.9645 - acc: 0.6710 - val_loss: 1.4911 - val_acc: 0.4639\n",
      "Epoch 265/700\n",
      "766/766 [==============================] - 4s 6ms/step - loss: 0.9602 - acc: 0.6723 - val_loss: 1.5251 - val_acc: 0.4588\n",
      "Epoch 266/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9615 - acc: 0.6671 - val_loss: 1.4972 - val_acc: 0.4381\n",
      "Epoch 267/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9564 - acc: 0.6619 - val_loss: 1.4904 - val_acc: 0.4278\n",
      "Epoch 268/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9532 - acc: 0.6749 - val_loss: 1.5151 - val_acc: 0.4330\n",
      "Epoch 269/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9588 - acc: 0.6749 - val_loss: 1.4987 - val_acc: 0.4742\n",
      "Epoch 270/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9379 - acc: 0.6723 - val_loss: 1.5200 - val_acc: 0.4948\n",
      "Epoch 271/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9477 - acc: 0.6802 - val_loss: 1.5070 - val_acc: 0.4794\n",
      "Epoch 272/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9466 - acc: 0.6619 - val_loss: 1.5400 - val_acc: 0.4639\n",
      "Epoch 273/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9438 - acc: 0.6841 - val_loss: 1.5544 - val_acc: 0.4897\n",
      "Epoch 274/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9418 - acc: 0.6723 - val_loss: 1.4980 - val_acc: 0.4536\n",
      "Epoch 275/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9399 - acc: 0.6671 - val_loss: 1.5059 - val_acc: 0.4381\n",
      "Epoch 276/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9364 - acc: 0.6684 - val_loss: 1.4918 - val_acc: 0.4742\n",
      "Epoch 277/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9317 - acc: 0.6684 - val_loss: 1.5394 - val_acc: 0.4536\n",
      "Epoch 278/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9417 - acc: 0.6749 - val_loss: 1.4886 - val_acc: 0.4691\n",
      "Epoch 279/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9371 - acc: 0.6762 - val_loss: 1.5452 - val_acc: 0.4639\n",
      "Epoch 280/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9268 - acc: 0.6658 - val_loss: 1.4975 - val_acc: 0.4845\n",
      "Epoch 281/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9267 - acc: 0.6749 - val_loss: 1.5201 - val_acc: 0.4330\n",
      "Epoch 282/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9292 - acc: 0.6867 - val_loss: 1.5181 - val_acc: 0.4485\n",
      "Epoch 283/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9223 - acc: 0.6815 - val_loss: 1.5130 - val_acc: 0.4742\n",
      "Epoch 284/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9264 - acc: 0.6736 - val_loss: 1.5376 - val_acc: 0.4588\n",
      "Epoch 285/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9252 - acc: 0.6775 - val_loss: 1.4844 - val_acc: 0.4639\n",
      "Epoch 286/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9245 - acc: 0.6828 - val_loss: 1.5007 - val_acc: 0.4794\n",
      "Epoch 287/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9181 - acc: 0.6775 - val_loss: 1.5403 - val_acc: 0.4691\n",
      "Epoch 288/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9148 - acc: 0.6789 - val_loss: 1.5050 - val_acc: 0.4794\n",
      "Epoch 289/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9166 - acc: 0.6671 - val_loss: 1.5047 - val_acc: 0.4639\n",
      "Epoch 290/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9120 - acc: 0.6828 - val_loss: 1.5347 - val_acc: 0.4433\n",
      "Epoch 291/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9151 - acc: 0.6893 - val_loss: 1.5464 - val_acc: 0.4330\n",
      "Epoch 292/700\n",
      "766/766 [==============================] - 6s 8ms/step - loss: 0.9148 - acc: 0.6723 - val_loss: 1.5355 - val_acc: 0.4485\n",
      "Epoch 293/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9199 - acc: 0.6749 - val_loss: 1.5102 - val_acc: 0.4588\n",
      "Epoch 294/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9160 - acc: 0.6802 - val_loss: 1.5159 - val_acc: 0.4742\n",
      "Epoch 295/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.8995 - acc: 0.6867 - val_loss: 1.5436 - val_acc: 0.4639\n",
      "Epoch 296/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9002 - acc: 0.6932 - val_loss: 1.5456 - val_acc: 0.4588\n",
      "Epoch 297/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9125 - acc: 0.6880 - val_loss: 1.5093 - val_acc: 0.4845\n",
      "Epoch 298/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9085 - acc: 0.6789 - val_loss: 1.5050 - val_acc: 0.4948\n",
      "Epoch 299/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9050 - acc: 0.6932 - val_loss: 1.5237 - val_acc: 0.4691\n",
      "Epoch 300/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.8979 - acc: 0.7037 - val_loss: 1.5143 - val_acc: 0.4433\n",
      "Epoch 301/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.9083 - acc: 0.6841 - val_loss: 1.5189 - val_acc: 0.4691\n",
      "Epoch 302/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.9016 - acc: 0.6841 - val_loss: 1.5203 - val_acc: 0.4794\n",
      "Epoch 303/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.8836 - acc: 0.6867 - val_loss: 1.4971 - val_acc: 0.4794\n",
      "Epoch 304/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.8885 - acc: 0.7128 - val_loss: 1.5243 - val_acc: 0.4330\n",
      "Epoch 305/700\n",
      "766/766 [==============================] - 5s 7ms/step - loss: 0.8860 - acc: 0.6971 - val_loss: 1.5450 - val_acc: 0.4536\n",
      "Epoch 306/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.8891 - acc: 0.6945 - val_loss: 1.5239 - val_acc: 0.4742\n",
      "Epoch 307/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8933 - acc: 0.6880 - val_loss: 1.5329 - val_acc: 0.4588\n",
      "Epoch 308/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8810 - acc: 0.7023 - val_loss: 1.5017 - val_acc: 0.4639\n",
      "Epoch 309/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8873 - acc: 0.7037 - val_loss: 1.5037 - val_acc: 0.4691\n",
      "Epoch 310/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.8929 - acc: 0.6880 - val_loss: 1.4961 - val_acc: 0.4639\n",
      "Epoch 311/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8754 - acc: 0.7050 - val_loss: 1.5112 - val_acc: 0.4845\n",
      "Epoch 312/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8767 - acc: 0.6932 - val_loss: 1.5486 - val_acc: 0.4639\n",
      "Epoch 313/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8796 - acc: 0.7102 - val_loss: 1.5478 - val_acc: 0.4691\n",
      "Epoch 314/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8784 - acc: 0.6958 - val_loss: 1.5407 - val_acc: 0.4639\n",
      "Epoch 315/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.8774 - acc: 0.6841 - val_loss: 1.5514 - val_acc: 0.4381\n",
      "Epoch 316/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8716 - acc: 0.7232 - val_loss: 1.4918 - val_acc: 0.4845\n",
      "Epoch 317/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8708 - acc: 0.7063 - val_loss: 1.5183 - val_acc: 0.4742\n",
      "Epoch 318/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8760 - acc: 0.6932 - val_loss: 1.5456 - val_acc: 0.4536\n",
      "Epoch 319/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8634 - acc: 0.6945 - val_loss: 1.5479 - val_acc: 0.4485\n",
      "Epoch 320/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8676 - acc: 0.7063 - val_loss: 1.5144 - val_acc: 0.4588\n",
      "Epoch 321/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.8651 - acc: 0.7154 - val_loss: 1.5510 - val_acc: 0.4536\n",
      "Epoch 322/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8599 - acc: 0.7023 - val_loss: 1.5343 - val_acc: 0.4845\n",
      "Epoch 323/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8663 - acc: 0.7010 - val_loss: 1.5581 - val_acc: 0.4588\n",
      "Epoch 324/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8664 - acc: 0.7089 - val_loss: 1.5092 - val_acc: 0.4433\n",
      "Epoch 325/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8588 - acc: 0.7063 - val_loss: 1.5227 - val_acc: 0.4691\n",
      "Epoch 326/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.8595 - acc: 0.6971 - val_loss: 1.5249 - val_acc: 0.4639\n",
      "Epoch 327/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8485 - acc: 0.7037 - val_loss: 1.5287 - val_acc: 0.4948\n",
      "Epoch 328/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8497 - acc: 0.7193 - val_loss: 1.5119 - val_acc: 0.4639\n",
      "Epoch 329/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8522 - acc: 0.7089 - val_loss: 1.5107 - val_acc: 0.4639\n",
      "Epoch 330/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8477 - acc: 0.7102 - val_loss: 1.5676 - val_acc: 0.4639\n",
      "Epoch 331/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8524 - acc: 0.7245 - val_loss: 1.5187 - val_acc: 0.4588\n",
      "Epoch 332/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8485 - acc: 0.6984 - val_loss: 1.5353 - val_acc: 0.4639\n",
      "Epoch 333/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8462 - acc: 0.7023 - val_loss: 1.5426 - val_acc: 0.4639\n",
      "Epoch 334/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8425 - acc: 0.7272 - val_loss: 1.5252 - val_acc: 0.4588\n",
      "Epoch 335/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8412 - acc: 0.7245 - val_loss: 1.5369 - val_acc: 0.4536\n",
      "Epoch 336/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8406 - acc: 0.7128 - val_loss: 1.5370 - val_acc: 0.4536\n",
      "Epoch 337/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8358 - acc: 0.7272 - val_loss: 1.5326 - val_acc: 0.4691\n",
      "Epoch 338/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8357 - acc: 0.7128 - val_loss: 1.5141 - val_acc: 0.4691\n",
      "Epoch 339/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8345 - acc: 0.7102 - val_loss: 1.5207 - val_acc: 0.4588\n",
      "Epoch 340/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8296 - acc: 0.7102 - val_loss: 1.5341 - val_acc: 0.4897\n",
      "Epoch 341/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8370 - acc: 0.7141 - val_loss: 1.5017 - val_acc: 0.4897\n",
      "Epoch 342/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.8282 - acc: 0.7167 - val_loss: 1.5216 - val_acc: 0.4485\n",
      "Epoch 343/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8355 - acc: 0.7128 - val_loss: 1.5308 - val_acc: 0.4845\n",
      "Epoch 344/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8241 - acc: 0.7193 - val_loss: 1.5528 - val_acc: 0.4381\n",
      "Epoch 345/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8333 - acc: 0.7193 - val_loss: 1.5402 - val_acc: 0.4639\n",
      "Epoch 346/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8193 - acc: 0.7180 - val_loss: 1.5136 - val_acc: 0.4742\n",
      "Epoch 347/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8317 - acc: 0.7193 - val_loss: 1.5575 - val_acc: 0.4485\n",
      "Epoch 348/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8304 - acc: 0.7180 - val_loss: 1.5263 - val_acc: 0.4794\n",
      "Epoch 349/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8169 - acc: 0.7076 - val_loss: 1.5438 - val_acc: 0.4536\n",
      "Epoch 350/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8228 - acc: 0.7232 - val_loss: 1.5340 - val_acc: 0.4330\n",
      "Epoch 351/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8262 - acc: 0.7272 - val_loss: 1.5437 - val_acc: 0.4691\n",
      "Epoch 352/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.8133 - acc: 0.7232 - val_loss: 1.5702 - val_acc: 0.4485\n",
      "Epoch 353/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8185 - acc: 0.7298 - val_loss: 1.5481 - val_acc: 0.4536\n",
      "Epoch 354/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8132 - acc: 0.7285 - val_loss: 1.5249 - val_acc: 0.4433\n",
      "Epoch 355/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8144 - acc: 0.7311 - val_loss: 1.5666 - val_acc: 0.4330\n",
      "Epoch 356/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8077 - acc: 0.7350 - val_loss: 1.5101 - val_acc: 0.4433\n",
      "Epoch 357/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8139 - acc: 0.7219 - val_loss: 1.5347 - val_acc: 0.4794\n",
      "Epoch 358/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8084 - acc: 0.7285 - val_loss: 1.5483 - val_acc: 0.4897\n",
      "Epoch 359/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8027 - acc: 0.7324 - val_loss: 1.5200 - val_acc: 0.4948\n",
      "Epoch 360/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.8070 - acc: 0.7193 - val_loss: 1.5167 - val_acc: 0.4639\n",
      "Epoch 361/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7972 - acc: 0.7454 - val_loss: 1.5584 - val_acc: 0.4330loss: 0.7793 -\n",
      "Epoch 362/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7981 - acc: 0.7298 - val_loss: 1.5191 - val_acc: 0.4691\n",
      "Epoch 363/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.8016 - acc: 0.7350 - val_loss: 1.5877 - val_acc: 0.4742\n",
      "Epoch 364/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7937 - acc: 0.7376 - val_loss: 1.5459 - val_acc: 0.4845\n",
      "Epoch 365/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7954 - acc: 0.7493 - val_loss: 1.5595 - val_acc: 0.4691\n",
      "Epoch 366/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7982 - acc: 0.7245 - val_loss: 1.5427 - val_acc: 0.4588\n",
      "Epoch 367/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7982 - acc: 0.7298 - val_loss: 1.5534 - val_acc: 0.4691\n",
      "Epoch 368/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7960 - acc: 0.7245 - val_loss: 1.5689 - val_acc: 0.4278\n",
      "Epoch 369/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7856 - acc: 0.7376 - val_loss: 1.5408 - val_acc: 0.4639\n",
      "Epoch 370/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7902 - acc: 0.7272 - val_loss: 1.5249 - val_acc: 0.4845\n",
      "Epoch 371/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7897 - acc: 0.7311 - val_loss: 1.5383 - val_acc: 0.4845\n",
      "Epoch 372/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7897 - acc: 0.7298 - val_loss: 1.5419 - val_acc: 0.4691\n",
      "Epoch 373/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7758 - acc: 0.7350 - val_loss: 1.6234 - val_acc: 0.4433\n",
      "Epoch 374/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7759 - acc: 0.7272 - val_loss: 1.5602 - val_acc: 0.4742\n",
      "Epoch 375/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7762 - acc: 0.7324 - val_loss: 1.5140 - val_acc: 0.4588\n",
      "Epoch 376/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7779 - acc: 0.7285 - val_loss: 1.5749 - val_acc: 0.4691\n",
      "Epoch 377/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7774 - acc: 0.7454 - val_loss: 1.5469 - val_acc: 0.4639\n",
      "Epoch 378/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7759 - acc: 0.7324 - val_loss: 1.5458 - val_acc: 0.4794\n",
      "Epoch 379/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7781 - acc: 0.7389 - val_loss: 1.5912 - val_acc: 0.4742\n",
      "Epoch 380/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7719 - acc: 0.7402 - val_loss: 1.5413 - val_acc: 0.4588\n",
      "Epoch 381/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7741 - acc: 0.7389 - val_loss: 1.5307 - val_acc: 0.4794\n",
      "Epoch 382/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7658 - acc: 0.7480 - val_loss: 1.5365 - val_acc: 0.4742\n",
      "Epoch 383/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7625 - acc: 0.7520 - val_loss: 1.5324 - val_acc: 0.4897\n",
      "Epoch 384/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.7671 - acc: 0.7415 - val_loss: 1.5687 - val_acc: 0.4485\n",
      "Epoch 385/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7576 - acc: 0.7467 - val_loss: 1.5920 - val_acc: 0.4691\n",
      "Epoch 386/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7635 - acc: 0.7350 - val_loss: 1.5611 - val_acc: 0.4691\n",
      "Epoch 387/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7601 - acc: 0.7415 - val_loss: 1.5576 - val_acc: 0.4845\n",
      "Epoch 388/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7531 - acc: 0.7559 - val_loss: 1.5255 - val_acc: 0.4639\n",
      "Epoch 389/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.7636 - acc: 0.7350 - val_loss: 1.5424 - val_acc: 0.46913\n",
      "Epoch 390/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.7553 - acc: 0.7402 - val_loss: 1.5656 - val_acc: 0.4588\n",
      "Epoch 391/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.7513 - acc: 0.7428 - val_loss: 1.5365 - val_acc: 0.4794\n",
      "Epoch 392/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.7564 - acc: 0.7467 - val_loss: 1.5473 - val_acc: 0.5000\n",
      "Epoch 393/700\n",
      "766/766 [==============================] - 5s 6ms/step - loss: 0.7511 - acc: 0.7376 - val_loss: 1.5273 - val_acc: 0.4948\n",
      "Epoch 394/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7550 - acc: 0.7533 - val_loss: 1.5539 - val_acc: 0.4794\n",
      "Epoch 395/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7456 - acc: 0.7363 - val_loss: 1.5596 - val_acc: 0.4742\n",
      "Epoch 396/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7528 - acc: 0.7559 - val_loss: 1.5694 - val_acc: 0.4691\n",
      "Epoch 397/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7345 - acc: 0.7611 - val_loss: 1.5841 - val_acc: 0.4485\n",
      "Epoch 398/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7468 - acc: 0.7441 - val_loss: 1.5463 - val_acc: 0.4794\n",
      "Epoch 399/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7426 - acc: 0.7533 - val_loss: 1.5575 - val_acc: 0.4381\n",
      "Epoch 400/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7388 - acc: 0.7480 - val_loss: 1.5555 - val_acc: 0.4588\n",
      "Epoch 401/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7452 - acc: 0.7389 - val_loss: 1.5686 - val_acc: 0.4742\n",
      "Epoch 402/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7373 - acc: 0.7467 - val_loss: 1.5878 - val_acc: 0.4691\n",
      "Epoch 403/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.7391 - acc: 0.7624 - val_loss: 1.5706 - val_acc: 0.5052\n",
      "Epoch 404/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7408 - acc: 0.7467 - val_loss: 1.5824 - val_acc: 0.4639\n",
      "Epoch 405/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7287 - acc: 0.7467 - val_loss: 1.6472 - val_acc: 0.4433\n",
      "Epoch 406/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.7350 - acc: 0.7533 - val_loss: 1.5592 - val_acc: 0.4845\n",
      "Epoch 407/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.7353 - acc: 0.7572 - val_loss: 1.5906 - val_acc: 0.4485\n",
      "Epoch 408/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.7353 - acc: 0.7441 - val_loss: 1.5794 - val_acc: 0.4742\n",
      "Epoch 409/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7180 - acc: 0.7559 - val_loss: 1.6106 - val_acc: 0.5155\n",
      "Epoch 410/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7316 - acc: 0.7585 - val_loss: 1.5455 - val_acc: 0.5155\n",
      "Epoch 411/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7188 - acc: 0.7624 - val_loss: 1.5686 - val_acc: 0.4794\n",
      "Epoch 412/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7279 - acc: 0.7559 - val_loss: 1.5556 - val_acc: 0.4742\n",
      "Epoch 413/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7282 - acc: 0.7546 - val_loss: 1.5770 - val_acc: 0.4794\n",
      "Epoch 414/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7136 - acc: 0.7611 - val_loss: 1.5874 - val_acc: 0.4691\n",
      "Epoch 415/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7141 - acc: 0.7715 - val_loss: 1.5820 - val_acc: 0.4742\n",
      "Epoch 416/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7113 - acc: 0.7676 - val_loss: 1.6480 - val_acc: 0.4485\n",
      "Epoch 417/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7220 - acc: 0.7533 - val_loss: 1.5615 - val_acc: 0.4794\n",
      "Epoch 418/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.7081 - acc: 0.7742 - val_loss: 1.5826 - val_acc: 0.4897\n",
      "Epoch 419/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7123 - acc: 0.7493 - val_loss: 1.5864 - val_acc: 0.4639\n",
      "Epoch 420/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7112 - acc: 0.7715 - val_loss: 1.5860 - val_acc: 0.4742\n",
      "Epoch 421/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7123 - acc: 0.7598 - val_loss: 1.5735 - val_acc: 0.4742\n",
      "Epoch 422/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7100 - acc: 0.7559 - val_loss: 1.5841 - val_acc: 0.4948\n",
      "Epoch 423/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.6998 - acc: 0.7702 - val_loss: 1.6024 - val_acc: 0.4845\n",
      "Epoch 424/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6990 - acc: 0.7624 - val_loss: 1.5532 - val_acc: 0.4897\n",
      "Epoch 425/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7027 - acc: 0.7611 - val_loss: 1.6172 - val_acc: 0.4588\n",
      "Epoch 426/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7085 - acc: 0.7624 - val_loss: 1.5789 - val_acc: 0.4948\n",
      "Epoch 427/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.7019 - acc: 0.7663 - val_loss: 1.5889 - val_acc: 0.4588cc: 0.7\n",
      "Epoch 428/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6919 - acc: 0.7728 - val_loss: 1.5841 - val_acc: 0.4897\n",
      "Epoch 429/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6963 - acc: 0.7572 - val_loss: 1.5438 - val_acc: 0.4845\n",
      "Epoch 430/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6863 - acc: 0.7702 - val_loss: 1.6166 - val_acc: 0.4948\n",
      "Epoch 431/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6921 - acc: 0.7794 - val_loss: 1.5766 - val_acc: 0.4742\n",
      "Epoch 432/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6882 - acc: 0.7624 - val_loss: 1.5760 - val_acc: 0.4845\n",
      "Epoch 433/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6952 - acc: 0.7689 - val_loss: 1.5586 - val_acc: 0.49486641 - ac\n",
      "Epoch 434/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.6851 - acc: 0.7702 - val_loss: 1.5796 - val_acc: 0.4948\n",
      "Epoch 435/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6858 - acc: 0.7676 - val_loss: 1.5910 - val_acc: 0.4897\n",
      "Epoch 436/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6876 - acc: 0.7742 - val_loss: 1.5975 - val_acc: 0.4433\n",
      "Epoch 437/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6782 - acc: 0.7794 - val_loss: 1.6005 - val_acc: 0.4794\n",
      "Epoch 438/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6822 - acc: 0.7833 - val_loss: 1.5735 - val_acc: 0.4897\n",
      "Epoch 439/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6818 - acc: 0.7676 - val_loss: 1.6018 - val_acc: 0.4691\n",
      "Epoch 440/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6787 - acc: 0.7585 - val_loss: 1.6259 - val_acc: 0.4948\n",
      "Epoch 441/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6763 - acc: 0.7715 - val_loss: 1.6025 - val_acc: 0.4897\n",
      "Epoch 442/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6741 - acc: 0.7898 - val_loss: 1.6048 - val_acc: 0.4742\n",
      "Epoch 443/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6686 - acc: 0.7833 - val_loss: 1.6269 - val_acc: 0.4639\n",
      "Epoch 444/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.6794 - acc: 0.7781 - val_loss: 1.5787 - val_acc: 0.4794\n",
      "Epoch 445/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6697 - acc: 0.7742 - val_loss: 1.6806 - val_acc: 0.4381\n",
      "Epoch 446/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6761 - acc: 0.7755 - val_loss: 1.5749 - val_acc: 0.4742\n",
      "Epoch 447/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6741 - acc: 0.7833 - val_loss: 1.6080 - val_acc: 0.4794: 1s - loss: 0.67\n",
      "Epoch 448/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6686 - acc: 0.7768 - val_loss: 1.5748 - val_acc: 0.5052\n",
      "Epoch 449/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6631 - acc: 0.7872 - val_loss: 1.6143 - val_acc: 0.4742\n",
      "Epoch 450/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6680 - acc: 0.7794 - val_loss: 1.6058 - val_acc: 0.4691 - acc:\n",
      "Epoch 451/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6615 - acc: 0.7742 - val_loss: 1.6027 - val_acc: 0.5103\n",
      "Epoch 452/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6613 - acc: 0.7872 - val_loss: 1.6066 - val_acc: 0.4845\n",
      "Epoch 453/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6572 - acc: 0.7963 - val_loss: 1.6138 - val_acc: 0.4948\n",
      "Epoch 454/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.6583 - acc: 0.7846 - val_loss: 1.5839 - val_acc: 0.4845\n",
      "Epoch 455/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6568 - acc: 0.7768 - val_loss: 1.6233 - val_acc: 0.4639\n",
      "Epoch 456/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6570 - acc: 0.7872 - val_loss: 1.5959 - val_acc: 0.5000\n",
      "Epoch 457/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6578 - acc: 0.7846 - val_loss: 1.5868 - val_acc: 0.4794\n",
      "Epoch 458/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6472 - acc: 0.7872 - val_loss: 1.5870 - val_acc: 0.4897\n",
      "Epoch 459/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6454 - acc: 0.7859 - val_loss: 1.6191 - val_acc: 0.4794\n",
      "Epoch 460/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6435 - acc: 0.7911 - val_loss: 1.5763 - val_acc: 0.4742\n",
      "Epoch 461/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6426 - acc: 0.7898 - val_loss: 1.6015 - val_acc: 0.4794\n",
      "Epoch 462/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6410 - acc: 0.7924 - val_loss: 1.6222 - val_acc: 0.5000\n",
      "Epoch 463/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6432 - acc: 0.7846 - val_loss: 1.5770 - val_acc: 0.4897\n",
      "Epoch 464/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6467 - acc: 0.7833 - val_loss: 1.6240 - val_acc: 0.4897\n",
      "Epoch 465/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6415 - acc: 0.7898 - val_loss: 1.6126 - val_acc: 0.5000\n",
      "Epoch 466/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6276 - acc: 0.7898 - val_loss: 1.6398 - val_acc: 0.4742\n",
      "Epoch 467/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6332 - acc: 0.8003 - val_loss: 1.6338 - val_acc: 0.4794\n",
      "Epoch 468/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6346 - acc: 0.7990 - val_loss: 1.5991 - val_acc: 0.4845\n",
      "Epoch 469/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6364 - acc: 0.7898 - val_loss: 1.6044 - val_acc: 0.4845\n",
      "Epoch 470/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.6256 - acc: 0.8055 - val_loss: 1.6086 - val_acc: 0.5103\n",
      "Epoch 471/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6318 - acc: 0.7898 - val_loss: 1.5903 - val_acc: 0.4897\n",
      "Epoch 472/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6290 - acc: 0.7911 - val_loss: 1.5854 - val_acc: 0.4897\n",
      "Epoch 473/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6252 - acc: 0.8029 - val_loss: 1.6039 - val_acc: 0.4897\n",
      "Epoch 474/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6284 - acc: 0.8003 - val_loss: 1.5850 - val_acc: 0.4948\n",
      "Epoch 475/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.6241 - acc: 0.7911 - val_loss: 1.6342 - val_acc: 0.4742\n",
      "Epoch 476/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6257 - acc: 0.8094 - val_loss: 1.6416 - val_acc: 0.5000\n",
      "Epoch 477/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6104 - acc: 0.8016 - val_loss: 1.6220 - val_acc: 0.5052\n",
      "Epoch 478/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6223 - acc: 0.7924 - val_loss: 1.6376 - val_acc: 0.5000\n",
      "Epoch 479/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6156 - acc: 0.7950 - val_loss: 1.6427 - val_acc: 0.4897\n",
      "Epoch 480/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6124 - acc: 0.8029 - val_loss: 1.6125 - val_acc: 0.5000.6\n",
      "Epoch 481/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6170 - acc: 0.7963 - val_loss: 1.6140 - val_acc: 0.4588\n",
      "Epoch 482/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6161 - acc: 0.8003 - val_loss: 1.6500 - val_acc: 0.5103\n",
      "Epoch 483/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6091 - acc: 0.8003 - val_loss: 1.6568 - val_acc: 0.4691\n",
      "Epoch 484/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6112 - acc: 0.8029 - val_loss: 1.6242 - val_acc: 0.5103\n",
      "Epoch 485/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6088 - acc: 0.7898 - val_loss: 1.6398 - val_acc: 0.4691\n",
      "Epoch 486/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6038 - acc: 0.8068 - val_loss: 1.6197 - val_acc: 0.4639\n",
      "Epoch 487/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.6002 - acc: 0.8146 - val_loss: 1.6094 - val_acc: 0.5052\n",
      "Epoch 488/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5994 - acc: 0.8120 - val_loss: 1.6513 - val_acc: 0.4948\n",
      "Epoch 489/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5995 - acc: 0.8225 - val_loss: 1.6073 - val_acc: 0.4845\n",
      "Epoch 490/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5990 - acc: 0.8159 - val_loss: 1.6245 - val_acc: 0.5155\n",
      "Epoch 491/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.5974 - acc: 0.8055 - val_loss: 1.6140 - val_acc: 0.4845\n",
      "Epoch 492/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5997 - acc: 0.8016 - val_loss: 1.6123 - val_acc: 0.4948\n",
      "Epoch 493/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5824 - acc: 0.8225 - val_loss: 1.6655 - val_acc: 0.4588\n",
      "Epoch 494/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5972 - acc: 0.8029 - val_loss: 1.6221 - val_acc: 0.4794\n",
      "Epoch 495/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5897 - acc: 0.8003 - val_loss: 1.6333 - val_acc: 0.5052\n",
      "Epoch 496/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.5918 - acc: 0.8133 - val_loss: 1.6369 - val_acc: 0.4845\n",
      "Epoch 497/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5918 - acc: 0.8198 - val_loss: 1.6287 - val_acc: 0.5052\n",
      "Epoch 498/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5804 - acc: 0.8094 - val_loss: 1.7044 - val_acc: 0.4794\n",
      "Epoch 499/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5797 - acc: 0.8146 - val_loss: 1.6273 - val_acc: 0.4948\n",
      "Epoch 500/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5860 - acc: 0.8211 - val_loss: 1.6138 - val_acc: 0.4948\n",
      "Epoch 501/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.5749 - acc: 0.8290 - val_loss: 1.6922 - val_acc: 0.4794\n",
      "Epoch 502/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5880 - acc: 0.8146 - val_loss: 1.6150 - val_acc: 0.4948\n",
      "Epoch 503/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5810 - acc: 0.8211 - val_loss: 1.6445 - val_acc: 0.4845\n",
      "Epoch 504/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5729 - acc: 0.8277 - val_loss: 1.6416 - val_acc: 0.5052\n",
      "Epoch 505/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.5684 - acc: 0.8185 - val_loss: 1.6371 - val_acc: 0.5000\n",
      "Epoch 506/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5781 - acc: 0.8303 - val_loss: 1.6328 - val_acc: 0.4897\n",
      "Epoch 507/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5704 - acc: 0.8225 - val_loss: 1.6207 - val_acc: 0.4845\n",
      "Epoch 508/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5694 - acc: 0.8146 - val_loss: 1.6873 - val_acc: 0.4845\n",
      "Epoch 509/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5663 - acc: 0.8290 - val_loss: 1.6187 - val_acc: 0.4948\n",
      "Epoch 510/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5650 - acc: 0.8277 - val_loss: 1.6531 - val_acc: 0.4639\n",
      "Epoch 511/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.5660 - acc: 0.8198 - val_loss: 1.6447 - val_acc: 0.4691\n",
      "Epoch 512/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5713 - acc: 0.8185 - val_loss: 1.6372 - val_acc: 0.4897\n",
      "Epoch 513/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5648 - acc: 0.8264 - val_loss: 1.6350 - val_acc: 0.5000\n",
      "Epoch 514/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5652 - acc: 0.8342 - val_loss: 1.6705 - val_acc: 0.4742\n",
      "Epoch 515/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5568 - acc: 0.8198 - val_loss: 1.6236 - val_acc: 0.5103\n",
      "Epoch 516/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5575 - acc: 0.8211 - val_loss: 1.6456 - val_acc: 0.5103\n",
      "Epoch 517/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.5506 - acc: 0.8316 - val_loss: 1.6524 - val_acc: 0.4897\n",
      "Epoch 518/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5551 - acc: 0.8342 - val_loss: 1.6920 - val_acc: 0.5000\n",
      "Epoch 519/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5534 - acc: 0.8277 - val_loss: 1.7175 - val_acc: 0.4742\n",
      "Epoch 520/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5508 - acc: 0.8512 - val_loss: 1.6863 - val_acc: 0.5103\n",
      "Epoch 521/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5426 - acc: 0.8225 - val_loss: 1.7286 - val_acc: 0.4845cc: 0\n",
      "Epoch 522/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.5526 - acc: 0.8238 - val_loss: 1.6721 - val_acc: 0.4227\n",
      "Epoch 523/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5471 - acc: 0.8316 - val_loss: 1.6896 - val_acc: 0.4845\n",
      "Epoch 524/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5496 - acc: 0.8251 - val_loss: 1.6633 - val_acc: 0.5052\n",
      "Epoch 525/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.5352 - acc: 0.8394 - val_loss: 1.6541 - val_acc: 0.4794\n",
      "Epoch 526/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5397 - acc: 0.8407 - val_loss: 1.6528 - val_acc: 0.5000\n",
      "Epoch 527/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.5456 - acc: 0.8394 - val_loss: 1.6534 - val_acc: 0.4742\n",
      "Epoch 528/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5463 - acc: 0.8394 - val_loss: 1.6726 - val_acc: 0.5258\n",
      "Epoch 529/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5441 - acc: 0.8316 - val_loss: 1.6468 - val_acc: 0.4897\n",
      "Epoch 530/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5372 - acc: 0.8407 - val_loss: 1.6541 - val_acc: 0.5000\n",
      "Epoch 531/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5359 - acc: 0.8381 - val_loss: 1.6427 - val_acc: 0.4897\n",
      "Epoch 532/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5267 - acc: 0.8433 - val_loss: 1.6417 - val_acc: 0.4948\n",
      "Epoch 533/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5279 - acc: 0.8394 - val_loss: 1.6974 - val_acc: 0.4948\n",
      "Epoch 534/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5314 - acc: 0.8368 - val_loss: 1.6358 - val_acc: 0.5000\n",
      "Epoch 535/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5265 - acc: 0.8473 - val_loss: 1.6676 - val_acc: 0.4897\n",
      "Epoch 536/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5259 - acc: 0.8394 - val_loss: 1.6903 - val_acc: 0.4948\n",
      "Epoch 537/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.5261 - acc: 0.8381 - val_loss: 1.6770 - val_acc: 0.5155\n",
      "Epoch 538/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5185 - acc: 0.8473 - val_loss: 1.6639 - val_acc: 0.5000\n",
      "Epoch 539/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5223 - acc: 0.8460 - val_loss: 1.6675 - val_acc: 0.5052\n",
      "Epoch 540/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5222 - acc: 0.8394 - val_loss: 1.6652 - val_acc: 0.5103\n",
      "Epoch 541/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5114 - acc: 0.8446 - val_loss: 1.6835 - val_acc: 0.5103\n",
      "Epoch 542/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.5165 - acc: 0.8525 - val_loss: 1.6771 - val_acc: 0.5052\n",
      "Epoch 543/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5151 - acc: 0.8525 - val_loss: 1.6503 - val_acc: 0.4948 0.5076 - \n",
      "Epoch 544/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5245 - acc: 0.8303 - val_loss: 1.6762 - val_acc: 0.4845\n",
      "Epoch 545/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5062 - acc: 0.8460 - val_loss: 1.6919 - val_acc: 0.4639\n",
      "Epoch 546/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5062 - acc: 0.8473 - val_loss: 1.7135 - val_acc: 0.5000\n",
      "Epoch 547/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5132 - acc: 0.8616 - val_loss: 1.7002 - val_acc: 0.4948\n",
      "Epoch 548/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5005 - acc: 0.8499 - val_loss: 1.6736 - val_acc: 0.5052\n",
      "Epoch 549/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5015 - acc: 0.8433 - val_loss: 1.7138 - val_acc: 0.4691\n",
      "Epoch 550/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5046 - acc: 0.8420 - val_loss: 1.7193 - val_acc: 0.5103\n",
      "Epoch 551/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4940 - acc: 0.8629 - val_loss: 1.7517 - val_acc: 0.4897\n",
      "Epoch 552/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.5057 - acc: 0.8525 - val_loss: 1.6765 - val_acc: 0.4794.5127\n",
      "Epoch 553/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.5004 - acc: 0.8499 - val_loss: 1.7202 - val_acc: 0.4948\n",
      "Epoch 554/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4956 - acc: 0.8538 - val_loss: 1.6976 - val_acc: 0.4691\n",
      "Epoch 555/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4966 - acc: 0.8460 - val_loss: 1.7096 - val_acc: 0.4794\n",
      "Epoch 556/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4941 - acc: 0.8590 - val_loss: 1.7560 - val_acc: 0.4639\n",
      "Epoch 557/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4899 - acc: 0.8551 - val_loss: 1.6780 - val_acc: 0.5000\n",
      "Epoch 558/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4924 - acc: 0.8551 - val_loss: 1.6702 - val_acc: 0.5155\n",
      "Epoch 559/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4844 - acc: 0.8551 - val_loss: 1.7329 - val_acc: 0.4794\n",
      "Epoch 560/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4939 - acc: 0.8642 - val_loss: 1.7049 - val_acc: 0.4897\n",
      "Epoch 561/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4898 - acc: 0.8538 - val_loss: 1.7202 - val_acc: 0.4948TA: 1s - loss: 0.5\n",
      "Epoch 562/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4883 - acc: 0.8603 - val_loss: 1.7147 - val_acc: 0.4742\n",
      "Epoch 563/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.4897 - acc: 0.8512 - val_loss: 1.7152 - val_acc: 0.4948\n",
      "Epoch 564/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4796 - acc: 0.8603 - val_loss: 1.7146 - val_acc: 0.5000\n",
      "Epoch 565/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4850 - acc: 0.8603 - val_loss: 1.7458 - val_acc: 0.4691\n",
      "Epoch 566/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4759 - acc: 0.8603 - val_loss: 1.7124 - val_acc: 0.5206\n",
      "Epoch 567/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4766 - acc: 0.8668 - val_loss: 1.7071 - val_acc: 0.4948\n",
      "Epoch 568/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.4795 - acc: 0.8695 - val_loss: 1.7621 - val_acc: 0.4897\n",
      "Epoch 569/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4712 - acc: 0.8616 - val_loss: 1.7381 - val_acc: 0.4897\n",
      "Epoch 570/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4688 - acc: 0.8695 - val_loss: 1.7133 - val_acc: 0.4794\n",
      "Epoch 571/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4783 - acc: 0.8590 - val_loss: 1.7643 - val_acc: 0.463941 - acc\n",
      "Epoch 572/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4797 - acc: 0.8564 - val_loss: 1.7382 - val_acc: 0.4948\n",
      "Epoch 573/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4738 - acc: 0.8603 - val_loss: 1.7120 - val_acc: 0.5052\n",
      "Epoch 574/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4729 - acc: 0.8668 - val_loss: 1.7698 - val_acc: 0.4845\n",
      "Epoch 575/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4662 - acc: 0.8681 - val_loss: 1.6890 - val_acc: 0.5052\n",
      "Epoch 576/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4655 - acc: 0.8590 - val_loss: 1.7483 - val_acc: 0.4794\n",
      "Epoch 577/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4732 - acc: 0.8616 - val_loss: 1.7068 - val_acc: 0.5052\n",
      "Epoch 578/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.4632 - acc: 0.8695 - val_loss: 1.7234 - val_acc: 0.4794\n",
      "Epoch 579/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4585 - acc: 0.8668 - val_loss: 1.7038 - val_acc: 0.4845\n",
      "Epoch 580/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4569 - acc: 0.8708 - val_loss: 1.7525 - val_acc: 0.5103: 0.\n",
      "Epoch 581/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4549 - acc: 0.8786 - val_loss: 1.7468 - val_acc: 0.4742\n",
      "Epoch 582/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4512 - acc: 0.8825 - val_loss: 1.7824 - val_acc: 0.4794\n",
      "Epoch 583/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.4457 - acc: 0.8812 - val_loss: 1.7198 - val_acc: 0.4897\n",
      "Epoch 584/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4514 - acc: 0.8786 - val_loss: 1.7356 - val_acc: 0.4845\n",
      "Epoch 585/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4437 - acc: 0.8786 - val_loss: 1.7146 - val_acc: 0.5103\n",
      "Epoch 586/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4482 - acc: 0.8721 - val_loss: 1.7237 - val_acc: 0.5000\n",
      "Epoch 587/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4515 - acc: 0.8695 - val_loss: 1.7293 - val_acc: 0.5000\n",
      "Epoch 588/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4477 - acc: 0.8864 - val_loss: 1.7353 - val_acc: 0.4794\n",
      "Epoch 589/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4493 - acc: 0.8708 - val_loss: 1.7472 - val_acc: 0.4794\n",
      "Epoch 590/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4372 - acc: 0.8786 - val_loss: 1.7923 - val_acc: 0.4536\n",
      "Epoch 591/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4459 - acc: 0.8747 - val_loss: 1.7552 - val_acc: 0.5052\n",
      "Epoch 592/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4445 - acc: 0.8825 - val_loss: 1.7495 - val_acc: 0.5052\n",
      "Epoch 593/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4342 - acc: 0.8708 - val_loss: 1.7831 - val_acc: 0.4897\n",
      "Epoch 594/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.4303 - acc: 0.8838 - val_loss: 1.7693 - val_acc: 0.4691\n",
      "Epoch 595/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4331 - acc: 0.8799 - val_loss: 1.7551 - val_acc: 0.5155\n",
      "Epoch 596/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4390 - acc: 0.8877 - val_loss: 1.7433 - val_acc: 0.4948\n",
      "Epoch 597/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4313 - acc: 0.8708 - val_loss: 1.7526 - val_acc: 0.4845\n",
      "Epoch 598/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4253 - acc: 0.8943 - val_loss: 1.8192 - val_acc: 0.4845\n",
      "Epoch 599/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.4279 - acc: 0.8825 - val_loss: 1.7486 - val_acc: 0.4742\n",
      "Epoch 600/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4269 - acc: 0.8773 - val_loss: 1.7847 - val_acc: 0.4588\n",
      "Epoch 601/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4270 - acc: 0.8786 - val_loss: 1.7260 - val_acc: 0.5052\n",
      "Epoch 602/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4280 - acc: 0.8734 - val_loss: 1.7866 - val_acc: 0.4897\n",
      "Epoch 603/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4181 - acc: 0.8773 - val_loss: 1.7711 - val_acc: 0.5000\n",
      "Epoch 604/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4186 - acc: 0.8838 - val_loss: 1.7618 - val_acc: 0.5000\n",
      "Epoch 605/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4152 - acc: 0.8799 - val_loss: 1.7494 - val_acc: 0.4845\n",
      "Epoch 606/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4142 - acc: 0.8916 - val_loss: 1.7657 - val_acc: 0.5206\n",
      "Epoch 607/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4120 - acc: 0.8903 - val_loss: 1.7790 - val_acc: 0.4794\n",
      "Epoch 608/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4101 - acc: 0.8943 - val_loss: 1.8285 - val_acc: 0.4485\n",
      "Epoch 609/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.4189 - acc: 0.8760 - val_loss: 1.7591 - val_acc: 0.4897\n",
      "Epoch 610/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4076 - acc: 0.8916 - val_loss: 1.7557 - val_acc: 0.4897\n",
      "Epoch 611/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4061 - acc: 0.8760 - val_loss: 1.8365 - val_acc: 0.4691\n",
      "Epoch 612/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4128 - acc: 0.8838 - val_loss: 1.7576 - val_acc: 0.4742\n",
      "Epoch 613/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4040 - acc: 0.8877 - val_loss: 1.8009 - val_acc: 0.4845\n",
      "Epoch 614/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.4080 - acc: 0.9073 - val_loss: 1.8157 - val_acc: 0.4897: 0s - loss: 0.4246 - \n",
      "Epoch 615/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4040 - acc: 0.8864 - val_loss: 1.7703 - val_acc: 0.4742\n",
      "Epoch 616/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4022 - acc: 0.8969 - val_loss: 1.7877 - val_acc: 0.4948\n",
      "Epoch 617/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4034 - acc: 0.8916 - val_loss: 1.7673 - val_acc: 0.4897\n",
      "Epoch 618/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.4031 - acc: 0.8864 - val_loss: 1.8291 - val_acc: 0.4897\n",
      "Epoch 619/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3936 - acc: 0.8943 - val_loss: 1.8002 - val_acc: 0.5000\n",
      "Epoch 620/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.3966 - acc: 0.8903 - val_loss: 1.8047 - val_acc: 0.4794\n",
      "Epoch 621/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3943 - acc: 0.9034 - val_loss: 1.8076 - val_acc: 0.4897\n",
      "Epoch 622/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3977 - acc: 0.8903 - val_loss: 1.8013 - val_acc: 0.4691\n",
      "Epoch 623/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3955 - acc: 0.8864 - val_loss: 1.7944 - val_acc: 0.4948\n",
      "Epoch 624/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3890 - acc: 0.9034 - val_loss: 1.7903 - val_acc: 0.4794\n",
      "Epoch 625/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.3964 - acc: 0.8930 - val_loss: 1.8393 - val_acc: 0.4536\n",
      "Epoch 626/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3905 - acc: 0.8982 - val_loss: 1.8116 - val_acc: 0.4845\n",
      "Epoch 627/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3864 - acc: 0.9021 - val_loss: 1.8071 - val_acc: 0.4948\n",
      "Epoch 628/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3916 - acc: 0.8930 - val_loss: 1.8145 - val_acc: 0.4742\n",
      "Epoch 629/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3809 - acc: 0.8982 - val_loss: 1.8490 - val_acc: 0.4639\n",
      "Epoch 630/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.3904 - acc: 0.8995 - val_loss: 1.8035 - val_acc: 0.5000\n",
      "Epoch 631/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3790 - acc: 0.8982 - val_loss: 1.8338 - val_acc: 0.4948\n",
      "Epoch 632/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3746 - acc: 0.9047 - val_loss: 1.8224 - val_acc: 0.4794\n",
      "Epoch 633/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3828 - acc: 0.9060 - val_loss: 1.8122 - val_acc: 0.4845\n",
      "Epoch 634/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3755 - acc: 0.8995 - val_loss: 1.7925 - val_acc: 0.4948\n",
      "Epoch 635/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3739 - acc: 0.9099 - val_loss: 1.8782 - val_acc: 0.4691\n",
      "Epoch 636/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3732 - acc: 0.9086 - val_loss: 1.8209 - val_acc: 0.4691\n",
      "Epoch 637/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3740 - acc: 0.9112 - val_loss: 1.7942 - val_acc: 0.4845\n",
      "Epoch 638/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3639 - acc: 0.9086 - val_loss: 1.9109 - val_acc: 0.4639\n",
      "Epoch 639/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3731 - acc: 0.8930 - val_loss: 1.8497 - val_acc: 0.4742\n",
      "Epoch 640/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.3650 - acc: 0.9112 - val_loss: 1.8635 - val_acc: 0.4948\n",
      "Epoch 641/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3711 - acc: 0.8916 - val_loss: 1.8439 - val_acc: 0.4948\n",
      "Epoch 642/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3622 - acc: 0.8943 - val_loss: 1.8155 - val_acc: 0.5000\n",
      "Epoch 643/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3673 - acc: 0.8969 - val_loss: 1.8179 - val_acc: 0.5000\n",
      "Epoch 644/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3591 - acc: 0.8982 - val_loss: 1.8278 - val_acc: 0.4794\n",
      "Epoch 645/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.3543 - acc: 0.9112 - val_loss: 1.8397 - val_acc: 0.453689 - acc: 0.9\n",
      "Epoch 646/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3633 - acc: 0.9086 - val_loss: 1.8444 - val_acc: 0.47940.9\n",
      "Epoch 647/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3564 - acc: 0.9112 - val_loss: 1.8310 - val_acc: 0.5000\n",
      "Epoch 648/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3562 - acc: 0.9060 - val_loss: 1.8881 - val_acc: 0.4948\n",
      "Epoch 649/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3573 - acc: 0.9034 - val_loss: 1.8673 - val_acc: 0.4794\n",
      "Epoch 650/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.3538 - acc: 0.8916 - val_loss: 1.8844 - val_acc: 0.4691\n",
      "Epoch 651/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3519 - acc: 0.9099 - val_loss: 1.8800 - val_acc: 0.4794\n",
      "Epoch 652/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3440 - acc: 0.9138 - val_loss: 1.8548 - val_acc: 0.4691\n",
      "Epoch 653/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3483 - acc: 0.9073 - val_loss: 1.8662 - val_acc: 0.5000\n",
      "Epoch 654/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3451 - acc: 0.9034 - val_loss: 1.8690 - val_acc: 0.4691\n",
      "Epoch 655/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3399 - acc: 0.9112 - val_loss: 1.8614 - val_acc: 0.4948\n",
      "Epoch 656/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.3389 - acc: 0.9243 - val_loss: 1.8386 - val_acc: 0.4897\n",
      "Epoch 657/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3403 - acc: 0.9230 - val_loss: 1.8591 - val_acc: 0.4948\n",
      "Epoch 658/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3401 - acc: 0.9191 - val_loss: 1.8632 - val_acc: 0.4794\n",
      "Epoch 659/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3314 - acc: 0.9204 - val_loss: 1.8894 - val_acc: 0.4691\n",
      "Epoch 660/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.3359 - acc: 0.9125 - val_loss: 1.8635 - val_acc: 0.4742\n",
      "Epoch 661/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3410 - acc: 0.9191 - val_loss: 1.8546 - val_acc: 0.4897\n",
      "Epoch 662/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3353 - acc: 0.9151 - val_loss: 1.8454 - val_acc: 0.4897\n",
      "Epoch 663/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3439 - acc: 0.9086 - val_loss: 1.8577 - val_acc: 0.4845\n",
      "Epoch 664/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3352 - acc: 0.9191 - val_loss: 1.8656 - val_acc: 0.4897\n",
      "Epoch 665/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3285 - acc: 0.9112 - val_loss: 1.8377 - val_acc: 0.5000\n",
      "Epoch 666/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3379 - acc: 0.9230 - val_loss: 1.8691 - val_acc: 0.4794\n",
      "Epoch 667/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3248 - acc: 0.9230 - val_loss: 1.8815 - val_acc: 0.4691\n",
      "Epoch 668/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3207 - acc: 0.9191 - val_loss: 1.8535 - val_acc: 0.4845\n",
      "Epoch 669/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3245 - acc: 0.9164 - val_loss: 1.8553 - val_acc: 0.4897\n",
      "Epoch 670/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3211 - acc: 0.9204 - val_loss: 1.8838 - val_acc: 0.4691\n",
      "Epoch 671/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.3207 - acc: 0.9164 - val_loss: 1.8653 - val_acc: 0.5103\n",
      "Epoch 672/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3212 - acc: 0.9282 - val_loss: 1.9072 - val_acc: 0.4897\n",
      "Epoch 673/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3158 - acc: 0.9178 - val_loss: 1.8896 - val_acc: 0.4948\n",
      "Epoch 674/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3208 - acc: 0.9204 - val_loss: 1.8929 - val_acc: 0.4794\n",
      "Epoch 675/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3202 - acc: 0.9256 - val_loss: 1.9378 - val_acc: 0.4794- acc: \n",
      "Epoch 676/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.3129 - acc: 0.9243 - val_loss: 1.9404 - val_acc: 0.4794\n",
      "Epoch 677/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3122 - acc: 0.9256 - val_loss: 1.9060 - val_acc: 0.4897\n",
      "Epoch 678/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3106 - acc: 0.9217 - val_loss: 1.9189 - val_acc: 0.4794\n",
      "Epoch 679/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3118 - acc: 0.9243 - val_loss: 1.9411 - val_acc: 0.4639\n",
      "Epoch 680/700\n",
      "766/766 [==============================] - 3s 5ms/step - loss: 0.3031 - acc: 0.9308 - val_loss: 1.9040 - val_acc: 0.4794\n",
      "Epoch 681/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3084 - acc: 0.9230 - val_loss: 1.9069 - val_acc: 0.4845\n",
      "Epoch 682/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3065 - acc: 0.9243 - val_loss: 1.9141 - val_acc: 0.5000\n",
      "Epoch 683/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3013 - acc: 0.9230 - val_loss: 1.9078 - val_acc: 0.4794\n",
      "Epoch 684/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.3042 - acc: 0.9373 - val_loss: 1.9036 - val_acc: 0.4794\n",
      "Epoch 685/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.2945 - acc: 0.9256 - val_loss: 1.8911 - val_acc: 0.5103\n",
      "Epoch 686/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.3006 - acc: 0.9308 - val_loss: 1.9537 - val_acc: 0.4845\n",
      "Epoch 687/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.2986 - acc: 0.9308 - val_loss: 1.9168 - val_acc: 0.4897\n",
      "Epoch 688/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.2926 - acc: 0.9295 - val_loss: 1.9407 - val_acc: 0.4845\n",
      "Epoch 689/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.2946 - acc: 0.9256 - val_loss: 1.9360 - val_acc: 0.4948\n",
      "Epoch 690/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.2944 - acc: 0.9295 - val_loss: 1.8954 - val_acc: 0.4897\n",
      "Epoch 691/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.3004 - acc: 0.9191 - val_loss: 1.9373 - val_acc: 0.4742\n",
      "Epoch 692/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.2958 - acc: 0.9282 - val_loss: 1.9257 - val_acc: 0.4742\n",
      "Epoch 693/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.2880 - acc: 0.9243 - val_loss: 1.9040 - val_acc: 0.4897\n",
      "Epoch 694/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.2924 - acc: 0.9321 - val_loss: 1.9248 - val_acc: 0.4794\n",
      "Epoch 695/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.2883 - acc: 0.9439 - val_loss: 1.9242 - val_acc: 0.4691\n",
      "Epoch 696/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.2885 - acc: 0.9295 - val_loss: 1.9181 - val_acc: 0.4897\n",
      "Epoch 697/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.2893 - acc: 0.9308 - val_loss: 1.9194 - val_acc: 0.4897\n",
      "Epoch 698/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.2845 - acc: 0.9256 - val_loss: 1.9793 - val_acc: 0.4845\n",
      "Epoch 699/700\n",
      "766/766 [==============================] - 4s 5ms/step - loss: 0.2777 - acc: 0.9386 - val_loss: 1.9914 - val_acc: 0.4691\n",
      "Epoch 700/700\n",
      "766/766 [==============================] - 3s 4ms/step - loss: 0.2869 - acc: 0.9243 - val_loss: 1.9675 - val_acc: 0.4691\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:/my_models\\Emotion_Voice_Detection_Model2.h5 \n"
     ]
    }
   ],
   "source": [
    "model_name = 'Emotion_Voice_Detection_Model2.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'C:/my_models')\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 46.91%\n"
     ]
    }
   ],
   "source": [
    "# loading json and creating model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"C:/my_models/Emotion_Voice_Detection_Model2.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = loaded_model.predict(x_testcnn, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2271674e-05, 1.1830255e-07, 1.7130513e-07, ..., 4.1565467e-02,\n",
       "        2.7543104e-01, 6.9329306e-03],\n",
       "       [2.4957684e-05, 8.8581979e-01, 1.6943505e-02, ..., 2.8401459e-02,\n",
       "        4.2887989e-02, 9.9868262e-03],\n",
       "       [1.4472539e-07, 7.0065513e-17, 1.6014674e-09, ..., 1.1355961e-04,\n",
       "        7.6384698e-05, 3.0686543e-08],\n",
       "       ...,\n",
       "       [3.5623757e-03, 8.1690578e-06, 2.0400823e-06, ..., 1.1689301e-01,\n",
       "        2.0518999e-01, 1.4639289e-04],\n",
       "       [1.0254214e-01, 5.1083755e-01, 1.4137062e-02, ..., 1.3738591e-02,\n",
       "        3.5497991e-04, 8.0039687e-02],\n",
       "       [6.2653367e-06, 2.2164797e-06, 1.2635531e-06, ..., 9.0816206e-01,\n",
       "        1.7277834e-03, 1.9030472e-02]], dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1=preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 5, 9, 6, 9, 5, 2, 4, 0, 0, 5, 2, 3, 9, 1, 7, 0, 6, 6, 2, 9,\n",
       "       8, 6, 9, 7, 0, 6, 6, 1, 1, 3, 8, 1, 2, 5, 7, 4, 6, 0, 0, 2, 0, 2,\n",
       "       6, 3, 4, 6, 9, 2, 8, 7, 1, 2, 4, 6, 7, 3, 7, 8, 7, 2, 0, 5, 3, 5,\n",
       "       2, 2, 9, 7, 7, 2, 8, 4, 4, 4, 8, 9, 2, 9, 7, 6, 9, 5, 5, 4, 7, 0,\n",
       "       3, 8, 5, 2, 2, 1, 4, 4, 6, 8, 1, 2, 3, 5, 7, 8, 3, 0, 7, 2, 5, 8,\n",
       "       6, 4, 6, 8, 9, 4, 1, 9, 9, 4, 6, 0, 7, 2, 7, 8, 2, 8, 0, 7, 2, 7,\n",
       "       2, 6, 4, 1, 3, 9, 3, 6, 7, 8, 1, 8, 5, 7, 9, 9, 9, 7, 3, 6, 5, 3,\n",
       "       5, 4, 0, 0, 3, 6, 2, 6, 2, 6, 8, 1, 8, 0, 7, 2, 5, 8, 2, 9, 4, 5,\n",
       "       7, 8, 3, 6, 2, 6, 9, 9, 9, 2, 1, 6, 7, 1, 4, 5, 1, 7], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = preds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (lb.inverse_transform((abc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predictedvalues\n",
       "0      male_angry\n",
       "1     female_calm\n",
       "2      male_angry\n",
       "3        male_sad\n",
       "4       male_calm\n",
       "5        male_sad\n",
       "6      male_angry\n",
       "7  female_fearful\n",
       "8      female_sad\n",
       "9    female_angry"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
    "preddf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=y_test.argmax(axis=1)\n",
    "abc123 = actual.astype(int).flatten()\n",
    "actualvalues = (lb.inverse_transform((abc123)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actualvalues\n",
       "0     male_calm\n",
       "1   female_calm\n",
       "2    male_angry\n",
       "3     male_calm\n",
       "4      male_sad\n",
       "5    female_sad\n",
       "6  male_fearful\n",
       "7    female_sad\n",
       "8    female_sad\n",
       "9  female_angry"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
    "actualdf[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('C:/test_audio/output10.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x1d39cde8248>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#livedf= pd.DataFrame(columns=['feature'])\n",
    "X, sample_rate = librosa.load('C:/test_audio/output2.wav', res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "featurelive = mfccs\n",
    "livedf2 = featurelive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "livedf2= pd.DataFrame(data=livedf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "livedf2 = livedf2.stack().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-70.152745</td>\n",
       "      <td>-69.913691</td>\n",
       "      <td>-67.810702</td>\n",
       "      <td>-68.664977</td>\n",
       "      <td>-71.470452</td>\n",
       "      <td>-71.470452</td>\n",
       "      <td>-71.470452</td>\n",
       "      <td>-71.470452</td>\n",
       "      <td>-71.470452</td>\n",
       "      <td>-71.470452</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.462678</td>\n",
       "      <td>-43.779465</td>\n",
       "      <td>-43.768887</td>\n",
       "      <td>-44.085496</td>\n",
       "      <td>-43.97565</td>\n",
       "      <td>-44.347019</td>\n",
       "      <td>-44.098364</td>\n",
       "      <td>-46.298862</td>\n",
       "      <td>-47.547014</td>\n",
       "      <td>-46.484299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "           0          0          0          0          0          0   \n",
       "0 -70.152745 -69.913691 -67.810702 -68.664977 -71.470452 -71.470452   \n",
       "\n",
       "         6          7          8          9    ...        206        207  \\\n",
       "           0          0          0          0  ...          0          0   \n",
       "0 -71.470452 -71.470452 -71.470452 -71.470452  ... -45.462678 -43.779465   \n",
       "\n",
       "         208        209       210        211        212        213        214  \\\n",
       "           0          0         0          0          0          0          0   \n",
       "0 -43.768887 -44.085496 -43.97565 -44.347019 -44.098364 -46.298862 -47.547014   \n",
       "\n",
       "         215  \n",
       "           0  \n",
       "0 -46.484299  \n",
       "\n",
       "[1 rows x 216 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livedf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "twodim= np.expand_dims(livedf2, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "livepreds = loaded_model.predict(twodim, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5578358e-03, 8.4999132e-01, 5.5450872e-02, 8.5636294e-03,\n",
       "        7.6262474e-02, 1.1075696e-09, 1.1046615e-03, 7.4910087e-05,\n",
       "        1.8627905e-04, 5.8080726e-03]], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livepreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "livepreds1=livepreds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveabc = livepreds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female_calm'], dtype=object)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livepredictions = (lb.inverse_transform((liveabc)))\n",
    "livepredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
